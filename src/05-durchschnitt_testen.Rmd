# Zentrale Tendenz testen {#zentrale-tendenz-testen}

Eine andere Fragestellung, welche mit Daten beantwortet werden soll, ist, ob eine gewisse Aussage wahr ist oder falsch. [Eine solche Aussage wird **Hypothese** (Symbol: $H$) genannt.]{.customdef #customdef-hypothese} Eine Hypothese könnte zum Beispiel sein: 

> $H:$ Es regnet. 

Ist die Hypothese einmal gefunden, können Daten gesammelt werden, um diese Hypothese zu bestätigen oder zu falsifizieren. Das heisst man geht nach raus ins Feld. Spürt man Regen auf der Haut bedeutet dies, dass $H$ wahr ist. Spürt man keinen Regen, so ist $H$ falsch.

Wenn eine Hypothese wahr ist, dann ist das Gegenteil der Hypothese falsch. Weil oft über die Hypothese und ihr Gegenteil debattiert wird, ist es nützlich die beiden auch terminologisch auseinanderhalten zu können. [Die Hypothese, welche den bisherigen Informationsstand reflektiert wird **Nullhypothese** (Symbol $H_0$) genannt.]{.customdef #customdef-nullhypothese} War es draussen bei der letzten Messung vor einer Stunde schönes Wetter, dann ist die Nullhypothese

> $H_0:$ Es regnet nicht. 

[Das Gegenteil der Nullhypothese wird **Alternativhypothese** (Symbol $H_1$) genannt.]{.customdef #customdef-alternativhypothese} Im Beispiel ist die Alternativhypothese 

> $H_1:$ Es regnet.

Die Nullhypothese bleibt der Stand der Wahrheit, bis sie durch Daten widerlegt wurde. Wenn man noch drinnen ist, kann keine Aussage über die Wahrheit von $H_0$ und $H_1$ gemacht werden, da die Daten fehlen. In diesem Fall wird angenommen, dass $H_0$ weiterhin wahr ist. Wenn man draussen Regen auf der Haut spürt, deutet dieser Datenpunkt darauf hin, dass $H_0$ nicht länger wahr ist und jetzt wahrscheinlich $H_1$ wahr ist. In diesem Fall spricht man davon, dass $H_0$ **abgelehnt** und $H_1$ **angenommen** wird.

## Entspricht der Erwartungswert einem gewissen Wert?

Um eine Hypothese mit Daten überprüfbar zu machen, muss diese in eine Form gebracht werden, welche Daten einbezieht. Eine einfache Form einer solchen überprüfbaren Hypothese ist 

> $H:$ Das durchschnittliche Vermögen einer in der Schweiz lebenden Person beträgt $100'000$ CHF. 

Wenn die Population alle in der Schweiz lebenden Personen sind, dann entspricht dies also der Nullhypothese

> $H_0:\mu = 100'000$. 

Abstrahiert, soll bei dieser Problemstellung herausgefunden werden, ob der Erwartungswert einer Population einem gewissen Wert entspricht. Das Gegenteil dieser Nullhypothese ist die Alternativhypothese 

> $H_1: \mu \neq 100'000$. 

Dies bedeutet, dass das durchschnittliche Vermögen der Population nicht bei $100'000$ CHF liegt. [Weil die Alternativhypothese hier zwei Ausgänge zulässt, nämlich kleiner oder grösser als $100'000$ CHF wird diese Art der Hypothesenstellung als **zweiseitige Hypothese** bezeichnet.]{.customdef #customdef-zweiseitige-hypothese}

Eine weitere Form der Hypothese wäre 

> $H:$ Das durchschnittliche Vermögen einer in der Schweiz lebenden Person beträgt weniger als oder genau $100'000$ CHF. 

In Formelsprache übersetzt entspricht dies 

> $H_0: \mu \leq 100'000$. 

Das Gegenteil davon ist, wenn das durchschnittliche Vermögen grösser und ungleich 100'000 CHF ist, also 

> $H_1: \mu > 100'000$. 

[Weil die Alternativhypothese hier nur einen Ausgang zulässt, nämlich grösser als $100'000$ CHF wird dies als **einseitige Hypothese** bezeichnet. Eine einseitige Hypothese kann auf beide Seiten formuliert sein: $H_0:\mu \leq 100'000$ und $H_1: \mu > 100'000$, wie eben erwähnt oder auch $H_0:\mu \geq 100'000$ und $H_1: \mu < 100'000$.]{.customdef #customdef-einseitige-hypothese}


::::{.caution data-latex=""}
::: {.remark}
Die verwendeten Zeichen in den Formeln sind

- $=$: Gleichheit, sprich "gleich". Beispiele: 
    - $3 = 3$ ($3$ gleich $3$) ist eine wahre Aussage. 
    - $3 = 4$ ($3$ gleich $4$) ist eine falsche Aussage.
- $\neq$: Ungleichheit, sprich "ungleich" oder "nicht gleich". Beispiele: 
    - $3 \neq 3$ ($3$ ist nicht gleich $3$) ist eine falsche Aussage. 
    - $3 \neq 4$ ($3$ ist nicht gleich $4$) ist eine wahre Aussage.
- $<$: Kleiner, sprich "kleiner". Beispiele: 
    - $4 < 3$ ($4$ ist kleiner als $3$) ist eine falsche Aussage. 
    - $3 < 3$ ($3$ ist kleiner als $3$) ist eine falsche Aussage. 
    - $3 < 4$ ($3$ ist kleiner als $4$) ist eine wahre Aussage.
- $\leq$: Kleiner gleich, sprich "kleiner gleich". Beispiele: 
    - $4 \leq 3$ ($4$ ist kleiner oder gleich wie $3$) ist eine falsche Aussage.
    - $3 \leq 3$ ($3$ ist kleiner oder gleich wie $3$) ist eine wahre Aussage. 
    - $3 \leq 4$ ($3$ ist kleiner oder gleich wie $4$) ist eine wahre Aussage.
- $>$: Grösser, sprich "grösser". Beispiele: 
    - $4 > 3$ ($4$ ist grösser als $3$) ist eine wahre Aussage. 
    - $3 > 3$ ($3$ ist grösser als $3$) ist eine falsche Aussage. 
    - $3 > 4$ ($3$ ist grösser als $4$) ist eine falsche Aussage.
- $\geq$: Grösser gleich, sprich "grösser gleich". Beispiele: 
    - $4 \geq 3$ ($4$ ist grösser oder gleich wie $3$) ist eine wahre Aussage. 
    - $3 \geq 3$ ($3$ ist grösser oder gleich wie $3$) ist eine wahre Aussage. 
    - $3 \geq 4$ ($3$ ist grösser oder gleich wie $4$) ist eine falsche Aussage.
    
:::
::::


:::{.example #vermoegen name="Vermögen"}

```{r exm-vermoegen}
gen_exm_vermoegen <- function(){
  # x ~ chisq(df)
  # a * x ~ a chisq(df)
  # E(a*x) ~ a E(chisq(df)) = a df
  # Var(a*x) ~ a^2 Var(x) = a^2 2k / n
  df <- 3L
  mu0 <- 100000
  scale_factor <- mu0/df
  
  n <- 20L
  set.seed(61)
  x <- scale_factor * rchisq(n, df)
  scores_hover <- x / 1000 # hovering with K CHF in scale
  x_mean <- x %>% mean()
  x_sd <- x %>% sd()
  t_emp <- (x_mean - mu0)/(x_sd/sqrt(n))
  p_value_the <- 1-pt((x_mean - 100000)/ (x_sd / sqrt(n)), n-1)
  effect_size <- (x_mean - mu0) / x_sd

  
  file_name <- '05-exm-vermoegen.sav'
  tibble(vermoegen = x) %>% write_sav(file_name)
  
  # distribution if H_0 were true
  n_samples <- 3000L
  x_means <- 1:n_samples %>% 
    map_dbl(~ mean(scale_factor*rchisq(n, df)))
  q95_x_means <- x_means %>% quantile(c(0.95)) %>% unlist() %>% unname()
  p_value_emp <- mean(x_means > x_mean)
  
  # plot sampling bag
  n_bag <- 200L
  scores_bag <- list(40*rchisq(n_bag,df),
                   # 60*rchisq(n_bag,df)
                   45*rchisq(n_bag,df)
                   )
  plots <- list()
  for (i in 1:length(scores_bag)) {
    plots[[i]] <- plot_ball_bag(
      scores_bag = scores_bag[[i]],
      scores_hover = scores_hover,
      score_name = "1000 CHF",
      seed = 123+i,
      no_legend = c(TRUE, FALSE)[i],
      limit_scores = c(0, 400)
    )
  }
  
  # plot histogram of sample means
  plot_hist_density <- plot_hist_denstiy_expected_value(
    x_means, 
    scale_factor*df, 
    sqrt((scale_factor)^2*2*df), 
    n,
    "Vermögen CHF",
    5000)
  
  line_xlim <- xlim(c(40000, 180000))
  sigma_g <- x_sd / sqrt(n)
  x_range_bounds <- c(mu0-3*sigma_g, mu0+3*sigma_g)
  x_range <- seq(x_range_bounds[1], x_range_bounds[2], length.out = 1000)
  create_text_data <- function(x,y,z){
    plot_attr_reja_pval$create_text_data(10000*c(6,13),x,y,z)
  }
  # Create data for histograms
  histogram_data <- tibble(
    x = rep(x_means, 2),
    plot_type = rep(c("Histogram p-Wert", 
                      "Histogram Ablehnungsbereich"), 
                    each = length(x_means))
  ) %>%
    plot_attr_reja_pval$add_colors(side = "right", upper = q95_x_means, test_stat = x_mean)
  
  # Create data for density plots
  density_data <- tibble(
    x = rep(x_range, 2),
    y = dt((x - mu0) / sigma_g, n - 1) / sigma_g,
    plot_type = rep(c("Verteilung p-Wert", 
                      "Verteilung Ablehnungsbereich"), 
                    each = length(x_range))
  )  %>%
    plot_attr_reja_pval$add_colors(side = "right", upper = q95_x_means, test_stat = x_mean)
  
  # Create text data for all plots
  text_sign <- c('95%', '5%')
  text_data_all <- bind_rows(
    create_text_data(
      round(100 *c(1 - p_value_emp, p_value_emp),1) %>% 
        str_c('%'),
      200,
      "Histogram p-Wert"
    ),
    create_text_data(
      text_sign, 
      200,
      "Histogram Ablehnungsbereich"
    ),
    create_text_data(
      round(100 *c(1-p_value_the, p_value_the),1) %>% 
        str_c('%'),
      0.000015, 
      "Verteilung p-Wert"
    ),
    create_text_data(
      text_sign, 
      0.000015,
      "Verteilung Ablehnungsbereich"
    )
  )
  
  
  
  plot_hist_curve_pval_reja <- ggplot() +
    geom_histogram(data = histogram_data,
                   aes(x = x, fill = color),
                   binwidth = 4300) +
    geom_area(data = density_data,
              aes(x = x, y = y, fill = color),
            stat = "identity") +
    geom_vline(xintercept = x_mean) +
    geom_text(data = text_data_all,
              mapping = aes(x = x, y = y, label = label, colour = color)) +
    facet_wrap(~ plot_type, nrow = 2, scales = "free_y", 
               strip.position = "top",
               labeller = plot_attr_reja_pval$custom_labeller) +
    line_xlim +
    plot_attr_reja_pval$theme +
    labs(x = "Vermögen", y = "W.-dichte                              Häufigkeit")

  return(mget(ls()))
}
exm_vermoegen <- gen_exm_vermoegen()
```

<!-- ```{r} -->
<!-- 1-pnorm(mean(exm_vermoegen$x), 100000, sd(exm_vermoegen$x_means)) -->
<!-- 1-pnorm(mean(exm_vermoegen$x), 100000, sd(exm_vermoegen$x) / sqrt(exm_vermoegen$n)) -->

<!-- 1-pt((mean(exm_vermoegen$x) - 100000)/ sd(exm_vermoegen$x_means), exm_vermoegen$n-1) -->
<!-- 1-pt((mean(exm_vermoegen$x) - 100000)/ (sd(exm_vermoegen$x) / sqrt(exm_vermoegen$n)), exm_vermoegen$n-1) -->
<!-- ``` -->

Eine Sozialpolitikberatungsfirma will herausfinden, ob das durchschnittliche Vermögen der in der Schweiz lebenden Personen im letzten Jahr gestiegen ist. Sie stellen dazu basierend auf dem aktuellen Wissensstand die Nullhypothese auf, dass das durchschnittliche Vermögen nicht gestiegen ist, und die Alternativhypothese, dass das durchschnittliche Vermögen gestiegen ist:

> $H_0: \mu \leq 100'000$ CHF

> $H_1: \mu > 100'000$ CHF

Um die Hypothesen auf einer Datengrundlage zu evaluieren, erfragt es das Vermögen von $n=`r exm_vermoegen$n`$ zufällig ausgewählten Personen und findet ein durchschnittliches Vermögen von $M=`r round(mean(exm_vermoegen$x))`$ CHF.

:::

Es kann nun schnell gesagt werden, dass das durchschnittliche Vermögen in der Population gestiegen ist, weil $`r round(mean(exm_vermoegen$x))`$ CHF grösser ist als $100'000$ CHF. Dies so zu behaupten wäre jedoch falsch, weil nicht alle Personen in der Population befragt wurden, sondern lediglich eine Zufallsstichprobe. Wie in Kapitel \@ref(stichprobenziehung) muss hier für eine Generalisierung der Stichprobe auf die Population der Effekt der zufälligen Stichprobenziehung miteinbezogen werden. 

Aufgrund der Zufallsstichprobe ist es unmöglich zu sagen, ob unsere Stichprobe eine eher seltene Stichprobenziehung aus einer Population mit unverändertem durchschnittlichen Vermögen von $100'000$ CHF ist (Abbildung \@ref(fig:exm-vermoegen-sampling-plot) links) oder ob es eine eher häufig vorkommende Stichprobenziehung aus einer Population mit höherem durchschnittlichen Vermögen ist (Abbildung \@ref(fig:exm-vermoegen-sampling-plot) rechts). 

```{r exm-vermoegen-sampling-plot, fig.cap="Vorgestellte Zufallsstichprobenziehung. Links: Nullhypothese ist wahr. Rechts: Nullhypothese ist falsch. Die grauen Punkte entsprechen Vermögen über 400'000 CHF.", echo = FALSE}
do.call(grid.arrange, c(exm_vermoegen$plots, ncol = 2))
```

Es kann jedoch ausgesagt werden, mit welcher Wahrscheinlichkeit der gefundene Stichprobenmittelwert realisiert wird, gegeben dass die Nullhypothese wahr ist. Hier wird also angenommen, dass eine Population mit Erwartungswert $\mu = 100'000$ CHF vorliegt und dass anschliessend zum Beispiel $`r exm_vermoegen$n_samples`$ Stichproben an je $`r exm_vermoegen$n`$ Beobachtungen pro Stichprobe gezogen werden. Von jeder dieser Stichproben wird das arithmetische Mittel berechnet. In der Verteilung dieser Mittelwerte, siehe Abbildung \@ref(fig:exm-vermoegen-histogram-plot), wird nun der tatsächliche Mittelwert der Stichprobe $\bar{x} = `r round(exm_vermoegen$x %>% mean())`$ verortet. 

```{r exm-vermoegen-histogram-plot, fig.cap="TODO.", echo = FALSE}
exm_vermoegen$plot_hist_density + 
  geom_vline(xintercept = exm_vermoegen$x %>% mean())+
  scale_x_continuous(n.breaks = 10)
```

Der beobachtete Mittelwert ist zwar nicht genau bei $100'000$ CHF, aber trotzdem noch einigermassen plausibel, wenn die Nullhypothese stimmt. Um diesen Gedanken zu formalisieren, gibt es zwei Denkweisen, welche nun vorgestellt werden.

Die eine Denkweise wurde von [Ronald Fisher](https://en.wikipedia.org/wiki/Ronald_Fisher) propagierte. Sie stellt die Frage nach der Wahrscheinlichkeit, dass zufällig der beobachtete Wert oder ein noch extremerer Wert in Richtung der Alternativhypothese resultiert, gegeben die Nullhypothese ist wahr. Im Beispiel entspricht dies der Wahrscheinlichkeit den Wert $`r round(exm_vermoegen$x %>% mean())`$ oder einen grösseren Wert zu beobachten, wenn der Erwartungswert tatsächlich bei $100'000$ CHF liegt. Um diese Wahrscheinlichkeit zu bestimmen, kann einfach gezählt werden, welcher Anteil der Stichprobenmittelwerte grösser oder gleich $`r round(exm_vermoegen$x %>% mean())`$ CHF ist. Im Beispiel sind dies $`r round(exm_vermoegen$p_value_emp,3)` = `r round(exm_vermoegen$p_value_emp*100,1)`\%$. [Dieser Wert wird, abgeleitet vom englischen _probability_, **$p$-Wert** (Symbol: $p$) genannt. Beim Berichten des $p$-Werts wird normalerweise die führende $0$ nicht geschrieben, also $p = `r round(exm_vermoegen$p_value_emp,3) %>% str_sub(2)`$.]{.customdef #customdef-pwert} 

[Bei der anderen von Neyman und Pearson propagierten Denkweise muss noch vor der Datenerhebung ein sogenanntes **Signifikanzniveau** (Symbol $\alpha$, sprich 'alpha')  bestimmt werden. Dieser Wert entspricht der Wahrscheinlichkeit, dass der statistische Test die Nullhypothese verwirft, obwohl diese wahr gewesen wäre. Normalerweise wird $\alpha = 5\%$ gesetzt.]{.customdef #customdef-signifikanzniveau} Es wird also akzeptiert, dass ein statistischer Test in $5\%$ der Fälle gegen die Nullhypothese entscheidet, obwohl diese wahr wäre. [In einem zweiten Schritt wird bestimmt, welches die $5\%$ unwahrscheinlichsten Werte sind, wenn die Nullhypothese wahr ist. Diese Werte werden **Ablehnungsbereich** genannt.]{.customdef #customdef-ablehnungsbereich} Im Beispiel sind dies die $5\%$ höchsten Werte, nämlich Vermögen von $`r round(exm_vermoegen$q95_x_means)`$ CHF und grössere Vermögen. Nun wird bestimmt, ob der tatsächliche beobachtete Wert im Ablehnungsbereich liegt oder nicht. [Im Beispiel liegt der Stichprobenmittelwert $`r round(exm_vermoegen$x_mean)`$ CHF nicht im Ablehnungsbereich. In diesem Fall wird die Nullhypothese nicht verworfen und das Testresultat erhält das Prädikat **nicht signifikant**. Läge der Stichprobenmittelwert im Ablehnungsbereich, so wäre das Testresultat als **signifikant** einzustufen.]{.customdef #customdef-signifikanz}

::::{.caution data-latex=""}
::: {.remark}
Ein signifikanter Unterschied bedeutet im allgemeinen Sprachgebrauch ein _bedeutsamer, substanzieller_ Unterschied. Im statistischen Kontext bedeutet ein _signifikanter Unterschied_, wie oben beschrieben, dass ein Unterschied bis auf eine gewisse Irrtumswahrscheinlichkeit (angegeben durch das Signifikanzniveau) _nicht zufällig_ zustande gekommen ist. Ein _nicht signifikanter Unterschied_ bedeutet dagegen, dass die Beobachtung _zufällig_ zustande gekommen sein könnte. Für letzteres gibt es zwei Erklärungen: (1) $H_0$ ist tatsächlich wahr. (2) $H_0$ ist zwar falsch, aber die Stichprobenziehung hat zufällig zu einem ähnlichen Resultat geführt, wie wenn $H_0$ wahr wäre. Ist ein Testresultat nicht signifikant, so kann also nicht genau gesagt werden, ob $H_0$ wahr ist oder nicht. Ist das Testresultat signifikant, so ist $H_0$ eher unwahrscheinlich.

In manchen Texten werden allgemeine und auch statistische Fragen bearbeitet. Hier empfiehlt sich für den allgemeinen Sprachgebrauch _substanziell_ und für die statischen Aussagen _statistisch signifikant_ zu verwenden.

Es wird ausserdem empfohlen, das Wort signifikant immer nur als Prädikat für eine Qualifizierung der Nullhypothese zu verwenden. Im Beispiel war $H_0: \mu \leq 100'000$CHF. Korrekte Aussage sind: 
- Das durchschnittliche Vermögen ist im letzten Jahr nicht signifikant gewachsen.
- Das durchschnittliche Vermögen ist in diesem Jahr nicht signifikant grösser als $100'000$ CHF.

:::
::::

Die beiden Denkarten entsprechen sich insofern, als ein $p$-Wert kleiner als $5\%$ ein signifikantes Resultat bei Signifikanzniveau $\alpha = 5\%$ bedeutet. In der Praxis werden beide Methoden verwendet. Im Beispiel liegt der $p$-Wert bei $p = `r round(exm_vermoegen$p_value_emp,3) %>% str_sub(2)`$. Dies bedeutet, dass die Wahrscheinlichkeit zufällig den realisierten Stichprobenmittelwert zu erhalten, gegeben, dass die Nullhypothese stimmt, grösser als $5\%$ ist und demnach auch der Unterschied nicht signifikant ist.

Ein noch zu lösendes Problem ist, dass normalerweise Geld, Zeit und Nerven fehlen, um eine Stichprobenziehung $`r exm_vermoegen$n_samples`$-mal zu wiederholen. Hier hilft es wieder zu beobachten, dass die Verteilung der Werte des Histogramms in Abbildung \@ref(fig:exm-vermoegen-histogram-plot) wieder mit zunehmender Stichprobengrösse immer genauer einer Normalverteilung folgen. Tatsächlich trifft es aufgrund des [zentralen Grenzwertsatzes](#customdef-zentraler-grenzwertsatz) immer zu, dass wenn ein Merkmal mit $N$ Beobachtungen, Erwartungswert $\mu$ und Standardabweichung $\sigma$ hat, der Wert

$$z = \frac{\bar{x}-\mu}{\frac{\sigma}{\sqrt{n}}}$$
normalverteilt ist, wobei $\mu$ hier dem Wert der Nullhypothese entspricht, also $100'000$ CHF. Dies entspricht der roten Linie in Abbildung \@ref(fig:exm-vermoegen-histogram-plot). Ist die Standardabweichung des Merkmals $\sigma$ in der Population unbekannt, so wird diese mit der Standardabweichung in der Stichprobe $s$ geschätzt. Diese zusätzliche Unsicherheit führt dazu, dass
\begin{equation}
t = \frac{\bar{x}-\mu}{\frac{s}{\sqrt{n}}}
(\#eq:t-emp-onesample)
\end{equation}
<!-- TODO: Discuss: I don't give the numerical values for t because they do not correspond to the distribution in the figure below because of the scaling and would therefore confuse the reader. -->
nicht mehr normal-, sondern $t$-verteilt ist bei $n-1$ Freiheitsgraden (grüne Linie, Abbildung \@ref(fig:exm-vermoegen-histogram-plot)). Die $t$-Verteilung mit allen Freiheitsgraden ist in `Jamovi` hinterlegt und es kann der Software überlassen werden den $p$-Wert und den Ablehnungsbereich genau zu bestimmen. In Abbildung \@ref(fig:exm-vermoegen-plots-sampling-theorie) wurde nochmal illustriert, dass es bei vielen Beobachtungen der theoretische $p$-Wert (Kurve) mit dem empirischen $p$-Wert der Simulationen (Histogramm) übereinstimmt respektive der Ablehnungsbereich der $t$-Verteilung (Kurve) gleich ist, wie der simulierte Ablehnungsbereich (Histogramm).

<!-- TODO: Discuss  -->
<!-- - why p-Wert does not correspond exactly to empirical p-Wert? -->
<!-- - what is that uncertainty w.r.t. the rejection area? -->

```{r exm-vermoegen-plots-sampling-theorie, fig.cap="Oben: Histogramm der simulierten Verteilung; unten: theoretische t-Verteilung; links: Illustration p-Wert; rechts: Illustration Ablehnungsbereich. Die Linie entspricht dem beobachteten Stichprobenmittelwert."}
exm_vermoegen$plot_hist_curve_pval_reja
```

[Die Berechnung des für den Test relevanten Wertes, hier des $t$-Wertes wird **Teststatistik** (oder auch _Prüfgrösse_ oder nur _Statistik_) genannt.]{.customdef #customdef-teststatistik} Eine Teststatistik hat normalerweise eine bekannte theoretische Verteilung, welcher die Teststatistik folgt, wenn die Nullhypothese wahr ist. [Aufgrund der theoretischen $t$-Verteilung der vorliegenden Statistik und der einen Stichprobe (vgl. nächstes Kapitel) wird dieser Test **Einstichproben-$t$-Test** genannt.]{.customdef #customdef-t-test}

Das oben gefundene Resultat wird in der folgenden Form berichtet:

> Ein Einstichproben-$t$-Test ergibt, dass das durchschnittliche Vermögen ($M = `r round(exm_vermoegen$x_mean)`$ CHF, $SD = `r round(exm_vermoegen$x_sd)`$, $N = `r round(exm_vermoegen$n)`$) in diesem Jahr nicht signifikant grösser als $100'000$ CHF ist, $t(`r round(exm_vermoegen$n-1)`) = `r round(exm_vermoegen$t_emp,3)`$, $p = `r round(exm_vermoegen$p_value_the,3) %>% str_sub(start = 2L)`$.

::::{.caution data-latex=""}
::: {.remark}
Folgende Begriffe und Zahlen werden dabei verwendet:

- Das _durchschnittliche_ Vermögen (fehlt durchschnittlich ist die Aussage falsch).
- $M$, $SD$, $N$ entsprechen dem arithmetischen Mittel, der geschätzten Standardabweichung und der Anzahl Beobachtungen in der Stichprobe. Die Einheit muss nicht wiederholt werden.
- Signifikanz (siehe letzter Hinweis)
- grösser als $100'000$ CHF ist die Referenz zur Alternativhypothese
- $t(`r round(exm_vermoegen$n-1)`)$ bedeutet, dass die Teststatistik $t$-verteilt ist mit $`r round(exm_vermoegen$n-1)`$ Freiheitsgraden.
- $`r round(exm_vermoegen$t_emp,3)`$ ist der Wert der Teststatistik berechnet mit Formel \@ref(eq:t-emp-onesample) aus der Stichprobe. Dieser Wert ist skaliert und muss im Kontext der standardisierten $t$-Verteilung wie in Abbildung \@ref(fig:t-distribution) interpretiert werden.
- $p = `r round(exm_vermoegen$p_value_the,3) %>% str_sub(start = 2L)`$ entspricht dem $p$-Wert. Es wird normalerweise die führende $0$ weggelassen (also nicht $`r round(exm_vermoegen$p_value_the,3)`)$, da es sich um eine Zahl handelt, welche nie kleiner als $0$ oder grösser als $1$ sein kann.
:::
::::


:::{.example #alexithymie name="Alexithymie"}

```{r exm-alexithymie}
gen_exm_alexithymie <- function(){
  set.seed(1982)
  mu0 <- 100
  x_min <- 37
  x_max <- 185
  n <- 391
  
  x <- rnorm(n, 96, 25) 
  x <- crop(x, x_min, x_max)
  x[which(x < x_min)] <- x_min
  x[which(x > x_max)] <- x_max
  # x %>% summary()
  # x %>% t.test(alternative = 'two.sided',
  #              mu = 100)
  x_mean <- x %>% mean()
  x_mean_sym <- mu0 + (mu0 - x_mean)
  x_sd <- x %>% sd()
  t_emp <- (x_mean - mu0)/(x_sd/sqrt(n))
  p_value_the <- 2*pt((x_mean - mu0)/ (x_sd / sqrt(n)), n-1)
  effect_size <- (x_mean - mu0) / x_sd
  
  file_name <- '05-exm-alexithymie.sav'
  tibble(alexithymie = x) %>% write_sav(file_name)
  
  # distribution if H_0 were true
  n_samples <- 4000L
  x_means <- 1:n_samples %>% 
    map_dbl(~ mean(rnorm(n, mu0, 25)))
  q975_x_means <- x_means %>% quantile(c(0.975)) %>% unlist() %>% unname()
  q025_x_means <- x_means %>% quantile(c(0.025)) %>% unlist() %>% unname()
  p_value_emp <- mean(x_means < x_mean | x_means > mu0 + (mu0 - x_mean))
  
  # plot histogram of sample means
  plot_hist_density <- plot_hist_denstiy_expected_value(
    x_means, 
    mu0, 
    x_sd, 
    n,
    "Alexithymie CHF",
    0.25)
  
  line_xlim <- xlim(c(95, 105))
  sigma_g <- x_sd / sqrt(n)
  x_range <- seq(mu0-3*sigma_g, mu0+3*sigma_g, length.out = 1000)
  create_text_data <- function(x,y,z){
    plot_attr_reja_pval$create_text_data(c(98, 102),x,y,z)
  }
  # Create data for histograms
  histogram_data <- tibble(
    x = rep(x_means, 2),
    plot_type = rep(c("Histogram p-Wert", 
                      "Histogram Ablehnungsbereich"), 
                    each = length(x_means))
  ) %>%
    plot_attr_reja_pval$add_colors(side = "both", upper = q975_x_means, lower = q025_x_means, test_stat = x_mean, mu0 = mu0)
  
  # Create data for density plots
  density_data <- tibble(
    x = rep(x_range, 2),
    y = dt((x - mu0) / sigma_g, n - 1) / sigma_g,
    plot_type = rep(c("Verteilung p-Wert", 
                      "Verteilung Ablehnungsbereich"), 
                    each = length(x_range))
  ) %>%
    plot_attr_reja_pval$add_colors(side = "both", upper = q975_x_means, lower = q025_x_means, test_stat = x_mean, mu0 = mu0)
  
  # Create text data for all plots
  text_pval <- str_c(round(100 * c(1 - p_value_emp, p_value_emp), 1), '%')
  text_sign <- c('95%', '5%')
  text_data_all <- bind_rows(
    create_text_data(
      text_pval,
      200,
      "Histogram p-Wert"
    ),
    create_text_data(
      text_sign, 
      200,
      "Histogram Ablehnungsbereich"
    ),
    create_text_data(
      round(100 *c(1-p_value_the,p_value_the),1) %>% 
        str_c('%'),
      0.25, 
      "Verteilung p-Wert"
    ),
    create_text_data(
      text_sign, 
      0.25,
      "Verteilung Ablehnungsbereich"
    )
  )
  
  plot_hist_curve_pval_reja <- ggplot() +
    geom_histogram(data = histogram_data,
                   aes(x = x, fill = color),
                   binwidth = 0.25) +
    
    geom_area(data = density_data,
              aes(x = x, y = y, fill = color),
            stat = "identity") +
    geom_vline(xintercept = x_mean) +
    geom_text(data = text_data_all,
              mapping = aes(x = x, y = y, label = label, colour = color)) +
    facet_wrap(~ plot_type, nrow = 2, scales = "free_y", 
               strip.position = "top",
               labeller = plot_attr_reja_pval$custom_labeller) +
    line_xlim +
    plot_attr_reja_pval$theme +
    labs(x = "Alexithymie", y = "W.-dichte                              Häufigkeit")

  return(mget(ls()))
}
exm_alexithymie <- gen_exm_alexithymie()
```

Mit Gefühlsblindheit oder _Alexithymie_ (griechisch: a = ohne, lexis= lesen, sprechen, thymie = Gefühle) werden Einschränkungen bei der Fähigkeit Emotionen wahrzunehmen, zu erkennen und zu beschreiben bezeichnet. Es gibt ein online [Messinstrument](https://www.alexithymie.com/de/), welches die Alexithymie auf einer Skala von $`r exm_alexithymie$x_min`$ Punkten (kleine Gefühlsblindheit) bis $`r exm_alexithymie$x_max`$ (grosse Gefühlsblindheit) misst. Die Skala wurde so gewählt, dass die durchschnittliche Alexithymie aller Menschen bei $`r exm_alexithymie$mu0`$ liegt. Eine Psychologin interessiert sich nun dafür, ob junge Menschen unter $25$ durchschnittlich andere Alexithymie-Werte aufweisen als die Gesamtbevölkerung. Um dies zu testen, befragt sie $N = `r exm_alexithymie$n`$ unter $25$-jährige mit besagtem Messinstrument. In dieser Gruppe wurde eine durchschnittliche Alexithymie von $M = `r round(exm_alexithymie$x_mean,1)`$ Punkten festgestellt.
:::

<!-- Discuss: Was könnten gründe sein für eine tiefere, höhrere Alexithymie? -->
<!-- Es kann festgestellt werden, dass das wahrnehmen, erkennen und beschreiben von Emotionen in den letzten Jahrzehnten vermehrt in den Fokus der Früherziehung gerückt ist. -->
<!-- Discuss: Wieso ist hier ein Test nötig? -->

Der erste Schritt ist auch hier die Null- und Alternativhypothesen aufzustellen. Die Psychologin stellt die Frage, ob sich die durchschnittliche Alexithymie in der Grundgesamtheit, in der Folge mit $\mu$ bezeichnet, von $100$ unterscheidet oder nicht. Es ist zu beobachten, dass sie keine Annahme über die Richtung der Abweichung trifft (eine höhere oder eine tiefere Alexithymie wären denkbar) und es sich deshalb um eine zweiseitige Hypothesenstellung handelt. 

Die Nullhypothese beschreibt den bisherigen Informationsstand, also dass die durchschnittliche Alexithymie der Population bei $100$ Punkten liegt, oder kurz

> $H_0:\mu = 100$ Punkte. 

Die Alternativhypothese besagt das Gegenteil davon, also hier, dass die durchschnittliche Alexithymie nicht mehr bei $100$ Punkten liegt, oder kurz

> $H_1: \mu \neq 100$ Punkte. 

Um die Wahrscheinlichkeit des beobachteten arithmetischen Mittels der Stichprobe von $M = `r round(exm_alexithymie$x_mean,1)`$ Punkten zu ermitteln, gegeben, dass die Nullhypothese wahr ist, kann erneut auf den Gedanken der wiederholten Stichprobenziehung zurückgegriffen werden. Bei diesem Gedankenexperiment wird angenommen, dass Nullhypothese wahr ist und dass das die Untersuchung $`r exm_alexithymie$n_samples`$-mal wiederholt wurde mit jeweils $`r exm_alexithymie$n`$ Beobachtungen. Von jeder dieser Stichproben kann wiederum das arithmetische Mittel berechnet werden. Die Verteilung dieser arithmetischen Mittel ist in Abbildung \@ref(fig:exm-alexithymie-plot) oben dargestellt.

```{r exm-alexithymie-plot, fig.cap="Oben: Histogramm der simulierten Verteilung der Alexithymie-Mittelwerte; unten: theoretische t-Verteilung; links: Illustration p-Wert; rechts: Illustration Ablehnungsbereich. Die Linie entspricht dem beobachteten Stichprobenmittelwert."}
exm_alexithymie$plot_hist_curve_pval_reja
```

Der $p$-Wert, also die Wahrscheinlichkeit, dass der beobachtete Wert oder ein noch extremerer Wert in Richtung der Alternativhypothese resultiert, wird hier aufgrund der zweiseitigen Hypothesenstellung auch zweiseitig ausgelegt. Extremer in Richtung der Alternativhypothese meint hier alle Werte, die weiter weg als der beobachtete Durchschnittswert $`r round(exm_alexithymie$x_mean,1)`$ vom hypothetischen Erwartungswert $\mu = `r exm_alexithymie$mu0`$ sind. Konkret sind dies alle Werte, welche kleiner als $`r round(exm_alexithymie$x_mean,1)`$, und alle Werte, welche grösser als $`r round(exm_alexithymie$x_mean_sym,1)`$ sind (roter Bereich in Abbildung \@ref(fig:exm-alexithymie-plot) oben rechts). Der Anteil der Werte, welche diese Bedingung erfüllen liegt bei $p = `r round(100*exm_alexithymie$p_value_emp,1)`\%$. Es ist demnach recht unwahrscheinlich, dass die Nullhypothese stimmt und zufällig ein Stichprobendurchschnittswert von $`r round(exm_alexithymie$x_mean,1)`$ Alexithymie-Punkten herauskommt.

Aufgrund der zweiseitigen Hypothesenstellung beinhaltet auch der Ablehnungsbereich sowohl die tiefsten $2.5\%$ und höchsten $2.5\%$, also insgesamt die $5\%$ extremen Durchschnittswerte. Dies sind alle Werte tiefer als  $`r round(exm_alexithymie$q025_x_means,2)`$ und alle Werte höher als $`r round(exm_alexithymie$q975_x_means,2)`$ (roter Bereich in Abbildung \@ref(fig:exm-alexithymie-plot) oben links). Da das arithmetische Mittel der Stichprobe $`r round(exm_alexithymie$x_mean,1)`$ im Ablehnungsbereich liegt, liegt hier ein signifikantes Resultat vor bei Signifikanzniveau $5\%$.

Auch in diesem Fall kann die Verteilung der Stichprobenmittelwerte mit dem zentralen Grenzwertsatz angenähert werden. Es ergeben sich annähernd dieselben Resultate für den $p$-Wert (roter Bereich in Abbildung \@ref(fig:exm-alexithymie-plot) unten rechts) und für den Ablehnungsbereich (roter Bereich in Abbildung \@ref(fig:exm-alexithymie-plot) unten links).

Die Psychologin kann nun wie folgt berichten:

> Ein Einstichproben-$t$-Test ergibt, dass die durchschnittliche Alexithymie ($M = `r round(exm_alexithymie$x_mean,1)`$ Punkte, $SD = `r round(exm_alexithymie$x_sd,1)`$, $N = `r round(exm_alexithymie$n)`$) sich bei den unter 25-jährigen signifikant vom Populationsdurchschnitt von $100$ Punkten unterscheidet, $t(`r round(exm_alexithymie$n-1)`) = `r round(exm_alexithymie$t_emp,3)`$, $p = `r round(exm_alexithymie$p_value_the,3) %>% str_sub(start = 2L)`$.


## Weicht der gefundene Durchschnitt stark vom hypothetischen Wert ab?

<!-- Discuss: Probleme (grosses n -> immer signifikant, je nach Einheit ist Erwartungswertunterschied ganz anders). -->

In einem so berichteten Testresultat sind essenziell zwei Informationen enthalten: (1) was sind die getesteten Hypothesen und (2) wie wahrscheinlich es ist, dass das gefundene Resultat eine Folge der Zufallsstichprobenziehung ist. Was hier noch fehlt ist eine Angabe darüber, wie gross die praktische Relevanz dieses Testresultates ist.

Um eine solche Relevanz zu messen wurde der Begriff der Effektstärke eingeführt. Eine Effektstärke ist eine Zahl ohne Einheit (Meter, Franken, ...), welche unabhängig von der Stichprobengrösse ist und nahe bei null liegt, wenn die Nullhypothese nicht abgelehnt wurde.

Wird im Vermögensbeispiel \@ref(exm:vermoegen) die Differenz zwischen geschätztem Erwartungswert und hypothetischem Erwartungswert 
$$\bar{x} - \mu = `r round(exm_vermoegen$x_mean)` \text{CHF} - `r exm_vermoegen$mu0` \text{CHF}  = `r round(exm_vermoegen$x_mean)-exm_vermoegen$mu0`$$
betrachtet, so fällt auf, dass dieser Wert bereits zwei der oben genannten Eigenschaften aufweist. Tatsächlich ist dieser Wert unabhängig von der Stichprobengrösse und er liegt nahe bei $0$, wenn das Testresultat nicht signifikant war. Letzteres kann beobachtet werde indem in der Formel \@ref(eq:t-emp-onesample) verschiedene Differenzen eingesetzt werden und mit der Abbildung  \@ref(fig:t-distribution) verglichen werden. 

<!-- Discuss: how? -->

Wenn jetzt ein anderer Sozialpsychologe die Auswertung wiederholen würde, aber statt in CHF in Rappen Rp rechnet, dann erhält er den Wert
$$\bar{x} - \mu = `r 100*round(exm_vermoegen$x_mean)` \text{Rp} - `r exm_vermoegen$mu0*100` \text{Rp}  = `r (round(exm_vermoegen$x_mean)-exm_vermoegen$mu0)*100`.$$
Dass mit den gleichen Zahlen je nach Einheit eine andere Effektstärke gefunden wird, ist unpraktisch für den Vergleich der Testresultate. Die Lösung in diesem Fall ist diese Differenz durch die geschätzte Standardabweichung zu rechnen. Dies ergibt

- in CHF: $d = \frac{\bar{x} - \mu}{s} = \frac{`r round(exm_vermoegen$x_mean)` \text{CHF} - `r exm_vermoegen$mu0` \text{CHF}}{`r round(exm_vermoegen$x_sd)`\text{CHF}}  = `r round((round(exm_vermoegen$x_mean)-exm_vermoegen$mu0)/round(exm_vermoegen$x_sd),2)`$
- in Rp: $d = \frac{\bar{x} - \mu}{s} = \frac{`r 100*round(exm_vermoegen$x_mean)` \text{Rp} - `r exm_vermoegen$mu0*100` \text{Rp}}{`r 100*round(exm_vermoegen$x_sd)`\text{Rp}}  = `r round((round(exm_vermoegen$x_mean)-exm_vermoegen$mu0)/round(exm_vermoegen$x_sd),2)` .$

Mit dieser Formel werden für beide Einheiten derselbe Wert berechnet. Effektiv dient jetzt als Einheit die Standardabweichung: Eine grosse Differenz bei einer grossen Standardabweichung des Merkmals führt zur selben Effektstärke wie eine kleine Differenz bei kleiner Standardabweichung eines Merkmals. Da Menschen sich nicht gewohnt sind Zahlen als Standardabweichungen zu interpretieren hat [@cohen1988] folgende Richtwerte entwickelt:

- $|d| \approx 0.3$: schwacher Effekt
- $|d| \approx 0.5$: mittlerer Effekt
- $|d| \approx 0.8$: starker Effekt

<!-- Discuss: 0.5 bedeutet die Differenz ist eine halbe standardabweichung gross. -->

Cohen selbst hat davor gewarnt diese Werte als absolut darzustellen. Vielmehr sollte die Interpretation der Effektstärke vom Forschungsgebiet und dem Messinstrument abhängen. Um im Unterricht eine beurteilbare Praxis zu etablieren, sollen folgende Regeln gelten:

- $0 < |d| \leq 0.4$: schwacher Effekt
- $0.4 < |d| \leq 0.65$: mittlerer Effekt
- $0.65 < |d|$: starker Effekt

<!-- Discuss absoluter Wert -->

Das Berichten der Testresultate wird mit der Effektstärke ergänzt:

> Ein Einstichproben-$t$-Test ergibt, dass das durchschnittliche Vermögen ($M = `r round(exm_vermoegen$x_mean)`$ CHF, $SD = `r round(exm_vermoegen$x_sd)`$, $N = `r round(exm_vermoegen$n)`$) in diesem Jahr nicht signifikant grösser als $100'000$ CHF ist, $t(`r round(exm_vermoegen$n-1)`) = `r round(exm_vermoegen$t_emp,3)`$, $p = `r round(exm_vermoegen$p_value_the,3) %>% str_sub(start = 2L)`, d = `r round(exm_vermoegen$effect_size,2)`$.

> Ein Einstichproben-$t$-Test ergibt, dass die durchschnittliche Alexithymie ($M = `r round(exm_alexithymie$x_mean,1)`$ Punkte, $SD = `r round(exm_alexithymie$x_sd,1)`$, $N = `r round(exm_alexithymie$n)`$) sich bei den unter 25-jährigen signifikant vom Populationsdurchschnitt von $100$ Punkten unterscheidet, $t(`r round(exm_alexithymie$n-1)`) = `r round(exm_alexithymie$t_emp,3)`$, $p = `r round(exm_alexithymie$p_value_the,3) %>% str_sub(start = 2L)`, d = `r round(exm_alexithymie$effect_size,2)`$.

In beiden Fällen liegt ein schwacher Effekt vor. Der Effekt bei der Alexithymie ist schwächer als der Effekt bei der Vermögensstudie. Der $p$-Wert sagt aber aus, dass der Effekt beim Vermögen durch die Zufallsstichprobe zustande gekommen ist, während es bei der Alexithymie unwahrscheinlich ist, dass der Effekt durch die Zufallsstichprobe zustande gekommen ist.

## Testvoraussetzungen

Damit der Einstichproben-$t$-Test durchgeführt werden dürfen, müssen einige Voraussetzungen eingehalten werden.

1. Das Merkmal muss intervallskaliert sein.
2. Die Beobachtungen müssen einer Zufallsstichprobe der Population entsprechen.
3. Die Beobachtungen müssen einer Normalverteilung entstammen oder die Anzahl der Beobachtungen muss gross genug sein. Häufig wird die Faustregel mehr als $30$ Beobachtungen verwendet.

## Übungen

::: {.exercise  #vermoegen}
<!-- 
Ziel: 
- Zahlen aus den Vermögen-Beispiel mit Jamovi verknüpfen.
-->
Reproduziere das Beispiel Vermögen \@ref(exm:vermoegen) mit `Jamovi` indem folgende Teilschritte durchgeführt werden:

- Datensatz `r inline_code(exm_vermoegen$file_name)` in `Jamovi` einladen.
- Wähle `Analysen > t-Tests > t-Test mit einer Stichprobe`.
- Definiere die Hypothese wie im Beispiel und wähle die Testoptionen so, dass du alle Zahlen des Testberichts wiederfindest.

:::

:::{.solution}
```{r sol-vermoegen-input, out.width='100%', fig.cap='Jamovi Eingabe.', fig.show='hold'}
knitr::include_graphics("figures/05-exr-vermoegen-jmv-input.jpg")
```

```{r sol-vermoegen-output, out.width='100%', fig.cap='Testresultat Einstichproben-t-Test und deskriptive Statistiken.', fig.show='hold'}
knitr::include_graphics("figures/05-exr-vermoegen-jmv-output.jpg")
```  
:::

::: {.exercise  #alexithymie}
<!-- 
Ziel: 
- Zahlen aus den Alexithymie-Beispiel mit Jamovi verknüpfen.
-->
Reproduziere das Beispiel Alexithymie \@ref(exm:alexithymie) mit `Jamovi` indem folgende Teilschritte durchgeführt werden:

- Datensatz `r inline_code(exm_alexithymie$file_name)` in `Jamovi` einladen.
- Wähle `Analysen > t-Tests > t-Test mit einer Stichprobe`.
- Definiere die Hypothese wie im Beispiel und wähle die Testoptionen so, dass du alle Zahlen des Testberichts wiederfindest.
:::

:::{.solution}
```{r sol-alexithymie-input, out.width='100%', fig.cap='Jamovi Eingabe.', fig.show='hold'}
knitr::include_graphics("figures/05-exr-alexithymie-jmv-input.jpg")
```

```{r sol-alexithymie-output, out.width='100%', fig.cap='Testresultat Einstichproben-t-Test und deskriptive Statistiken.', fig.show='hold'}
knitr::include_graphics("figures/05-exr-alexithymie-jmv-output.jpg")
```  
:::


::: {.exercise  #circadian}
<!-- 
Ziel: 
- Erster eigener Test selbstständig durchführen
- Zweiseitiger Test
- Signifikanz begreifen
-->

```{r exr-circadian}
gen_exr_circadian <- function(){
  set.seed(1982)
  mu0 <- 24
  n <- 57
  
  x <- rnorm(n, 24.5, 2) 
  # x %>% summary()
  # x %>% t.test(alternative = 'two.sided',
  #              mu = mu0)
  x_mean <- x %>% mean()
  x_mean_sym <- mu0 + (mu0 - x_mean)
  x_sd <- x %>% sd()
  t_emp <- (x_mean - mu0)/(x_sd/sqrt(n))
  p_value_the <- 2*(1-pt(abs((x_mean - mu0)/ (x_sd / sqrt(n))), n-1))
  effect_size <- (x_mean - mu0) / x_sd
  
  file_name <- '05-exr-circadian.sav'
  tibble(tageslaenge = x) %>% write_sav(file_name)
  
  return(mget(ls()))
}
exr_circadian <- gen_exr_circadian()
```

Es soll überprüft werden, ob der 24-stündige Tagesrhythmus, auch _zirkadianer Rhythmus_ genannt, des Menschen auch ohne Tageslicht aufrechterhalten wird. Eine solche Untersuchung wird von @czeisler1999 berichtet. Wir gehen von folgendem fiktiven Versuch aus:  Freiwillige werden für vier Tage in einer Kellerwohnung ohne jedes Tageslicht einquartiert. Jede Versuchsperson ist während der vier Tage allein, darf die Wohnung nicht verlassen und erhält keinerlei Hinweise auf die aktuelle Tageszeit. Die Person muss unmittelbar vor dem Zu-Bett-Gehen, einen Knopf betätigen, wodurch die Uhrzeit festgehalten wird. Als Variable wird die Dauer der `tageslaenge` (in Stunden) zwischen dem Zu-Bett-Gehen am dritten Versuchstag und dem Zu-Bett-Gehen am vierten Versuchstag verwendet. Die erhobenen Daten sind in `r inline_code(exr_circadian$file_name)` abgelegt.

a) Ohne einen Test durchzuführen, haben die Proband:innen einen anderen zirkadianen Rhythmus als Menschen die nicht am Experiment teilnehmen? Weshalb es hier sinnvoll ist einen statistischen Test zu verwenden?
b) Stellen Sie mit einem Einstichproben-t-Test fest, ob der zirkadiane Rhythmus durch das Tageslicht beeinflusst wird. Stellen Sie insbesondere die Hypothesen auf und berichten Sie das Testresultat adäquat.
c) Erklären Sie alle Zahlen und Symbole im Testbericht.
:::

:::{.solution}
Für diese Übung werden die Daten in `Jamovi` wie in Abbildung \@ref(fig:sol-circadian-input) analysiert. Das Resultat der Analyse ist in Abbildung \@ref(fig:sol-circadian-output) festgehalten.

```{r sol-circadian-input, out.width='100%', fig.cap='Jamovi Eingabe.'}
knitr::include_graphics("figures/05-exr-circadian-jmv-input.jpg")
```

```{r sol-circadian-output, out.width='100%', fig.cap='Jamovi Ausgabe.'}
knitr::include_graphics("figures/05-exr-circadian-jmv-output.jpg")
``` 

a) Die Versuchpersonen haben einen durchschnittlichen zirkadianen Rhythmus von $M = `r round(exr_circadian$x_mean,1)`$ Stunden. Dies ist länger als die regulären $24$ Stunden. Es ist unklar, ob hier gerade zufällig Personen beobachtet wurden bei welche sich der zirkadiane Rhytmus verlängert. Um die Wahrscheinlichkeit dieses Zufalls zu quantifizieren wird ein statistischer Test durchgeführt.
b) Die Nullhypothese geht vom aktuell bekannten aus, also in diesem Fall, dass sich der durchschnittliche zirkadiane Rhythmus unter den Versuchsbedinungen nicht verändert. Der normale zirkadiane Rhythmus ist Sonnenbedingt $24$ Stunden lang, also wird die Nullhypothese $H_0: \mu = 24$ Stunden aufgestellt. $\mu$ ist hier die durchschnittiche Dauer des zirkadianen Rhythmus in der Population. Im Versuch geht es darum festzustellen, ob der normale zirkadiane Rhythmus gehalten wird oder nicht. Ein nicht gehaltener zirkadianer Rhythmus würde bedeuten, dass sich die Tagesdauer verkürzt oder verlängert gegenüber der Nullhypothese. Es ist hier also eine zweiseitige Hypothesenstellung und die Alternativhypothese lautet $H_1: \mu \neq 24$ Stunden.

> Ein Einstichproben-$t$-Test ergibt, dass die durchschnittliche Tageslänge ($M = `r round(exr_circadian$x_mean,1)`$ Stunden, $SD = `r round(exr_circadian$x_sd,1)`$, $N = `r round(exr_circadian$n)`$) unter Experimentalbedingungen  sich signifikant von $24$ Stunden unterscheidet, $t(`r round(exr_circadian$n-1)`) = `r round(exr_circadian$t_emp,2)`$, $p = `r round(exr_circadian$p_value_the,3) %>% str_sub(start = 2L)`, d = `r round(exr_circadian$effect_size,3)`$.

c) $M, SD,$ und $N$ sind das arithmetische Mittel, die geschätzte Standardabweichung und die Anzahl Beobachtungen der Stichprobe. $p$ ist die Wahrscheinlichkeit, zufällig den Stichprobenmittelwert oder einen noch extremeren Wert im Sinne der Alternativehypothese zu beobachten, falls die Nullhypothese stimmt. Dieser Wert ist kleiner als $5\%$. Deswegen wird von einem signifikanten Unterschied der durchschnittlichen Tageslänge zum Erwartungswert gesprochen. $24$ Stunden ist der Vergleichswert der Nullhypothese. $t(`r round(exr_circadian$n-1)`)$ bedeutet, dass die Teststatistik $t$-verteilt ist mit `r exr_circadian$n-1` Freiheitsgraden, sofern die Nullhypothese wahr ist. Mit der aktuellen Stichprobenziehung wurde ein Wert von $`r round(exr_circadian$t_emp,2)`$ realisiert. Dieser Wert ist mit der $t$-Verteilung in Abbildung \@ref(fig:t-distribution) zu vergleichen. Der Wert entspricht einer eher unwahrscheinlichen Beobachtung dieser Verteilung. $d = `r round(exr_circadian$effect_size,3)`$, schliesslich, bezieht sich auf die Effektstärke. Das Testresultat entspricht einem mittleren Effekt.
:::

::: {.exercise  #schwimmen}
<!-- 
Ziel: 
- Gerichtete Hypothese kleiner als ein Wert
-->

```{r exr-schwimmen}
gen_exr_schwimmen <- function(){
  set.seed(1982)
  mu0 <- 1.58
  n <- 13
  
  x <- rnorm(n, 1.50, 0.8) 
  x %>% summary()
  x %>% t.test(alternative = 'less',
               mu = mu0)
  x_mean <- x %>% mean()
  x_mean_sym <- mu0 + (mu0 - x_mean)
  x_sd <- x %>% sd()
  t_emp <- (x_mean - mu0)/(x_sd/sqrt(n))
  p_value_the <- pt(t_emp, n-1)
  effect_size <- (x_mean - mu0) / x_sd
  
  file_name <- '05-exr-schwimmen.sav'
  dd <- tibble(kraul_zeit = x) 
  dd %>% write_sav(file_name)
  jmv_res <- (dd %>% 
    jmv::ttestOneS(vars = 'kraul_zeit', 
                   testValue = 1.58, 
                   hypothesis = 'lt', desc = TRUE,
                   effectSize = TRUE))
  jmv_res_test <- jmv_res$ttest$asDF %>% 
    rename_with(~ .x %>% str_remove('\\[stud\\]'))
  jmv_res_desc <- jmv_res$descriptives$asDF
  
  return(mget(ls()))
}
exr_schwimmen <- gen_exr_schwimmen()
```

Im Schwimmclub Neustadt erreichen neue Schwimmer nach einem Jahr Training eine Kraul-Schwimmzeit von durchschnittlich $`r exr_schwimmen$mu0`$ Minuten für $100$ Meter. Eine Sportstudentin will eine neue Trainingsmethode ausprobieren und herausfinden, ob die Methode bessere Ergebnisse erzielt. Dazu trainiert neue Schwimmer ein Jahr lang mit dieser Methode und misst anschliessend deren Kraul-Schwimmzeit über $100$ Meter. Die Daten sind in `r inline_code(exr_schwimmen$file_name)` abgelegt.

a) Wie viele Schwimmer hat die Sportstudentin trainiert?
b) Ist die neue Trainingsmethode besser als die bisherige? Erklären Sie die Signifikanz und Relevanz des Experimentresultats.
:::

:::{.solution}
Für diese Übung werden die Daten in `Jamovi` wie in Abbildung \@ref(fig:sol-schwimmen-input) analysiert. Das Resultat der Analyse ist in Abbildung \@ref(fig:sol-schwimmen-output) festgehalten.

```{r sol-schwimmen-input, out.width='100%', fig.cap='Jamovi Eingabe.'}
knitr::include_graphics("figures/05-exr-schwimmen-jmv-input.jpg")
```

```{r sol-schwimmen-output, out.width='100%', fig.cap='Jamovi Ausgabe.'}
knitr::include_graphics("figures/05-exr-schwimmen-jmv-output.jpg")
```

a) Die Sportstudentin hat $N = `r exr_schwimmen$jmv_res_desc$num`$ Schwimmer trainiert.
b) Die Forschungsfrage ist hier, ob die neue Trainingsmethode besser ist. Besser meint hier, dass die mit dieser Trainingsmethode trianierten Schwimmer nach dem Training durchschnittlich schneller schwimmen als die anderen. Die Alternativhypothese ist also $H_1: \mu < `r exr_schwimmen$mu0`$. Die Nullhypothese sagt genau das Gegenteil davon aus, nämlich, dass die durchschnittliche Schimmzeit mit der neuen Methode gleich bleibt oder sogar noch länger wird $H_0: \mu \geq `r exr_schwimmen$mu0`$. Das Testresultat lässt sich wie folgt berichten:

> Ein Einstichproben-$t$-Test ergibt, dass die durchschnittliche Schwimmzeit ($M = `r round(exr_schwimmen$jmv_res_desc$mean,2)`$ Minuten, $SD = `r round(exr_schwimmen$jmv_res_desc$sd,2)`$, $N = `r exr_schwimmen$jmv_res_desc$num`$) mit der neuen Trainingsmethode nicht signifikant tiefer als $`r exr_schwimmen$mu0`$ Minuten ist, $t(`r exr_schwimmen$jmv_res_test$df`) = `r round(exr_schwimmen$jmv_res_test$stat,2)`$, $p = `r round(exr_schwimmen$jmv_res_test$p,3) %>% str_sub(start = 2L)`, d = `r round(exr_schwimmen$jmv_res_test$es,3)`$.

Das Testresultat ist nicht signifikant, da der $p$-Wert grösser als $5\%$ ist. Tatsächlich bedeutet $p = `r round(exr_schwimmen$jmv_res_test$p,3) %>% str_sub(start = 2L)`$, dass, wenn die Nullhypothese wahr ist, das gefundene Testresultat oder dass die Schwimmer noch schneller sind in $`r round(100*exr_schwimmen$jmv_res_test$p,1)`\%$ zufällig durch die Zufallsstichprobenziehung zustande kommt. Kurz gesagt, das Resulat könnt auch Zufall sein.

Die gefundene Effektstärke ist mittel. Wenn das Resultat nicht zufällig wäre, dann würde die Trainingsmethode immerhin einen mittleren Effekt erzielen. Wenn es tatsächlich einen mittleren Effekt gibt, dann könnte die Sportstudentin das Experiment nochmal mit mehr Probanden wiederholen, um den Effekt auch als statistisch signifikan nachweisen zu können. Falls der gefundene Effekt nur zufällig zustande gekommen ist und er nicht exisitiert, wird auch eine Experimentwiederholung mit mehr Probandinnen immernoch kein signifikantes Testergebnis liefern. 
:::


::: {.exercise  #markpreisanalyse-testen}
<!-- 
Ziel: 
- Ungerichtete Hypothese 
-->

Die Firma Pear bringt ein neues Smartphone das F42 der Reihe Supernova X auf den Markt. Das Smartphone ist für Jugendliche im Alter von $15-20$ Jahre konzipiert. Das Vorgängermodell F41 wurde für durchschnittlich $300$ CHF verkauft. Um herauszufinden, ob sich die durchschnittliche Zahlbereitschaft des neuen Modells von der Zahlbereitschaft für das alte Modell abweicht, erfragt Pear bei $`r exr_marktpreisanalyse$n`$ Jugendlichen die Zahlbereitschaft. Die Daten stehen unter `r inline_code(exr_marktpreisanalyse$file_name)` zur Verfügung. 

a) Stellen Sie die oben formulierte Hypothese mit mathematischer Schreibweise dar.
b) Testen Sie die Hypothese.
c) Berichten Sie die Testergebnisse.
d) Was bedeuten die Werte Statistik, $df$, $p$ und Effektstärke.
e) Der Stichprobenmittelwert liegt tiefer als $300$ CHF. Hätte man bereits hier feststellen können, dass sich die durchschnittliche Zahlungsbereitschaft verändert hat?

:::

:::{.solution}
Für diese Übung werden die Daten in `Jamovi` wie in Abbildung \@ref(fig:sol-marktpreisanalyse-testen-input) analysiert. Das Resultat der Analyse ist in Abbildung \@ref(fig:sol-marktpreisanalyse-testen-output) festgehalten.

```{r sol-marktpreisanalyse-testen-input, out.width='100%', fig.cap='Jamovi Eingabe.'}
knitr::include_graphics("figures/05-exr-marktpreisanalyse-testen-jmv-input.jpg")
```

```{r sol-marktpreisanalyse-testen-output, out.width='100%', fig.cap='Jamovi Ausgabe.'}
knitr::include_graphics("figures/05-exr-marktpreisanalyse-testen-jmv-output.jpg")
```

a) Es gibt zunächst keinen Anhaltspunkt, weshalb sich die Zahlbereitschaft geändert haben sollte. Deshalb ist die Nullhypothese $H_0: \mu = 300$ CHF, wobei $\mu$ für den Erwartungswert des Merkmals Preis ist. Pear fragt sich, ob der $\mu$ von $300$ abweicht, gibt aber keine Richtung vor. Deshalb wurde $H_0$ zweiseitig formuliert. Das Gegenteil der Nullhypothese ist die Alternativhypothese $H_1: \mu \neq 300$ CHF.
b) Das Testen erfolgt wie oben in den Bildschirmaufnahmen von `Jamovi` dargestellt.
c) Ein Einstichproben-$t$-Test ergibt, dass sich die durchschnittliche Zahlbereitschaft ($M=`r round(mean(exr_marktpreisanalyse$tab$preis),2)`$ CHF, $SD = `r round(sd(exr_marktpreisanalyse$tab$preis),2)`$, $N = `r length(exr_marktpreisanalyse$tab$preis)`$) nicht signifikant von $300$ CHF unterscheidet, $t(`r exr_marktpreisanalyse$tab$preis %>% length()-1`)= -0.848, p = .399, d = -0.101$.
d) Statistik entspricht der beobachteten Teststatistik in der Stichprobe. Der Wert kann im Vergleich zur $t$-Verteilung in Abbildung \@ref(fig:t-distribution) gelesen werden. $-0.848$ ist bei allen dargestellten Verteilungen kein seltener Wert, wenn die Nullhypothese stimmt. Dieser Wert der Statistik deutet also nicht darauf hin, dass die Nullhypothese falsch ist. Die Freiheitsgrade $df$ bestimmen die genaue Form der t-Verteilung. In Abbildung \@ref(fig:t-distribution) sind die genauen Formen für $df = 1$, $df = 4$ und $df = 9$ dargestellt. Die $t$-Verteilung, welche die Verteilung der Mittelwerte am besten abbildet ist die mit $df = n-1$, wobei $n$ die Anzahl Beobachtungen ist. Es sind $70$ Beobachtungen gemacht worden, also ist $df = 69$. Die $t$-Verteilung sieht in diesem Fall ungefähr aus wie die Normalverteilung in Abbildung \@ref(fig:t-distribution). Der $p$-Wert von $0.399$ bedeutet, dass die Wahrscheinlichkeit diesen Stichprobenmittelwert oder einen extremeren im Sinne der Alternativhypothese bei $39.9\%$ liegt und damit ziemlich wahrscheinlich ist, gegeben dass die Nullhypohthese wahr ist. Auch dies reflektiert also, dass aufgrund der Stichprobe nicht geschlossen werden kann, dass der Erwartungswert von $300$ CHF abweicht. Die Effektstärke $d= -0.101$ ist gemäss Cohen als schwach einzustufen.
e) Der Stichprobenmittelwert sagt aus, dass in dieser Stichprobe die Zahlungsbereitschaft nicht gleich war wie für das Modell F41. Diese Aussage ist jedoch limitiert auf die Stichprobe und kann nur auf die Population ausgeweitet werden, wenn ein statistischer Test durchgeführt wurde. Es könnte ja sein, dass es einen Unterschied im Populationsmittelwert gibt, dieser aber aufgrund einer seltenen Zufallsstichprobenziehung nicht offenbar wird.
:::

::: {.exercise  #aslkdfjoeiu12342}

<!-- ```{r exr-test-drink-usa} -->
<!-- gen_exr_test_drink_usa <- function(){ -->
<!--   set.seed(1982) -->
<!--   mu0 <- 3 -->
<!--   n <- 15 -->

<!--   x <- rnorm(n, 3.8, 1.4)  -->
<!--   file_name <- '05-exr-test-drink-usa.sav' -->
<!--   dd <- tibble(fluessigkeit_liter = x)  -->
<!--   dd %>% write_sav(file_name) -->
<!--   jmv_res <- (dd %>%  -->
<!--     jmv::ttestOneS(vars = 'fluessigkeit_liter',  -->
<!--                    testValue = mu0,  -->
<!--                    hypothesis = 'gt', desc = TRUE, -->
<!--                    effectSize = TRUE)) -->
<!--   jmv_res_test <- jmv_res$ttest$asDF %>%  -->
<!--     rename_with(~ .x %>% str_remove('\\[stud\\]')) -->
<!--   jmv_res_desc <- jmv_res$descriptives$asDF -->

<!--   return(mget(ls())) -->
<!-- } -->
<!-- exr_test_drink_usa <- gen_exr_test_drink_usa() -->
<!-- ``` -->

TODO
:::

:::{.solution}
TODO
:::

## Test

::: {.exercise  #test-theorie}
Welche der folgenden Aussagen zum Einstichproben-$t$-Test sind wahr, welche falsch?

a) Der Einstichproben-$t$-Test überprüft, ob der Stichprobenmittelwert einer bestimmten Zahl entspricht.
b) Beim Einstichproben-$t$-Test ist die Teststatistik $t$-verteilt mit $n-1$ Freiheitsgraden.
c) Der $p$-Wert ist immer kleiner als das Signifikanzniveau.
d) $H_1: \mu > 50$ ist eine mögliche Formulierung für die Alternativhypothese des Einstichproben-$t$-Test.
:::

:::{.solution}
a) Falsch
b) Richtig
c) Falsch
d) Richtig
:::

::: {.exercise  #test-drink-usa}

```{r exr-test-drink-usa}
gen_exr_test_drink_usa <- function(){
  set.seed(1982)
  mu0 <- 3
  n <- 15
  
  x <- rnorm(n, 3.8, 1.4) 
  file_name <- '05-exr-test-drink-usa.sav'
  dd <- tibble(fluessigkeit_liter = x) 
  dd %>% write_sav(file_name)
  jmv_res <- (dd %>% 
    jmv::ttestOneS(vars = 'fluessigkeit_liter', 
                   testValue = mu0, 
                   hypothesis = 'gt', desc = TRUE,
                   effectSize = TRUE))
  jmv_res_test <- jmv_res$ttest$asDF %>% 
    rename_with(~ .x %>% str_remove('\\[stud\\]'))
  jmv_res_desc <- jmv_res$descriptives$asDF
  
  return(mget(ls()))
}
exr_test_drink_usa <- gen_exr_test_drink_usa()
```

In der Schweiz wird empfohlen $3$ Liter Flüssigkeit pro Tag zu sich zu nehmen. Auf einer Reise in die USA fragt Karin zufällige Leute nach ihrer Flüssigkeitsaufnahme. Die Daten notiert sie im Datensatz `r inline_code("05-exr-drink-usa")`. Sie will nun testen, ob alle Leute in den USA durchschnittlich mehr Flüssigkeit pro Tag zu sich nehmen, als es in der Schweiz empfohlen ist. Testen Sie die Hypothese einem Einstichproben-$t$-Test, stellen Sie dabei `Jamovi` auf $3$ Nachkommastellenrundung ein. Welche der folgenden Aussagen sind wahr, welche falsch.

a) Die durchschnittliche Flüssigkeitsaufnahme ist in den USA signifikant grösser als in der Schweiz empfohlen.
b) Der gefundene Effekt ist gemäss Cohen als gross einzustufen.
c) Karin hat $14$ Personen befragt.
d) Die Nullhypothese lautet $H_0: \mu \leq 3$ Liter.
:::

:::{.solution}
a) Richtig
b) Falsch
c) Falsch
d) Richtig
:::

::: {.exercise  #98zvh3blbel}

<!-- ```{r exr-test-drink-usa} -->
<!-- gen_exr_test_drink_usa <- function(){ -->
<!--   set.seed(1982) -->
<!--   mu0 <- 3 -->
<!--   n <- 15 -->

<!--   x <- rnorm(n, 3.8, 1.4)  -->
<!--   file_name <- '05-exr-test-drink-usa.sav' -->
<!--   dd <- tibble(fluessigkeit_liter = x)  -->
<!--   dd %>% write_sav(file_name) -->
<!--   jmv_res <- (dd %>%  -->
<!--     jmv::ttestOneS(vars = 'fluessigkeit_liter',  -->
<!--                    testValue = mu0,  -->
<!--                    hypothesis = 'gt', desc = TRUE, -->
<!--                    effectSize = TRUE)) -->
<!--   jmv_res_test <- jmv_res$ttest$asDF %>%  -->
<!--     rename_with(~ .x %>% str_remove('\\[stud\\]')) -->
<!--   jmv_res_desc <- jmv_res$descriptives$asDF -->

<!--   return(mget(ls())) -->
<!-- } -->
<!-- exr_test_drink_usa <- gen_exr_test_drink_usa() -->
<!-- ``` -->

TODO
:::

:::{.solution}
TODO
:::
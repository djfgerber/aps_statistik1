# Durchschnitt und Standardabweichung schätzen

```{r prep_example, echo = FALSE}
set.seed(1928)
m <- 1000
n <- 30
means <- map_dbl(1:m, ~ mean(rnorm(n, 30, 10)))
lb <- round(unname(quantile(means, 0.025)),1)
ub <- round(unname(quantile(means, 0.975)),1)
a <- 1
b <- 7
n1 <- 100
means1 <- map_dbl(1:m, ~ mean(runif(n1, a, b)))
lb1 <- round(unname(quantile(means1, 0.025)),1)
ub1 <- round(unname(quantile(means1, 0.975)),1)
```

Wie die in Abschnitt \@ref(stichprobenziehung-lösung) erklärte Lösung für das Problem der zufälligen Stichprobe konkret gemacht werden muss hängt von der Problemstellung ab. 

## Wo liegt der Durchschnitt der Grundgesamtheit?

Ein Parameter über welchen wir gerne eine Aussage treffen würden ist die zentrale Tendenz in der Grundgesamtheit. Diese wird **Erwartungswert** (Symbol $\mu$ [gr.: mü]) genannt. Wenn das arithmetische Mittel der Stichprobe berechnet wird, ergibt dies auch ein Schätzwert für besagten Erwartungswert. Aufgrund der zufälligen Stichprobenziehung ist jedoch auch klar, dass dieser Schätzwert nie genau dem wahren Erwartungswert entspricht. 

Die Folgefrage ist also wie genau unsere Schätzung ist. Um dies zu quantifizieren, wiederholen wir die Stichprobenziehung und berechnen das arithmetische Mittel dieser zweiten Stichprobe. Dann wiederholen wir diesen Prozess, zum Beispiel `r m` mal.

```{r hist-mean-estimation, echo = FALSE, fig.cap = "Verteilung der arithmetischen Mittel von 1000 zufällig gezogenen Stichproben der Zustandsangst."}
tibble(x = means) %>% 
  ggplot(aes(x=x))+
  geom_histogram(binwidth = 0.5)+
  labs(y = 'Häufigkeit', x = 'Zustandsangst')
```

Die Häufigkeitsverteilung der berechneten arithmetischen Mittelin Abbildung \@ref(fig:hist-mean-estimation) lässt nun Aussage über die Häufigkeit und damit über die Wahrscheinlichkeit von gewissen Werten als Erwartungswert zu. Ein Durchschnittswert der Zustandesangst um die 30 ist hier am wahrscheinlichsten und ein Wert tiefer als 27 oder höher 33 eher selten. Um diese Schätzung wissenschaftlicher präziser zu gestalten, werden konventionell die 95% häufigsten Werte (die höchsten Balken im Histogramm) als wahrscheinlich betrachtet. Die 5% verbleibenden Werte, verteilt auf das untere und obere Extrem, werden als unwahrscheinlich betrachtet. Das 2.5% Perzentil trennt die 2.5% tiefsten arithmetischen Mittel ab und liegt im Beispiel bei `r lb`. Das 97.5.5%-Perzentil trennt die höchsten 2.5% (oder eben die tiefsten 97.5%) arthmetischen Mittel ab  und liegt bei `r ub`. 

```{r hist-mean-estimation1, fig.cap = "Verteilung der arithmetischen Mittel von 1000 zufällig gezogenen Stichproben der Zustandsangst."}
tibble(x = means) %>% 
  mutate(color = if_else(means < lb | means > ub, "green", "red")) %>% 
  ggplot(aes(x=x, fill = color, color = "black"))+
  geom_histogram(binwidth = 0.5)+
  geom_vline(xintercept = lb)+
  geom_vline(xintercept = ub)+
  labs(y = 'Häufigkeit', x = 'Zustandsangst')+
  theme(legend.position = "none")
```

TODO: explain example 2 likert scale


```{r hist-mean-estimation2, fig.cap = "TODO: Verteilung der arithmetischen Mittel von 1000 zufällig gezogenen Stichproben der Zustandsangst."}
tibble(x = means1) %>% 
  mutate(color = if_else(means1 < lb1 | means1 > ub1, "green", "red")) %>% 
  ggplot(aes(x=x, fill = color, color = "black"))+
  geom_histogram(binwidth = 0.05)+
  geom_vline(xintercept = lb1)+
  geom_vline(xintercept = ub1)+
  xlim(c(3,5))+
  labs(y = 'Häufigkeit', x = 'TODO')+
  theme(legend.position = "none")
```
TODO: explain quantiles.

Das Problem mit diesem Vorgehen ist, dass es aus finanziellen oder technischen Gründen selten möglich ist mehrere Stichproben aus derselben Population zu ziehen. Glücklicherweise haben Statistiker:innen herausgefunden, dass die Häufigkeitsverteilungen wie in Abbildungen \@ref(fig:hist-mean-estimation1) und \@ref(fig:hist-mean-estimation2) immer dieselbe Verteilung haben und dies unabhängig davon wie die ursprüngliche Verteilung des Merkmals aussah. Diese Verteilung ist eine sogenannte **Normalverteilung**. 

Die Normalverteilung sieht eine Glocke ähnlich. Deshalb wird sie auch Gausssche Glockenkurve nach Carl F. Gauss (1777-1855) benannt. Die Normalverteilung kann mit nur zwei Parametern beschrieben werden. 

- $\mu_g$ gibt an, wo auf der x-Achse der höchste Punkt der Glocke liegt
- $\sigma_g$ gibt an, wie flach die Glockenform ist (ein grosser Wert entspricht einer flachen Glockenform, ein tiefer Wert einer steilen Glockenform).

Auf [seeing-theory.brown.edu > Continuous > Normal](https://seeing-theory.brown.edu/probability-distributions/index.html#section2) kann der Einfluss von $\mu$ und $\sigma$ auf die Normalverteilung erfahren werden. 

Diese Tatsache, dass die Durchschnitte aller Merkmale normalverteilt sind, ist so zentral für die Statistik, dass sie **Zentraler Grenzwertsatz** genannt wurde. Der zentrale Grenzwertsatz besagt geneauer, dass bei einem Merkmal mit Erwartungswert $\mu$ und Standardabweichung $\sigma$, der Durchschnitt aller Stichprobenwerte einer Normalverteilung mit $\mu_g = \mu$ und $\sigma_g = \frac{\sigma}{\sqrt{n}}$ entspricht, wobei $n$ die Stichprobengrösse bezeichnet.

:::{.remark}
- $\mu_g = \mu$ bedeutet, dass der Wert, welcher unter der normalverteilung am wahrscheinlichsten ist, genau dem Erwartungswert des untersuchten Merkmales entspricht.
- $\sigma_g = \frac{\sigma}{\sqrt{n}}$ hat zwei Implikationen:
  - je grösser die Streuung des Merkmals (grosses $\sigma$) desto breiter ist auch die Streuung der arithmetischen Mittel (grosses $\sigma_g$). Dies bedeutet, je weniger Streuung das Merkmal aufweist, desto genauer ist die Bestimmung des Erwartungswertes des Merkmales.
  - je grösser die Anzahl Beobachtungen $n$, desto kleiner die Streuung der arithmetischen Mittel (kleines $\sigma_g$). Dies bedeutet, je grösser die Stichprobe ist, desto genauer ist die Bestimmung des Erwartungswertes des Merkmales.
:::

Die Abbildungen \@ref(fig:normal-approx) und \@ref(fig:normal-approx1) illustrieren den zentralen Grenzwertsatz für Beispiel 1 und 2 respektive. Dabei wird einstweilen angenommen, dass $\mu$ und $\sigma$ bekannt sind. Diese Annahme wird später aufgelöst und dient hier lediglich der Illustration.

```{r normal-approx, fig.cap = "Die arithmetischen Mittel sind Normalverteilt mit Parametern $\\mu_g = 30$ und $\\sigma_g = 10 / \\sqrt{30}$."}
s <- sqrt(100)
t_curve = tibble(
    x = seq(23,37, by = 0.01),
   y = dt((x - 30) / (s/sqrt(n)), n-1)/ (s/sqrt(n)))
bell_curve = tibble(x = seq(23,37, by = 0.01),
       y = dnorm(x, 30, sqrt(100/n)),
       color = "black")
tibble(x = means) %>%
  ggplot() +
  geom_histogram(aes(x = x, y = after_stat(density)), binwidth = 0.5) +
  geom_vline(xintercept = lb) +
  geom_vline(xintercept = ub) +
  geom_line(
    data = bell_curve,
    aes(x = x, y = y),
    colour = "#f12489",
    linewidth = 1.5
  ) +
  geom_line(
    data = t_curve,
    aes(x = x, y = y),
    colour = "#038992",
    linewidth = 2, 
    linetype = "dotted"
  ) +
  labs(y = 'Wahrscheinlichkeitsdichte', x = 'TODO') +
  theme(legend.position = "none")
```

```{r normal-approx1, fig.cap = "Die arithmetischen Mittel sind Normalverteilt mit Parametern $\\mu_g = 4$ und $\\sigma_g = 1.73 / \\sqrt{100}$."}
s1 <- sqrt((b-a)^2/12)
bell_curve = tibble(x = seq(3, 5, by = 0.01),
       y = dnorm(x, (b+a)/2, s1/sqrt(n1)))
t_curve = tibble(
    x = seq(3, 5, by = 0.01),
   y = dt((x - (b+a)/2) / (s1/sqrt(n1)), n1-1)/ (s1/sqrt(n1)))
tibble(x = means1) %>%
  ggplot() +
  geom_histogram(aes(x = x, y = after_stat(density)), binwidth = 0.05) +
  geom_vline(xintercept = lb1) +
  geom_vline(xintercept = ub1) +
  geom_line(
    data = bell_curve,
    aes(x = x, y = y),
    colour = "#f12489",
    linewidth = 2
  ) +
  geom_line(
    data = t_curve,
    aes(x = x, y = y),
    colour = "#038992", 
    linetype = "dotted",
    linewidth = 2
  ) +
  labs(y = 'Wahrscheinlichkeitsdichte', x = 'TODO') +
  theme(legend.position = "none")
```

Die Erkenntnis des zentralen Grenzwertsatz macht also das wiederholte ziehen von Stichproben unnötig. Die Normalverteilung ist theoretisch konstruiert und ihr 2.5%- und 97.5%-Perzentil können theoretisch hergeleitet werden. Tabelle \@ref(tab:quantiles-norm) wird kann beobachtet werden, dass für unsere zwei Beispiele die Perzentile der Stichprobe und der Normalverteilung sehr ähnlich, wenn auch nicht exakt gleich sind. Die Ungenauigkeit rührt daher, dass der zentrale Grenzwertsatz nur dann exakt funktioniert, wenn die Anzahl Beobachtungen (unendlich) gross ist.

```{r quantiles-norm}
tibble(
  Beispiel= c(1,2),
  "2.5%-Perzentil (Stichprobe)"= c(lb, lb1),
  "97.5%-Perzentil (Stichprobe)"= c(ub, ub1),
  "2.5%-Perzentil (Normalverteilung)"= c(qnorm(0.025, 30, sqrt(100/n)), qnorm(0.025, (b+a)/2, sqrt(((b-a)^2/12)/n1))),
  "97.5%-Perzentil (Normalverteilung)"= c(qnorm(0.975, 30, sqrt(100/n)), qnorm(0.975, (b+a)/2, sqrt(((b-a)^2/12)/n1)))
) %>% knitr::kable(caption = "Vergleich Perzentile der Stichprobe und der theoretischen Verteilung.")
```

Einstweilen wurde hier angenommen, dass die Streuung des Merkmals $\sigma$ bekannt ist. Dies ist in der Realität nie der Fall. Wenn $\sigma$ also auch aus der Stichprobe geschätzt werden muss, ist die Verteilung der arthmetischen Mittel 

$$ \bar{x} - \frac{\sigma}{\sqrt{n}} \cdot z_{2.5\%} < \mu < \bar{x} - \frac{\sigma}{\sqrt{n}} \cdot z_{2.5\%}$$



## Wo liegt der Durchschnitt der Standardabweichung?

## Übungen

# Durchschnitt und Standardabweichung schätzen

```{r 4-prep_example, include=FALSE}
m <- 1000L
a <- 1
b <- 7
n1 <- 100
x1 <- runif(n1, a, b)
means1 <- map_dbl(1:m, ~ mean(runif(n1, a, b)))
sds1 <- map_dbl(1:m, ~ sd(runif(n1, a, b)))
lb1 <- round(unname(quantile(means1, 0.025)), 1)
ub1 <- round(unname(quantile(means1, 0.975)), 1)
m_means1 <- a+(b - a) / 2
s_means1 <- sqrt(((b - a) ^ 2 / 12) / n1)
lb1_t <- m_means1 - qt(0.975, n1 - 1) * s_means1
ub1_t <- m_means1 + qt(0.975, n1 - 1) * s_means1
```

Wie die in Abschnitt \@ref(stichprobenziehung-loesung) skizzierte Lösung für das Problem der zufälligen Stichprobe konkret umgesetzt wird, hängt von der Problemstellung ab. Im folgenden wird ein Verfahren zur Generalisierung der Schätzung der zentralen Tendenz 
<!-- und eines für die Schätzung der Variabilität  -->
basierend auf einer Stichprobe präsentiert.

## Wo liegt der Durchschnitt der Grundgesamtheit?

Ein Parameter über welchen wir gerne eine Aussage treffen würden ist die zentrale Tendenz in der Grundgesamtheit. [Diese wird **Erwartungswert** (Symbol $\mu$ [gr.: mü]) genannt.]{.customdef #customdef-erwartungswert} Wenn das arithmetische Mittel der Stichprobe berechnet wird, ergibt dies auch ein Schätzwert für besagten Erwartungswert. Aufgrund der zufälligen Stichprobenziehung ist jedoch auch klar, dass dieser Schätzwert nie genau dem wahren Erwartungswert entspricht. 

In Beispiel \@ref(exm:angst) liegt das arithmetische Mittel in der Stichprobe der Studierenden bei $M=`r exm_angst$x_mean`$. Dieser Wert entspricht nun auch der Schätzung des Erwartungswertes, also der geschätzten durchschnittlichen Angst aller Menschen. Die Folgefrage ist also wie genau unsere Schätzung ist. Um dies zu quantifizieren, wiederholen wir die Stichprobenziehung und berechnen das arithmetische Mittel dieser zweiten Stichprobe. Dann wiederholen wir diesen Prozess, zum Beispiel $`r exm_angst$n_samples`$ mal.

```{r exm-angst-hist-means, echo = FALSE, fig.cap = paste("Verteilung der arithmetischen Mittel von", exm_angst$n_samples, "zufällig gezogenen Stichproben der Angst.")}
tibble(x = exm_angst$x_means) %>% 
  ggplot(aes(x=x))+
  geom_histogram(binwidth = 0.5)+
  labs(y = 'Häufigkeit', x = 'Angst')
```

Die Häufigkeitsverteilung der berechneten arithmetischen Mittel in Abbildung \@ref(fig:exm-angst-hist-means) lässt nun Aussage über die Häufigkeit und damit über die Wahrscheinlichkeit von gewissen Werten als Erwartungswert zu. Ein Durchschnittswert der Zustandesangst um die 30 ist hier am wahrscheinlichsten und ein Wert tiefer als $27$ oder höher $33$ eher selten. Um diese Aussage präziser zu gestalten, werden konventionell die $95$% häufigsten Werte (die höchsten Balken im Histogramm) als wahrscheinlich betrachtet. Die $5$% verbleibenden Werte, verteilt auf das untere und obere Extrem, werden als unwahrscheinlich betrachtet. Das $2.5$% Perzentil trennt die $2.5$% tiefsten arithmetischen Mittel ab und liegt im Beispiel bei $`r  exm_angst$lb_means_emp`$. Das $97.5$%-Perzentil trennt die höchsten $2.5$% (oder eben die tiefsten $97.5$%) arthmetischen Mittel ab und liegt bei $`r exm_angst$ub_means_emp`$. Dies ist in Abbildung \@ref(fig:exm-angst-hist-means-emp-ci) ersichtlich.


```{r exm-angst-hist-means-emp-ci, fig.cap = paste0("Verteilung der arithmetischen Mittel von ",exm_angst$n_samples," zufällig gezogenen Stichproben der Angst.")}
plot_hist_means(exm_angst$x_means, exm_angst$lb_means_emp,  exm_angst$ub_means_emp, 0.5, 'Angst')
```

:::{.example #agreableness name="Verträglichkeit"}
Einer der Big-5 Persönlichkeitszüge ist die Verträglichkeit. Eine einfache Art die Big-5 zu messen ist mit den 10 Fragen aus dem ten-item personality inventory _TIPI_ [@gosling2003]. Für die Verträglichkeit müssen zwei Items (Item 1: Critical, quarrelsome; Item 2: Sympathetic, warm) auf einer Likert-Skala von 1 bis 7 eingeordnet werden. Anschliessend werden die Antworten gemittelt. Ein Student möchte herausfinden, ob mit diesem Messinstrument die durchschnittliche Verträglichkeit aller Menschen mittig also bei $4$ liegt. Dafür befragt er $n = `r n1`$ Personen und findet die Werte $M=`r round(mean(x1), 2)`, s = `r round(sd(x1),2)`$.
:::

```{r exm-agreableness-hist, fig.cap = paste("Verteilung der", n1, "beobachteten Verträglichkeitswerte einer zufällig gezogenen Stichprobe.")}
tibble(x = x1) %>% 
  ggplot(aes(x=x))+
  geom_histogram(binwidth = 0.5)+
  labs(y = 'Häufigkeit', x = 'Verträglichkeit')
```

Die Verteilung der Beobachtungen, siehe Abbildung \@ref(fig:exm-agreableness-hist), zeigt, dass alle Werte zwischen $1$ und $7$ vorkommen, aber keine zentrale Tendenz greifbar ist. Um herauszufinden wie zutreffend die Schätzung des Erwartungswertes der Verträglichkeit von $M=`r round(mean(x1), 2)`$ ist, stelle man sich wieder vor, dass der Student $`r m`$-mal die Stichprobenziehung wiederholt und jedes mal das arithmetische Mittel $M$ von neuem berechnet. Die Verteilung der arithmetischen Mittel dieser Stichproben ist in Abbildung \@ref(fig:exm-agreableness-hist-means) dargestellt. Bei dieser Verteilung kann erneut links und rechts $2.5\%$ der Werte abgeschnitten werden, um zum Schluss zu gelangen, dass das arithmetische Mittel in $95\%$ der Fälle zwischen $`r lb1`$ und $`r ub1`$ zu liegen kommt.

```{r exm-agreableness-hist-means, fig.cap = paste0("Verteilung der arithmetischen Mittel von ",m," zufällig gezogenen Stichproben der Verträglichkeit.")}
plot_hist_means(means1, lb1, ub1, 0.05, "Verträglichkeit")
```

Das Problem mit diesem Vorgehen ist, dass es aus finanziellen oder technischen Gründen selten möglich ist mehrere Stichproben aus derselben Population zu ziehen. Glücklicherweise haben Statistiker:innen herausgefunden, dass die Häufigkeitsverteilungen wie in Abbildungen \@ref(fig:exm-angst-hist-means-emp-ci) und \@ref(fig:exm-agreableness-hist-means) immer dieselbe Verteilung haben und dies unabhängig davon wie die ursprüngliche Verteilung des Merkmals aussah. [Diese Verteilung ist eine sogenannte **Normalverteilung**]{.customdef #customdef-normalverteilung}. 

Die Normalverteilung sieht eine Glocke ähnlich. Deshalb wird sie auch Gausssche Glockenkurve nach Carl F. Gauss (1777-1855) benannt. Die Normalverteilung kann mit nur zwei Parametern beschrieben werden. 

- $\mu_g$ gibt an, wo auf der x-Achse der höchste Punkt der Glocke liegt
- $\sigma_g$ gibt an, wie flach die Glockenform ist (ein grosser Wert entspricht einer flachen Glockenform, ein tiefer Wert einer steilen Glockenform).

Auf [seeing-theory.brown.edu > Continuous > Normal](https://seeing-theory.brown.edu/probability-distributions/index.html#section2) kann der Einfluss von $\mu$ und $\sigma$ auf die Normalverteilung erfahren werden. 

[Diese Tatsache, dass die Durchschnitte aller Merkmale normalverteilt sind, ist so zentral für die Statistik, dass sie **Zentraler Grenzwertsatz** genannt wurde.]{.customdef #customdef-zentraler-grenzwertsatz} Der zentrale Grenzwertsatz besagt geneauer, dass bei einem Merkmal mit Erwartungswert $\mu$ und Standardabweichung $\sigma$, der Durchschnitt aller Stichprobenwerte einer Normalverteilung mit $\mu_g = \mu$ und $\sigma_g = \frac{\sigma}{\sqrt{n}}$ entspricht, wobei $n$ die Stichprobengrösse bezeichnet.

::::{.caution data-latex=""}
:::{.remark}

- $\mu_g = \mu$ bedeutet, dass der Wert, welcher unter der normalverteilung am wahrscheinlichsten ist, genau dem Erwartungswert des untersuchten Merkmales entspricht.
- $\sigma_g = \frac{\sigma}{\sqrt{n}}$ hat zwei Implikationen:
  - je grösser die Streuung des Merkmals (grosses $\sigma$) desto breiter ist auch die Streuung der arithmetischen Mittel (grosses $\sigma_g$). Dies bedeutet, je weniger Streuung das Merkmal aufweist, desto genauer ist die Bestimmung des Erwartungswertes des Merkmales.
  - je grösser die Anzahl Beobachtungen $n$, desto kleiner die Streuung der arithmetischen Mittel (kleines $\sigma_g$). Dies bedeutet, je grösser die Stichprobe ist, desto genauer ist die Bestimmung des Erwartungswertes des Merkmales.
:::
::::

Die Abbildungen \@ref(fig:exm-angst-normal-approx) und \@ref(fig:exm-agreableness-normal-approx) illustrieren den zentralen Grenzwertsatz für Beispiel \@ref(exm:angst) und \@ref(exm:agreableness) respektive, wobei die Normalverteilung der roten Linie entspricht. Dabei wird einstweilen angenommen, dass $\mu$ und $\sigma$ bekannt sind. Diese Annahme wird später aufgelöst und dient hier lediglich der Illustration.

```{r exm-angst-normal-approx, fig.cap = paste0("Die arithmetischen Mittel sind Normalverteilt mit Parametern $\\mu_g = ",round(mean(exm_angst$x),2),"$ und $\\sigma_g = ",round(sd(exm_angst$x),2)," / \\sqrt{",exm_angst$n,"}$.")}
plot_hist_denstiy_expected_value(exm_angst$x_means, exm_angst$x_mean, exm_angst$x_sd, exm_angst$n, "Angst", 0.5)
```

```{r exm-agreableness-normal-approx, fig.cap = paste0("Die arithmetischen Mittel sind Normalverteilt mit Parametern $\\mu_g = ",round(mean(x1),2),"$ und $\\sigma_g = ",round(sd(x1),2)," / \\sqrt{",n1,"}$.")}
plot_hist_denstiy_expected_value(means1, 4, sqrt((b - a) ^ 2 / 12), n1, "Verträglichkeit", 0.05)
```

Die Erkenntnis des zentralen Grenzwertsatz macht also das wiederholte ziehen von Stichproben unnötig. Die Normalverteilung ist theoretisch konstruiert und ihr $2.5\%$- und $97.5\%$-Perzentil können theoretisch hergeleitet werden. Tabelle \@ref(tab:quantiles-norm) wird kann beobachtet werden, dass für unsere zwei Beispiele die Perzentile der Stichprobe und der Normalverteilung sehr ähnlich, wenn auch nicht exakt gleich sind. Die Ungenauigkeit rührt daher, dass der zentrale Grenzwertsatz nur dann exakt funktioniert, wenn die Anzahl Beobachtungen (unendlich) gross ist.


```{r quantiles-norm}
(tibble(
  Beispiel = c("Angst", "Vertraeglichkeit"),
  "2.5%-Perzentil (sample)" = c(exm_angst$lb_means_emp, lb1),
  "97.5%-Perzentil  (sample)" = c(exm_angst$ub_means_emp, ub1),
  "2.5%-Perzentil norm" = c(qnorm(0.025, exm_angst$m_means, exm_angst$s_means), 
                            qnorm(0.025, m_means1, s_means1)),
  "97.5%-Perzentil norm" = c(qnorm(0.975, exm_angst$m_means, exm_angst$s_means), 
                               qnorm(0.975, m_means1, s_means1)),
  "2.5%-Perzentil t" = c(exm_angst$lb_means_t, lb1_t),
  "97.5%-Perzentil t" = c(exm_angst$ub_means_t, ub1_t)
) %>%
  kableExtra::kbl(
    booktabs = TRUE,
    col.names = c("Beispiel","2.5%", "97.5%", "2.5%", "97.5%", "2.5%", "97.5%"),
    digits = 2,
    align = c("c", "r", "r", "r", "r"),
    caption = "Vergleich Perzentile der Stichprobe und der theoretischen Verteilung."
  )) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = FALSE
  ) %>% 
  add_header_above(c(" " = 1, 
                     "Stichprobe" = 2, 
                     "Normalverteilung" = 2, 
                     "t-Verteilung" = 2))

```


Einstweilen wurde hier angenommen, dass die Streuung des Merkmals $\sigma$ bekannt ist. Dies ist in der Realität nie der Fall und eine weitere, wenn auch weniger grosse Ungenauigkeitsquelle. [Wenn $\sigma$ also auch aus der Stichprobe geschätzt werden muss, ist die Ännäherung der Verteilung der arithmetischen Mittel besser gegeben mit einer **Student-$t$-Verteilung** oder kurz $t$-Verteilung.]{.customdef #customdef-student-verteilung} Die grüne gestrichtelte Linie in den Abbildungen \@ref(fig:exm-angst-normal-approx) und \@ref(fig:exm-agreableness-normal-approx) entspricht der $t$-Verteilung im jeweiligen Beispiel. 

Der Unterschied zwischen der Normalverteilung und der $t$-Verteilung ist nur sichtbar, wenn $n$ klein ist. In Beispiel \@ref(exm:angst) mit $n = `r exm_angst$n`$ ist ein kleiner Unterschied, in Beispiel \@ref(exm:agreableness) mit $n = `r n1`$ ist kein Unterschied zwischen der Normalverteilung und der $t$-Verteilung sichtbar. [Tatsächlich wird die $t$-Verteilung mit einem Parameter charaktisiert, welcher __Freiheitsgrade__ (eng. degrees of freedom, $df$) genannt wird.]{.customdef #customdef-freiheitsgrade} In Abbildung \@ref(fig:t-distribution) wird die $t$-Verteilung mit verschiedenen Freiheitsgraden mit der Normalverteilung verglichen. Bei der $t$-Verteilung mit den kleinsten Freiheitsgraden sind extremere Werte wahrscheinlicher als $t$-Verteilungen mit grösseren Freiheitsgraden. 

```{r t-distribution, fig.cap="Student-t-Verteilungen mit 1, 4 und 9 Freiheitsgraden im Vergleich zu der Normalverteilung."}
tibble(x = seq(-4, 4, by = 0.1),
       Normalverteilung = dnorm(x),
       t_1 = dt(x, 2-1),
       t_4 = dt(x, 5-1),
       t_9 = dt(x, 10-1)) %>%
  pivot_longer(cols = 2:5, names_to = "Verteilung", values_to="Wahrscheinlichkeitsdichte") %>% 
  ggplot(aes(x=x))+
  geom_line(aes(y=Wahrscheinlichkeitsdichte, color = Verteilung))+
  labs(x="")
```

Die Freiheitsgrade der $t$-Verteilung in der Annäherung oben entsprechen der Anzahl Beobachtungen minus 1, also $df = n-1$. Die höhere Wahrscheinlichkeit von extremeren Werten bei kleinen Freiheitsgraden spiegelt die grössere Unsicherheit der Schätzung des Erwartungswertes wieder, wenn die Standardabweichung unbekannt und damit auch geschätzt werden muss. Je kleiner $n$ ist, desto stärker fällt diese Unsicherheit aus.

Die arithmetischen Mittel bei unbekannter Standardabweichung sind bei wiederholter Stichprobenziehung genau $t$-verteilt. Um die Genauigkeit der Schätzung des Erwartungswertes zu bestimmen genügt es folglich, das 2.5% und das 97.5% Perzentil der $t$-Verteilung mit $n-1$ Freiheitsgraden zu bestimmen. Diese Perzentile können mit 

$$ \bar{x} - \frac{s}{\sqrt{n}} \cdot t_{97.5\%, n-1} < \mu < \bar{x} + \frac{s}{\sqrt{n}} \cdot t_{97.5\%, n-1}$$

berechnet werden, wobei $\bar{x}$ das arithmetische Mittel, $s$ die Standardabweichung und $t_{97.5\%, n-1}$ dem Wert des 97.5%-Perzentil einer auf 0 zentrierten $t$-Verteilung mit $n-1$ Freiheitsgraden entspricht. Letzere Perzentile der $t$-Verteilung können bei Bedarf in entsprechenden Tabellen nachgeschlagen werden. Als Gedankenstütze kann für $t_{97.5\%, n-1}$ immer $2$ gedacht werden, da dies ungefähr dem wahren Wert entspricht, wenn $n$ grösser als $50$ ist.

Das $2.5\%$ und das $97.5\%$ Perzentil der Verteilung der arithmetischen Mittel ergeben nun die untere respektive obere Schranke eines [**Intervalles**. Ein Intervall bezeichnet durch die Symbolik $[$untere Schranke, obere Schranke$]$ beinhaltet alle Zahlen zwischen der unteren und der oberen Schranke.]{.customdef #customdef-interval} [Ein Intervall mit den oben beschriebenen Perzentilen als Schranken wurde so berechnet, dass bei wiederhohlter Stichprobenziehung der wahre Erwarungswert in $95\%$ der Fälle umschlossen wird. Grob übersetzt bedeutet dies, dass wir zu $95\%$ sicher oder _konfident_ sind, dass der Erwarungswert in diesem Intervall liegt. Dieses Intervall wird deshalb als $95\%$-**Konfidenzintervall** (Symbol KI) bezeichnet.]{.customdef #customdef-confidence-interval}

In Beispiel \@ref(exm:angst), kann aus der Tabelle \@ref(tab:quantiles-norm) entnommen werden, dass die Angst in der Population bei $M = `r round(mean(exm_angst$x),2)`$ $95\%$ KI $[`r round(exm_angst$lb_means_t,2)`,`r round(exm_angst$ub_means_t,2)`]$ liegt. In Beispiel \@ref(exm:agreableness), kann aus der Tabelle \@ref(tab:quantiles-norm) entnommen werden, dass die Verträglichkeit in der Population bei $M = `r round(mean(x1), 2)`$ $95\%$ KI $[`r round(lb1_t,2)`,`r round(ub1_t,2)`]$ liegt. Wann immer eine Schätzung eines zentralen Wertes berichtet wird, soll dies ab jetzt in der soeben gezeigten Darstellung inklusive Angabe des Konfidenzintervalls erfolgen. Damit wird der Leserin aufgezeigt, wo der Schätzwert der zentralen Tendenz liegt und gleichzeigtig wird intuitiv vermittelt wie genau die Schätzung ist.

Es ist nun spannend zu explorieren, wie sich die Stichprobengrösse $n$ oder die geschätzte Standardabweichung $s$ auf die Länge des Konfidenzintervalls auswirkt. Dies kann in den Übungen \@ref(exr:ki-mean-n-vary) und \@ref(exr:ki-mean-s-vary) selbst erforscht werden.

<!-- ## Wo liegt die Standardabweichung? -->


<!-- This is probably wrong. Skip the chapter? -->
<!-- ```{r} -->

<!-- x_range <- seq(min(sds^2), max(sds^2), by = 0.1) -->
<!-- chisq_curve = tibble( -->
<!--   x = x_range, -->
<!--   y = dchisq(x/((ex_angst_sd^2)/(n-1)), n - 1) * (m) -->
<!-- ) -->

<!-- tibble(x = sds^2) %>% -->
<!--   ggplot(aes(x = x))+ -->
<!--   geom_histogram(binwidth = 2) + -->
<!--   geom_line( -->
<!--       data = chisq_curve, -->
<!--       aes(x = x, y = y), -->
<!--       colour = "#f12489", -->
<!--       linewidth = 1 -->
<!--     ) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- x_range <- seq(min(sds1^2), max(sds1^2), by = 0.05) -->
<!-- ex_agreableness_sd <- sqrt((b-a)^2 / 12) -->

<!-- chisq_curve = tibble( -->
<!--   x = x_range, -->
<!--   y = dchisq(x * (n1-1) / (ex_agreableness_sd^2), n1 - 1) * (n1-1) / (ex_agreableness_sd^2) -->
<!-- ) -->

<!-- tibble(x = sds1^2) %>% -->
<!--   ggplot(aes(x = x))+ -->
<!--   geom_histogram(binwidth = bw, aes(y = after_stat(density))) + -->
<!--   geom_line( -->
<!--       data = chisq_curve, -->
<!--       aes(x = x, y = y), -->
<!--       colour = "#f12489", -->
<!--       linewidth = 1 -->
<!--     ) -->
<!-- ``` -->

## Übungen

::: {.exercise #marktpreisanalyse}
<!-- 
Ziel: 
- Konfidenzintervall mit Jamovi berechnen und berichten
-->
```{r exr-marktpreisanalyse}
gen_exr_marktpreisanalyse <- function(){
  set.seed(234)
  n <- 70
  tab <- tibble(preis = rchisq(n, 10)*30)
  file_name <- '04-exr-marktpreisanalyse.sav'
  tab %>%
    write_sav(file_name)
  return(mget(ls()))
} 
exr_marktpreisanalyse <- gen_exr_marktpreisanalyse()
```

Die Firma Pear bringt ein neues Smartphone das F42 der Reihe Supernova X auf den Markt. Das Smartphone ist für Jugendliche im Alter von $15-20$ Jahre konzipiert. Um herauszufinden, welcher Marktpreis für das F42 verlangt werden kann, erfragt Pear bei $`r exr_marktpreisanalyse$n`$ Jugendlichen die Zahlbereitschaft. Die Daten stehen unter `r inline_code(exr_marktpreisanalyse$file_name)` zur Verfügung. Wie gross ist die durchschnittliche Zahlbereitschaft der Jugendlichen? Berichten Sie die Ergebnisse der Marktanalyse mit einem $95\%$-Konfidenzintervall.
:::

:::{.solution}
Der Datensatz wird bei `Jamovi` eingelesen und die  Analyseparameter wie in Abbildung \@ref(fig:sol-marktpreisanalyse-input) gesetzt. Die Nachkommastellen können im Menu oben rechts bei den drei vertikalen Punkten eingestellt werden.


```{r sol-marktpreisanalyse-input, out.width='100%', fig.cap='Jamovi setzen der Analyseparameter.'}
knitr::include_graphics("figures/04-exr-marktpreisanalyse-jmv-input.jpg")
```

Dies produziert das Analyseergebnis in Abbildung \@ref(fig:sol-marktpreisanalyse-output).

```{r sol-marktpreisanalyse-output, out.width='100%', fig.cap='Jamovi Ausgabe.'}
knitr::include_graphics("figures/04-exr-marktpreisanalyse-jmv-output.jpg")
```

Die Marktanalyse mit $N = 70$ Befragten hat ergeben, dass Jugendliche im Alter von $15-20$ Jahren bereit sind durchschnittlich $M = 288.34$ CHF $95\%$-KI $[260.92,315.76]$ auszugeben für das neue Supernova X F42 von Pear.
:::

::: {.exercise #stranger}
<!-- 
Ziel: 
- Konfidenzintervall mit Jamovi berechnen, interpretieren und berichten
-->
```{r exr-stranger}
gen_exr_stranger <- function(){
  set.seed(234)
  n <- 421
  s <- 0.21
  tab <- tibble(vorher = rnorm(n, 3.78, s),
         nachher = rnorm(n, 3.34, s))
  file_name <- '04-exr-stranger.sav'
  tab %>%
    write_sav(file_name)
  return(mget(ls()))
} 
exr_stranger <- gen_exr_stranger()
```

In einer Studie werden $`r exr_stranger$n`$ Probandinnen über eine Woche lang beauftragt immer wieder fremde Personen anzusprechen. Dabei wird unter anderem am Anfang und am Ende der Woche gemessen, wie unangenehm auf einer Skala von $1$ bis $5$ dies für die Probandinnen ist. Die Daten stehen unter `r inline_code(exr_stranger$file_name)` zur Verfügung. Verwenden Sie für drei Nachkommastellen in `Jamovi` für die folgenden Teilaufgaben.

(a) Berechnen Sie das $95\%$-Konfidenzintervall für die durchschnittliche Unangenehmheit in der Grundgesamtheit für die Situation am Anfang und am Ende der Studie und berichten und interpretieren Sie das Resultat. Denken Sie die Intervention hat die Unangenehmheit, welche durch das Ansprechen von Fremden entsteht, in der Grundgesamtheit durchschnittlich gesenkt? 
(b) Vergleichen Sie die Längen der errechneten Konfidenzintervalle. 
(c) Wiederholen Sie die Aufgabe und berechnen Sie jetzt das $90\%$ und das $99\%$-Konfidenzintervall. Wie verhält sich die Länge des Konfidenzintervalls bei unterschiedlichen Vertrauenswahrscheinlichkeiten?

Diese Aufgabe ist angelehnt an @sandstrom2022.
:::

:::{.solution}
Der Datensatz wird bei `Jamovi` eingelesen und die  Analyseparameter wie in Abbildung \@ref(fig:sol-stranger-input) gesetzt. Die Nachkommastellen können im Menu oben rechts bei den drei vertikalen Punkten eingestellt werden.


```{r sol-stranger-input, out.width='100%', fig.cap='Jamovi setzen der Analyseparameter.'}
knitr::include_graphics("figures/04-exr-stranger-jmv-input.jpg")
```

Dies produziert das Analyseergebnis in Abbildung \@ref(fig:sol-stranger-output).

```{r sol-stranger-output, out.width='100%', fig.cap='Jamovi Ausgabe.'}
knitr::include_graphics("figures/04-exr-stranger-jmv-output.jpg")
```

(a) Die durchschnittliche Unangenehmheit lag am Anfang der Woche bei $M=3.784, 95\%$ KI $[3.764, 3.803]$ Punkten und am ende der Woche bei $M=3.328, 95\%$ KI $[3.309, 3.348]$ Punkten. Wenn die Studie $100$ mal wiederholt wird und jedes mal ein $95\%$ Konfidenzintervall für den Erwartungswert der Unangenehmheit berechnet wird, so wird der tatsächliche Erwartungswert in $95\%$ der Fälle also ungefähr $95$ mal vom Konfidenzintervall überdeckt. Da die Konfidenzintervalle weit auseinander liegen, kann davon ausgegangen werden, dass die Unangenehmheit durchschnittlich tatsächlich nach dem Versuch tiefer liegt als vor dem Versuch. Die Unangenehmheit kann also durch Training vermindert werden.
(b) Die Länge der Konfidenzintervalle betragen am Anfang der Woche $3.803-3.764=0.039$ und am Ende der Woche $3.348-3.309= 0.039$. 
(c) Um das $90\%$ Konfidenzintervall zu berechnen kann in der in Abbildung \@ref(fig:sol-stranger-input) dargestellten Maske der Wert für `Konfidenzintervall für den Mittelwert` auf $90$ gesetzt werden. Die durchschnittliche Unangenehmheit lag am Anfang der Woche bei $M=3.784, 90\%$ KI $[3.767, 3.800]$ Punkten und am ende der Woche bei $M=3.328, 90\%$ KI $[3.312, 3.345]$ Punkten. Die durchschnittliche Unangenehmheit lag am Anfang der Woche bei $M=3.784, 99\%$ KI $[3.758, 3.809]$ Punkten und am ende der Woche bei $M=3.328, 99\%$ KI $[3.303, 3.354]$ Punkten. Die Länge der $90\%$ Konfidenzintervalle ist $3.800-3.767=0.033$ und $3.345-3.312=0.033$. Die Länge der $99\%$ Konfidenzintervalle ist $3.809-3.758=0.051$ und $3.354-3.303=0.051$. Es kann also hier empirisch festgestellt werden, dass das Konfidenzintervall grösser wird, je höher die Vertrauenswahrscheinlichkeit sein soll. 
:::


::: {.exercise #ki-approx-normal}
<!-- 
Ziel: 
- Erleben, dass Mittelwerte normalverteilt sind.
-->

```{r ki-approx-normal}
gen_exr_ki_approx_normal <- function(n){
  seed <- 1928
  set.seed(1928)
  m <- 10000
  lambda <- 7
  x <- rpois(n, lambda)
  x_samples <- map(1:m, ~ rpois(n, lambda))
  means <- x_samples %>% map_dbl(mean)
  sds <- x_samples %>% map_dbl(sd)
  lb <- unname(quantile(means, 0.025))
  ub <- unname(quantile(means, 0.975))
  m_means <- mean(x)
  s_means <- sqrt(sd(x) / n)
  lb_t <- lambda - qt(0.975, n - 1) * s_means
  ub_t <- lambda + qt(0.975, n - 1) * s_means
  return(mget(ls()))
}

ns <- c(10, 40, 100)
list_experiments <- map(ns, ~ gen_exr_ki_approx_normal(.x))
tibble(!!!setNames(
    map(list_experiments,~c(.x$means)),
    paste0("n_", ns)
)) %>%
    haven::write_sav('data/04-exr-zentraler-grenzwertsatz.sav')
```

Für ein Experiment werden in drei Runden jeweils $`r list_experiments[[1]]$m`$ Zufallsstichproben erhoben mit respektive $10$, $40$ und $100$ Beobachtungen pro Zufallsstichprobe. Die Verteilung der jeweils ersten Zufallsstichprobe für eine Stichprobengrösse ist in Abbildung \@ref(fig:ki-approx-normal1) dargestellt. Die Daten sind nicht normalverteilt, weil keine Glockenkurve wie oben beschrieben das Histogramm gut abdecken würde.

```{r ki-approx-normal1, fig.cap="TODO."}
map_dfr(c(1:3),
        ~tibble(x = list_experiments[[.x]]$x_samples[[1]],
       n = list_experiments[[.x]]$n)) %>% 
  ggplot() +
  geom_histogram(aes(x=x), binwidth = 1)+
  facet_wrap(~n,labeller = label_both)+
  labs(x="Wert", y = 'Häufigkeit')
```

Die arithmetischen Mittel der $10'000$ Stichproben sind im Datensatz `04-exr-zentraler-grenzwertsatz.sav` festgehalten. In der Spalte `n_10` zum Beispiel steht jede Zeile für das arithmetische Mittel eine Zufallstichprobe mit $10$ Beobachtungen. Der zentrale Grenzwertsatz besagt, dass diese arithmetischen Mittel normalverteilt sind mit zunehmender Stichprobengrösse $n$. Erstellen Sie ein Histogramm mit der Erweiterung `JJStatsPlot` und zeichnen Sie eine Normalverteilung darüber. Interpretieren Sie das Resultat.

:::

:::{.solution}

Die Übereinanderlegung des jeweiligen Histograms und der Wahrscheinlichkeitsdichte der Normalverteilung wird in Abbildung \@ref(fig:sol-ki-approx-normal) gezeigt. Es ist deutlich zu sehen, dass die Linie nur bei $n=100$ die Häufigkeitsverteilung der arithmetischen Mittel gut nachbilden kann. Bei $n=10$ und $n=50$ ist ein grosser Unterschied zwischen Häufigkeitsverteilung und Linie sichtbar. Das genaue $n$ ab welchem eine Häufigkeitsverteilung gut durch die Normalverteilung angenähert wird hängt von der ursprünglichen Verteilung der Daten ab, d.h. der Verteilung in Abbildung \@ref(fig:ki-approx-normal1). Es kann deshalb nicht generell gesagt werden, dass ab $n=100$ die Annäherung immer gut sei, so wie in diesem Beispiel. Der zentrale Grenzwertsatz besagt demnach auch lediglich, dass man immer ein grosses $n$ wählen kann, so dass die Annäherung gut ist. Er besagt nichts darüber, wie gross $n$ sein muss.

```{r sol-ki-approx-normal, fig.cap="TODO", fig.show="hold", out.width="50%"}
knitr::include_graphics("figures/04-exr-ki-approx-normal-jmv-input.jpg")
knitr::include_graphics("figures/04-exr-ki-approx-normal-jmv-output1.jpg")
knitr::include_graphics("figures/04-exr-ki-approx-normal-jmv-output2.jpg")
knitr::include_graphics("figures/04-exr-ki-approx-normal-jmv-output3.jpg")
```

:::

::: {.exercise #ki-mean-n-vary}
<!-- 
Ziel: 
- 
-->

```{r exr-ki-mean-n-vary}
gen_exr_ki_mean_n_vary <- function(){
  seed <- 1029
  set.seed(seed)
  sample_sizes <- c(5, 20, 50, 100, 1000)
  samples <- sample_sizes %>%
    map(~rexp(.x,4))
  ki_table <- tibble(x = samples,
         n = sample_sizes) %>%
    mutate(
      means = x %>% map_dbl(mean),
           sds = x %>% map_dbl(sd),
           lb = means - qt(0.975, n-1) * sds / sqrt(n),
           ub = means + qt(0.975, n-1) * sds / sqrt(n),
           il = ub - lb)
  tibble(!!!setNames(
      map(ki_table$x, ~c(.x, rep(NA, 1000 - length(.x)))),
      paste0("col_", seq_along(ki_table$x))
  )) %>%
    haven::write_sav('data/04-exr-stichprobengroesse.sav')
  return(mget(ls()))
}

exr_ki_mean_n_vary <- gen_exr_ki_mean_n_vary()
```

Eine Mensa will herausfinden, wie lange die Leute um 12h durchschnittlich anstehen müssen. Dazu befragt sie `r exr_ki_mean_n_vary$ki_table$n[1]` Kund:innen. Das Resultat der Untersuchung ist, dass die Kund:innen im Durchschnitt $0.4$ Stunden anstehen müssen. Leider ist das Konfidenzintervall sehr gross. Da die Mensa nicht weiss, wie viele Leute befragt werden müssen, um ein kleineres Konfidenzintervall zu erhalten befragt sie in 4 weiteren Runden jeweils `r knitr::combine_words(exr_ki_mean_n_vary$ki_table$n[-c(1)], and = " und ", oxford_comma = FALSE)` Kund:innen. Die Daten aller 5 Untersuchungen sind unter `04-exr-stichprobengroesse.sav` abgelegt. Für jede der 5 Stichproben:

  a. Was ist die Schätzung des Erwartungswertes der Wartezeit?
  b. Wie gross ist die Standardabweichung der Wartezeit?
  c. Wie gross ist die Standardabweichung der arithmetischen Mittel?
  d. Bestimmen Sie die 95%-Konfidenzintervalle.
  e. Berechnen Sie die Länge jedes Konfidenzintervalls.

Vergleichen Sie die Resultate der Berechnungen für jede Stichprobe:

  f. Weshalb ist die Schätzung für den Erwartungswert für jede Stichprobe unterschiedlich?
  g. Was lässt sich über den Zusammenhang zwischen Stichprobengrösse und der Länge des Konfidenzintervalls sagen?

:::

:::{.solution}

Abbildung \@ref(fig:sol-ki-mean-n-vary) zeigt die Berechnunganweisungen für Jamovi und die resultierende Tabelle daraus.

```{r sol-ki-mean-n-vary, fig.cap="Links: Jamovi-Anleitung zur Erstellung der Tabelle mit den relevanten Kenngrössen; rechts: Tabelle mit relevanten Kenngrössen.", fig.show="hold", out.width="50%"}
  knitr::include_graphics("figures/04-exr-stichprobengroesse-jmv-input.jpg")
  knitr::include_graphics("figures/04-exr-stichprobengroesse-jmv-output.jpg")
```

  a. Der Erwartungswert der Wartezeiten (das heisst der Populationmittelwerte der Wartezeiten) wird mit dem arithmetischen Mittel der Stichprobe geschätzt und kann in der Tabelle bei `Mittelwert` abgelesen werden. Der Erwartungswert der Wartezeiten beträgt bei allen Stichproben ausser bei der ersten ungefähr 0.22 Stunden, also ein bisschen weniger als eine Viertelstunde.
  b. Der Standardabweichung der Wartezeiten der Stichprobe sind in der Tabelle bei `Std.-abw.` abzulesen. Die Standardabweichungen sind für alle Stichproben ausser der ersten ungefähr bei 0.23.
  c. Die Standardabweichung der arithmetischen Mittel liegt bei $s/\sqrt{n}$. Für die erste Stichprobe ist dies $0.157 / \sqrt{5} = `r 0.157/sqrt(5)`$. Diese Werte werden auch als Standardfehler bezeichnet und sind in der Tabelle bei `Std.-fehler` ablesbar.
  d. Die untere und obere Schranke der 95%-Konfidenzintervalle sind bei `Untere` und `Obere` respektive abzulesen.  
  e. Die Länge des Konfidenzintervalls entspricht jeweils dem höheren Wert minus dem tieferen Wert. Für die erste Stichprobe ist dies 0.597 - 0.208 = `r (0.597 - 0.208)`, für die anderen `r knitr::combine_words(map_dbl(exr_ki_mean_n_vary$ki_table$il[-c(1)], ~ round(.x, 2)), and = " und ", oxford_comma = FALSE)`.
  f. Die Schätzung des Erwartungswertes ist das arithmetische Mittel der Stichprobe. Da jedesmal eine neue Zufallsstichprobe gezogen wurde und diese nicht dieselben Beobachtungen enthalten, ergeben sich auch jedesmal andere Stichprobenmittelewerte.
  g. Je grösser $n$, desto kleiner ist das Konfidenzintervall. Wenn man also ein kleines Konfidenzintervall erreichen will, braucht man eine grössere Stichprobe.
:::



::: {.exercise #ki-mean-s-vary}
<!-- 
Ziel: 
- 
-->
```{r exr-ki-mean-s-vary}
print('hi')
```

:::

:::{.solution}
TODO
:::



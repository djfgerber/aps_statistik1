---
editor_options: 
  markdown: 
    wrap: 72
---

# Zusammenhang dichotomer Merkmale {#vierfelder}

## Zusammenhang dichotomer Merkmale beschreiben

::: {#alcohol-edu .example name="Alkohol und Bildung"}
```{r exm-alcohol-edu}
gen_exm_alcohol_edu <- function(){
  set.seed(212123)
  file_name <- '09-exm-alcohol-edu.sav'
  n <- 1000
  no_risk_tert <- 0.184
  no_risk_other <- 0.234

  p_tert <- round(2313/(2313+2916+892),3)
  
  dd <- tibble(bildung = c(rep("tertiär", p_tert*n),rep("andere", (1-p_tert)*n)),
       alkoholkonsum = c(rep("oft", round((1-no_risk_tert)*n*p_tert,0)), 
                         rep("selten", round(no_risk_tert*n*p_tert, 0)), 
                         rep("oft", round((1-no_risk_other)*n*(1-p_tert))), 
                         rep("selten", round((no_risk_other)*n*(1-p_tert))))) %>% 
    slice_sample(n=nrow(.)) %>% 
    write_sav(file_name)
  jmv_output <- jmv::contTables(
    dd,
    "alkoholkonsum",
    "bildung",
    chiSq = TRUE,
    chiSqCorr = TRUE,
    odds = TRUE,
    relRisk = TRUE,
    diffProp = TRUE, 
    phiCra = TRUE,
    pcCol = TRUE,
    compare = 'columns'
  )
  jmv_output_freq <- jmv_output$freqs$asDF %>% 
    clean_jmv_colnames()
  jmv_output_odds <- jmv_output$odds$asDF %>% 
    clean_jmv_colnames()
  jmv_output_test <- jmv_output$chiSq$asDF %>% 
    clean_jmv_colnames()
  jmv_output_nom <- jmv_output$nom$asDF %>% 
    clean_jmv_colnames()
  return(mget(ls()))
}
exm_alcohol_edu <- gen_exm_alcohol_edu()
```

Vom Bundesamt für Statistik BFS werden regelmässig Daten zum
Alkoholkonsum in der Schweiz erhoben. Dabei wird ermittelt, welcher
Anteil der Bevölkerung weniger als einmal pro Woche und welcher Anteil
mehr als einmal pro Woche Alkohol konsumiert. Diese Anteile werden
anschliessen für verschiedene Untergruppen ausgewiesen, zum Beispiel für
Leute mit Tertiärbildung und anderem Bildungsabschluss. Es werden hier
also zwei dichotome Merkmale (Bildung: Tertiär/nicht Tertiär und
Alkoholkonsum: mind. 1x / Woche, weniger als 1x / Woche) und deren
Zusammenhang betrachtet. Um diese Anteile abzuschätzen werden
$`r exm_alcohol_edu$n`$ Personen befragt. Der Datensatz ist als `r inline_code(exm_alcohol_edu$file_name)` verfügbar.
:::

Im Datensatz wird für jede Person eine Zeile ausgewiesen, siehe
Abbildung \@ref(fig:exm-alcohol-edu-data-view).

```{r exm-alcohol-edu-data-view, out.width='50%', fig.cap='Daten Alkoholkonsum und Bildung.'}
knitr::include_graphics("figures/09-exm-alcohol-edu-data-view.jpg")
```

Da der Mensch nicht besonders gut darin ist unzählige Zeilen eine
Tabelle zu absorbieren, werden die Daten oft in einer Vierfeldertafel
zusammengefasst. [Die **Vierfeldertafel** ist eine Kreuztabelle bei
welcher die Ausprägungen des einen Merkmals als Spalten und des anderen
als Zeilen fungieren.]{#customdef-vierfeldertafel
.customdef} Die Zellen werden dann mit der Anzahl Beobachtungen befüllt,
für welche die Ausprägungskombination im Datensatz zutrifft, siehe
Abbildung \@ref(fig:exm-alcohol-edu-data-view).

```{r exm-alcohol-edu-aggdata-view, out.width='50%', fig.cap='Vierfeldertafel Alkoholkonsum und Bildung..'}
knitr::include_graphics("figures/09-exm-alcohol-edu-aggdata-view.jpg")
```

Im psychologischen und medizinischen Kontext bezieht sich ein Merkmal
oft auf einen schädlichen und einen nicht schädlichen Ausgang. Im
Beispiel ist es der Alkoholkonsum. [Dieses Merkmal wird
**Risikovariable** genannt.]{#customdef-risikovariable
.customdef} In der Vierfeldertafel kann die Risikovariable die Zeilen
oder die Spalten bestimmen. Die Risikovariable wird durch andere
Merkmale sogenannte ursächliche Variablen erklärt. Im breiteren
statistischen Kontext wird die Risikovariable abhängige Variable und die
ursächliche Variable als unabhängige Variable bezeichnet.

[Mit **Risiko** wird die Wahrscheinlichkeit benannt den schädlichen
Ausgang zu erleiden und wird mit dem Anteil des schädlichen Ausgangs an
der Gesamtzahl berechnet.]{#customdef-risiko .customdef}
Das Risiko kann je nach Ausprägung der ursächlichen Variable
unterschiedlich hoch sein. Das Risiko mehr als 1x pro Woche Alkohol zu
konsumieren ist demnach
$308/378 = `r round(308/378,3)` = `r round(100*308/378,1)`\%$ für
Menschen mit tertiärer Ausbildung und
$476/622 = `r round(476/622,3)` = `r round(100*476/622,1)`\%$ für
Menschen mit anderer Ausbildung. Das Risiko kann in `Jamovi` unter
`Zellen > Prozentsätze` und dann `Zeile` (wenn das ursächliche Merkmal
die Zeilen bestimmt) oder `Spalte` (wenn das ursächliche Merkmal die
Spalte bestimmt) angezeigt werden.

Die Risiken für die tertiär und andere Ausbildungen können nun
verglichen werden. [Dazu kann die Differenz der beiden Risiken
sogenannte **Risikodifferenz** (in `Jamovi` unter
`Statistiken > Unterschiede in den Proportionen`) betrachtet
werden.]{#customdef-risikodifferenz .customdef} Wenn die
Risiken der beiden Gruppen mit $p_1$ und $p_2$ bezeichnet werden,
entspricht dies schlicht
$$p_1 - p_2 = `r round(308/378,3)` - `r round(476/622,3)`=`r round(308/378,3)- round(476/622,3)`.$$
Das Risiko mehr als $1$x pro Woche Alkohol zu konsumieren ist also
$`r round(308/378,3)- round(476/622,3)` = `r 100*(round(308/378,3)- round(476/622,3))`\%$
höher für Personen mit einem tertiären Bildungsabschluss. Da die Risiken
immer Werte zwischen $0$ und $1$ sind, muss dieser Formel nach die
Differenz der Risiken zwischen $-1$ und $1$ liegen. Wenn die Differenz
der beiden Risiken $0$ ist, bedeutet dies, dass die Risiken in beiden
Gruppen gleich gross sind. Je weiter die Differenz der Risiken von $0$
weg ist, desto unterschiedlicher sind die Risiken in den zwei Gruppen.

Eine andere Art die Risiken zu vergleichen ist sie ins Verhältnis zu
setzen. [Dies wird **relatives
Risiko**]{#customdef-tagname .customdef}
$$\text{RR} = \frac{p_1}{p_2} = \frac{`r round(308/378,3)`}{ `r round(476/622,3)`}=`r round(round(308/378,3)/ round(476/622,3),3)`$$
genannt. Das Risiko mehr als $1$x pro Woche Alkohol zu konsumieren ist
für Personen mit tertiärer Ausbildung also
$`r round(round(308/378,3)/ round(476/622,3),3)`$ mal so gross wie für
Personen mit anderer Ausbildung. Sind $p_1$ und $p_2$ gleich gross, so
ist das relative Risiko bei $1$. Ist $p_1$ kleiner als $p_2$, so ist das
relative Risiko kleiner als $1$. Ist $p_1$ grösser als $p_2$, so ist das
relative Risiko grösser als $1$. Insgesamt ist das relative Risiko immer
eine Zahl zwischen $0$ und $+\infty$. Das Tauschen der
Gruppennummerierung führt zu einer Umkehr des Wertes rund um $1$. Wenn
im Beispiel also die andere Bildung als Gruppe $1$ bezeichnet würde, so
ist das relative Risiko
$$\text{RR} = \frac{p_1}{p_2} = \frac{`r round(476/622,3)`}{ `r  round(308/378,3)`}=`r round(  round(476/622,3)/round(308/378,3),3)`$$

:::: {.caution data-latex=""}
::: remark
Das hier die relativen Risiken für die Gruppenneunummerierung fast
gleich weit von $1$ entfernt liegen ist im Normalfall nicht so. Dies
kann an folgendem Zahlenbeispiel gesehen werden: $0.75 / 0.25 = 3$ und
umgekehrt $0.25/0.75 = 0.333$.
:::
::::

Das relative Risiko sagt im Gegensatz zu Risikodifferenz nichts mehr
über das absolute Risiko aus. Wenn ein Medikament, zum Beispiel das
Risiko einer Psychose von $1$ aus $5000$ auf $1$ aus $10000$ reduziert,
so ist die Risikodifferenz bei $0.0001 - 0.0002 = -0.01\%$. Das relative
Risiko ist in dem Fall jedoch $0.0001/0.0002 = 50\%$. Wird nun nur das
relative Risiko berichtet, könnten Lesende von einem zu grossen Nutzen
des Medikaments ausgehen. Es wird deshalb empfohlen immer die
Risikodifferenz und das relative Risiko zu berichten.

Die Risikodifferenz und das relative Risiko können nur berechnet werden,
wenn die gesamt Anzahl Fälle repräsentativ für die Population ist. Dies
ist bei Fall-Kontroll Studien nicht der Fall, wie folgendes Beispiel
zeigt. Für solche Studien können weder die Risikodifferenz noch das
relative Risiko sinnvoll berechnet werden.

::: {#dog-cancer .example name="Krebs bei Hunden"}
```{r exm-dog-cancer}
gen_exm_dog_cancer <- function(){
  set.seed(23)
  
  n <- 375

  file_name <- '09-exm-dog-cancer.sav'
  dd <- tibble(Hund = c("Tumor", "Kein Tumor", "Tumor", "Kein Tumor"),
               Herbizid = c("Angewendet", "Angewendet", "Nicht Angewendet", "Nicht Angewendet"),
               Anzahl = c(191,304,300,641)) %>% 
  write_sav(file_name)
  return(mget(ls()))
}
exm_dog_cancer <- gen_exm_dog_cancer()
```

@hayes1991 haben sich für den Zusammenhang zwischen malignen Lymphomen
bei Hunden (ugs. bösartiger Lymphdrüsenkrebs) und der Anwendung des
Herbizids $2, 4$-Dichlorphenoxyessigsäure in Hausgärten interessiert.
Dabei haben Sie in einer Fall-Kontroll Studie (case-control study) die
Zahlen im Datensatz `r inline_code(exm_dog_cancer$file_name)` ermittelt.
:::

Die Daten sind hier bereits in aggregierten Fallzahlen präsentiert,
siehe Abbildung \@ref(fig:exm-dog-cancer-data-view).

```{r exm-dog-cancer-data-view, out.width='50%', fig.cap='Daten Malignes Lymphoma bei Hunden.'}
knitr::include_graphics("figures/09-exm-dog-cancer-data-view.jpg")
```

Um diese Daten korrekt in `Jamovi` einzulesen, kann unter
`Analysen > Häufigkeiten > Kreuztabellen > Unabhängige Stichproben` die
Anzahl Fälle bei `Anzahl (optional)` eingelesen werden. Dies resultiert
in der Vierfeldertafel in Abbildung
\@ref(fig:exm-dog-cancer-aggdata-view).

```{r exm-dog-cancer-aggdata-view, out.width='50%', fig.cap='Vierfeldertafel Malignes Lymphoma bei Hunden.'}
knitr::include_graphics("figures/09-exm-dog-cancer-aggdata-view.jpg")
```

Case-control bedeutet, dass Hunde mit Tumor (Fall/case) in einer
Tierklinik gegeben waren. Dazu wurde eine gewisse Anzahl (normalerweise
zwischen $1$ bis $4$ mal so viele wie kranke) gesunde Hunde
(Kontroll/control) zufällig ausgewählt. Bei allen Hunden wurde
anschliessend ermittelt, ob die Hunde auf einem mit dem entsprechenden
Herbizid belasteten Garten Zeit verbracht haben. Da von den
Studienautoren bestimmt wurde, wie viele gesunde Hunde ermittelt werden,
kann der Anteil der kranken Hunde nicht als Mass für das Vorkommen der
Erkrankung in der jeweiligen Gruppe dienen. Es ist hier also nicht
aussagekräftig den Anteil kranker Hunde pro Gruppe oder das daraus
folgende relative Risiko zu bestimmen.

[Stattdessen wird in diesen Fällen das **Chancenverhältnis** (eng. odds
ratio)]{#customdef-odds-ratio .customdef}\
$$OR =\frac{\frac{a}{c}}{\frac{b}{d}} = \frac{a\cdot d}{b\cdot c} = \frac{191\cdot 641}{300\cdot 304} = 1.34$$
berechnet, wobei $a, b, c$ und $d$ den Anzahl Fällen in der
Vierfeldertafel von oben nach unten und von links nach rechts
entsprechen. [Die **Chance** (eng. odds) ist dabei eine Art
Wahrscheinlichkeit auszudrücken.]{#customdef-odds
.customdef} Sie ist definiert als Wahrscheinlichkeit, dass ein Ereignis
eintrifft geteilt durch die Wahrscheinlichkeit, dass das Ereignis nicht
eintrifft. Für die Herbizid belasteten Hunde ist die Chance ein Tumor zu
haben also $a/c=191/304=0.63$ und für die anderen Hunde
$b/d=300/641=0.47$. Es gilt, je höher die Chance desto höher die
Eintreffwahrscheinlichkeit. Ein Chancenverhältnis von $1.34$
schliesslich bedeutet, dass die Chance einen Tumor zu entwickeln für
einen Herbizid belasteten Hund $1.34$-mal so hoch ist wie für einen
nicht Herbizid belasteten.

:::: {.caution data-latex=""}
::: remark
-   Es kann festgestellt werden, dass das Chancenverhältnis unabhängig
    von der Wahl der ursächlichen und Risikovariable ist
    $$ OR = \frac{a\cdot d}{b\cdot c} = \frac{a\cdot d}{c\cdot b}.$$
-   Für kleine Fallzahlen (Risiko $<10\%$) liegt das Chancenverhältnis
    nahe am relativen Risiko.
-   Das Chancenverhältnis lässt, wie das relative Risiko, keinen Schluss
    über das absolute Risiko zu.
:::
::::

## Zusammenhang dichotomer Merkmale testen

In `Jamovi > Analysen > Häufigkeiten > Kreuztabellen > Unabhängige Stichproben > Statistiken > Tests` stehen verschiedene Tests zur Verfügung, um zu testen, ob ein in einer Zufallsstichprobe
gefundener Zusammenhang zwischen den Risiken $p_1$ und $p_2$ auf die
Risiken in der Population $\pi_1$ und $\pi_2$ (sprich 'pi') übertragen
werden darf.

### $z$-Test für den Unterschied zwischen den zwei Anteilen

Wenn die Merkmale unabhängig voneinander sind, dann sollte das Risiko in
beiden Gruppen ungefähr gleich gross sein. Dies impliziert auch, dass
die Risikodifferenz $0$ ist. Beim $z$-Test für den Unterschied zwischen
den zwei Anteilen wird also $H_0: \pi_1 - \pi_2 = 0$ und damit
äquivalent $H_0: \pi_1 = \pi_2$ getestet. Wird die Nullhypothese
verworfen, wird fortan an die Alternativhypothese
$H_1: \pi_1 \neq \pi_2$ geglaubt. Aus Platzgründen werden hier nur die
zweiseitigen Hypothesenstellungen erwähnt. Die einseitigen
Hypothesenstellungen funktionieren aber anaolg zu den bisher gesehen
Tests.

Die Teststatistik für den $z$-Test der Risikodifferenz ist

$$z = \frac{p_1-p_2}{\sqrt{\frac{p_1(1-p_1)}{n_1}+\frac{p_2(1-p_2)}{n_2}}} = -1.85,$$

wobei $n_1$ und $n_2$ der Anzahl vom Risiko betroffene bzw. nicht
betroffene Beobachtungen darstellen. Wenn die Nullhypothese wahr ist,
ist diese Teststatistik ist standardnormalverteilt. Dies entspricht der
Normalverteilung in Abbildung \@ref(fig:t-distribution). Je grösser die
Differenz der beiden Risiken, desto weiter weg von $0$ ist die
Teststatistik und desto unwahrscheinlicher ist es, dass die berechnete
Teststatistik aufgrund der Zufallsstichprobenziehung zustande kommt. Der
genaue $p$-Wert kann mit `Jamovi` unter
`Tests > z-Test für den Unterschied zwischen den zwei Anteilen`
ermittelt werden. Mit $p = .0649$ kann die Nullhypothese knapp nicht
verworfen werden. Die beiden Anteile $\pi_1$ und $\pi_2$ könnten also
gleich sein.

> Ein zweiseitiger $z$-Test für den Unterschied zwischen den zwei
> Anteilen ergibt, dass der Anteil der mehr als einmal pro Woche
> alkoholkonsumierenden Personen mit Tertiärbildung ($p_1 = 81.5\%$),
> nicht signifikant von ebendiesem Anteil der Personen mit anderer
> Bildung ($p_2 = 76.5\%$) unterscheidet, $z = -1.85, p = .0649$.

### $\chi^2$-Test

[Der $\chi^2$-Test (sprich 'chi-quadrat-test') ist eine zweite
allgemeinere Variante, um den Zusammenhang zwischen zwei dichotomen
Merkmalen zu testen.]{#customdef-chisq-test .customdef}
Die Nullhypothese ist wiederum, dass die beiden Merkmale unabhängig
voneinander sind.

Um nun die Teststatistik näher verstehen zu können, muss ein kurzer
Exkurs in Wahrscheinlichkeitslehre unternommen werden. Diese besagt
nämlich, dass wenn zwei Ereignisse A und B unabhängig voneinander
auftreten, dann ist die Auftretenswahrscheinlichkeit genau gleich dem
Produkt der Wahrscheinlichkeiten der jeweiligen Ereignisse. In Formeln
ausgedrückt
$$p(A \text{ und }B) \overset{\text{unabhängig}}{=} p(A) \cdot p(B).$$

Auf das Beispiel \@ref(exm:alcohol-edu) bezogen bedeutet dies, dass wenn
Alkoholkonsum und die Ausbildungsart unabhängig voneinander sind, dann
entspricht die Wahrscheinlichkeit mehr als $1$x pro Woche Alkohol zu
konsumieren und eine tertiäre Ausbildung genossen zu haben

$$
p(\text{[alkohol > 1x pro Woche] und tertiär}) = \frac{`r exm_alcohol_edu$jmv_output_freq %>% filter(alkoholkonsum == "oft") %>% pull(all_of("1_count"))`}{`r exm_alcohol_edu$jmv_output_freq %>% filter(alkoholkonsum == "oft") %>% pull(all_of("total_count"))`} = `r round((exm_alcohol_edu$jmv_output_freq %>% filter(alkoholkonsum == "oft") %>% pull(all_of("1_count")))/(exm_alcohol_edu$jmv_output_freq %>% filter(alkoholkonsum == "oft") %>% pull(all_of("total_count"))),5)`
$$

genau

$$
p(\text{[alkohol > 1x pro Woche]}) \cdot p(\text{tertiär}) = \frac{`r exm_alcohol_edu$jmv_output_freq %>% filter(alkoholkonsum == "oft") %>% pull(all_of("total_count"))`}{`r exm_alcohol_edu$jmv_output_freq %>% filter(alkoholkonsum == "Total") %>% pull(all_of("total_count"))`}\cdot \frac{`r exm_alcohol_edu$jmv_output_freq %>% filter(alkoholkonsum == "Total") %>% pull(all_of("1_count"))`}{`r exm_alcohol_edu$jmv_output_freq %>% filter(alkoholkonsum == "Total") %>% pull(all_of("total_count"))`} = `r round((exm_alcohol_edu$jmv_output_freq %>% filter(alkoholkonsum == "oft") %>% pull(all_of("total_count"))/ exm_alcohol_edu$jmv_output_freq %>% filter(alkoholkonsum == "Total") %>% pull(all_of("total_count")))* (exm_alcohol_edu$jmv_output_freq %>% filter(alkoholkonsum == "Total") %>% pull(all_of("1_count"))/exm_alcohol_edu$jmv_output_freq %>% filter(alkoholkonsum == "Total") %>% pull(all_of("total_count"))),5)`
$$

entsprechen. Die Zahlen zeigen an, dass dies für diese Stichprobe klar
nicht gegeben ist. Die beobachtete Differenz könnte sich aber auch aus
der Zufallsstichprobenziehung ergeben haben. Der $\chi^2$-Vierfeldertest
vergleicht nun in jeder Zelle $i$ der Vierfeldertafel die tatsächlich
beobachteten Beobachtungen $o_i$ (observed) mit den erwarteten
Beobachtungen $e_i$ (expected), wenn die Unabhängigkeit gegeben wäre.
Letztere berechnet sich durch $p(A) \cdot p(B) \cdot n$, wobei $n$ die
Gesamtanzahl Beobachtungen ist. Im Beispiel

$$e_1 = p(\text{[alkohol > 1x pro Woche]}) \cdot p(\text{tertiär}) \cdot n =`r round(((exm_alcohol_edu$jmv_output_freq %>% filter(alkoholkonsum == "oft") %>% pull(all_of("total_count"))/ exm_alcohol_edu$jmv_output_freq %>% filter(alkoholkonsum == "Total") %>% pull(all_of("total_count")))* (exm_alcohol_edu$jmv_output_freq %>% filter(alkoholkonsum == "Total") %>% pull(all_of("1_count"))/exm_alcohol_edu$jmv_output_freq %>% filter(alkoholkonsum == "Total") %>% pull(all_of("total_count")))),5)` \cdot  `r exm_alcohol_edu$jmv_output_freq %>% filter(alkoholkonsum == "Total") %>% pull(all_of("total_count"))` = `r round(((exm_alcohol_edu$jmv_output_freq %>% filter(alkoholkonsum == "oft") %>% pull(all_of("total_count"))/ exm_alcohol_edu$jmv_output_freq %>% filter(alkoholkonsum == "Total") %>% pull(all_of("total_count")))* (exm_alcohol_edu$jmv_output_freq %>% filter(alkoholkonsum == "Total") %>% pull(all_of("1_count"))/exm_alcohol_edu$jmv_output_freq %>% filter(alkoholkonsum == "Total") %>% pull(all_of("total_count")))* exm_alcohol_edu$jmv_output_freq %>% filter(alkoholkonsum == "Total") %>% pull(all_of("total_count"))),5)` $$
Je weiter diese Zahl von der beobachteten Zahl abweicht, desto
unwahrscheinlicher ist die Unabhängigkeit. Der $\chi^2$ trägt dem
Rechnung, indem die Teststatistik

$$\chi^2 = \sum_{i = 1}^k \frac{(o_i - e_i)^2}{e_i} = `r round(exm_alcohol_edu$jmv_output_test$value_chiSq,2)`,$$
wobei $k$ hier für die Anzahl Zellen steht. Eine grosse Teststatistik
spricht also gegen die Unabhängigkeit.

Wenn die Stichprobenziehung oft wiederholt wird, kann festgestellt
werden, dass diese Teststatistik einer bekannten Verteilung, der
$\chi^2$-Verteilung bei $df = 1$ Freiheitsgraden folgt. [Die
$\chi^2$-Verteilung ist für verschiedene Freiheitsgrade in Abbildung
\@ref(fig:chisq-distribution)
dargestellt.]{#customdef-chisq-distribution .customdef}
Die Teststatistik des $\chi^2$-Vierfeldertests
$`r round(exm_alcohol_edu$jmv_output_test$value_chiSq,2)`$ wird also mit
der roten Verteilung in der Abbildung verglichen. Die Werte rechts auf
der Abbildung sind seltener und der beobachtete Wert liegt so, dass er
zu den $`r report_p(exm_alcohol_edu$jmv_output_test$p_chiSq)`$
seltensten Beobachtungen zählt, sofern die Unabhängigkeit gilt. Dies
reicht hier gerade nicht, um die Nullhypothese bei Signifikanzniveau
$\alpha = 5\%$ zu verwerfen.

```{r chisq-distribution, fig.cap="Chiquadrat-Verteilungen mit 1, 4 und 9 Freiheitsgraden."}
tibble(x = seq(0, 20, by = 0.01),
       chisq_1 = dchisq(x, 2-1),
       chisq_4 = dchisq(x, 5-1),
       chisq_9 = dchisq(x, 10-1)) %>%
  pivot_longer(cols = 2:4, names_to = "Verteilung_df", values_to="Wahrscheinlichkeitsdichte") %>% 
  ggplot(aes(x=x))+
  geom_line(aes(y=Wahrscheinlichkeitsdichte, color = Verteilung_df))+
  labs(x="")+
  ylim(c(0,0.25))
```

[Um die Effektstärke des $\chi^2$-Tests anzugeben kann **Cramérs $\phi$**]{.customdef #customdef-cramers-phi} 



$$\phi = \sqrt{\frac{\chi^2}{n}} = \sqrt{\frac{`r round(exm_alcohol_edu$jmv_output_test$value_chiSq,2)`}{`r exm_alcohol_edu$n`}} = `r round(sqrt(round(exm_alcohol_edu$jmv_output_test$value_chiSq,2) / exm_alcohol_edu$n),2)`$$

Cramérs $\phi$ immer grösser als $0$ und kleiner als $1$. Je weiter
$\phi$ von $0$ weg ist, desto stärker sind die Merkmale voneinander
abhängig. [Da dies auch als Zusammenhangsmass gesehen werden kann wird
Cramérs $\phi$ auch **Vierfelderkorrelation** genannt.]{.customdef #customdef-vierfelderkorrelation} Die Interpretation als Effektstärke erfolgt dabei wir für die Korrelation. Ein Wert von
$0.06$ wird demnach als schwach eingestuft.

> Ein $\chi^2$-Test ergibt, dass der Alkoholkonsum (mehr/weniger als 1x
> pro Woche) und Bildung (Tertiär/andere Bildung) ($p_1-p_2= `r -round(exm_alcohol_edu$jmv_output_odds$v_dp, 2)`$, $RR = `r round(1/exm_alcohol_edu$jmv_output_odds$v_rr, 2)`$) nicht signifikant
> abhängig voneinander sind,
> $\chi^2 (1) = `r round(exm_alcohol_edu$jmv_output_test$value_chiSq,2)`, p = .0649, \phi = 0.06$.

Der $\chi^2$ Test hat für die Vierfeldervariante immer den gleichen
$p$-Wert wie der Test der Risikodifferenz auf $0$. Beide Tests basieren
auf dem zentralen Grenzwertsatz und dürfen deshalb nur angewendet
werden, wenn gewisse Voraussetzungen erfüllt sind. Die Voraussetzung
ist, dass insgesamt $40$ oder mehr Beobachtungen vorliegen müssen. [Ist
dies nicht der Fall, aber in jeder Zelle ist die Anzahl der erwarteten
Beobachtungen bei $5$ oder grösser, so kann der $\chi^2$-Test mit
**Kontinuitätskorrektur** oder Yates-Korrektur verwendet
werden]{#customdef-chisq-corrected .customdef}
$$\chi^2_{Yates} = \sum_{i = 1}^k \frac{(|o_i - e_i| -0.5)^2}{e_i}.$$

In Beispiel sind mit $n = 1000$ genügend Beobachtungen vorhanden, um
ohne die Kontinuitätskorrektur auszukommen. Der Bericht des Tests ist
genau gleich wie der Bericht des $\chi^2$-Test ausser, dass der Name des
Verfahrens geändert wird:

> Ein $\chi^2$-Test mit Kontinuitätskorrektur ergibt, dass der
> Alkoholkonsum ...

### Exakter Test nach Fisher und Yates

Wenn die erwarteten Beobachtungen in mindestens einer Zelle kleiner als
$5$ sind, dann ist die Approximation der Verteilung der Teststatistik
durch den $\chi^2$-Test sogar mit Kontinuitätskorrektur zu ungenau.

::: {#red-white-wine .example name="Wette: Unterscheiden von Rot- und Weisswein"}
```{r exm-red-white-wine}
file_name <- '09-exm-red-white-wine.sav'
dd <- tibble(ist = c("rotwein", "rotwein", "weisswein", "weisswein"),
       sagt = c("rotwein", "weisswein", "rotwein", "weisswein"),
       anzahl = c(4, 1, 1, 3)) %>% 
  write_sav(file_name)
file_name <- '09-exm-red-white-wine-alternative.sav'
dd <- tibble(ist = c("rotwein", "rotwein", "weisswein", "weisswein"),
       sagt = c("rotwein", "weisswein", "rotwein", "weisswein"),
       anzahl = c(5, 0, 0, 4)) %>% 
  write_sav(file_name)
```

Nina behauptet, sie kann Rotwein von Weisswein am Geschmack
unterscheiden. Sie bereiten ein Experiment vor, um dies zu testen
verbinden Nina die Augen. Als Statistiklernende wissen sie, dass es
nicht genügt, dass Nina einmal die richtige Weinsorte wählt - dies
könnte ja zufällig richtig sein. Stattdessen werden $5$ Gläser Rotwein
und $4$ Gläser Weisswein vorbereitet und Nina in zufälliger Reihenfolge
zum Probieren angeboten. Das Experiment endet mi den Zahlen in Abbildung
\@ref(fig:exm-red-white-wine-aggdata-view).

```{r exm-red-white-wine-aggdata-view, fig.cap = "Vierfeldertafel Wette Unterschied Rot- und Weisswein."}
knitr::include_graphics("figures/09-exm-red-white-wine-aggdata-view.jpg")
```
:::

Da nur wenige Beobachtungen gemacht wurden, kann die Wahrscheinlichkeit
eines Ausgangs des Experiments mit Hilfe der
hypergeometrischen-Verteilung genau berechnet werden. Die
Wahrscheinlichkeit für den Experimentausgang in Abbildung
\@ref(fig:exm-red-white-wine-aggdata-view) entspricht $p_0 = 0.159$.

Der $p$-Wert eines Tests ist bekannterweise die Wahrscheinlichkeit die
berechnetet Teststatistik zu beobachten *oder eine unwahrscheinlichere
Situation im Sinne der Alternativhypothese*. Nina will zeigen, dass Sie
Rotwein und Weisswein richtig erkennen kann, was der Alternativhypothese
entspricht. Ihr ist gedient, wenn sie Rot- und Weisswein überzufällig
oft richtig erkennt, nicht aber, wenn sie den Rot- und Weisswein
unterdurchschnittlich oft richtig erkennt. Die Alternativhypothese ist
also hier einseitig formuliert zu verstehen.

Um dem zweiten Teil dieser Definition des $p$-Werts gerecht zu werden,
werden nun andere, unwahrscheinlichere Experimentausgänge im Sinne der
Alternativhypothese bewertet. Um dies zu erreichen, wird hier
angenommen, dass in jedem Fall die Randsummen immer gleichbleiben (also
$5$ für ist Rotwein, $4$ für ist Weisswein, $5$ für sagt Rotwein und $4$
für sagt Weisswein). Wenn ist und sagt unabhängig voneinander ist und
Nina also die Weinfarben nicht auseinanderhalten kann, dann wäre es
unwahrscheinlicher, wenn sie alle $5$ Rotweine als solche erkannt hätte.
Wenn die Randsummen gleich gehalten werden, entspricht dies der
Situation in Abbildung \@ref(fig:exm-red-white-wine-aggdata-view-alt).
Die Wahrscheinlichkeit für diese Situation ist $p_1 = 0.008$.

```{r exm-red-white-wine-aggdata-view-alt, fig.cap = "Vierfeldertafel Wette Unterschied Rot- und Weisswein."}
knitr::include_graphics("figures/09-exm-red-white-wine-aggdata-view-alt.jpg")
```

Grundsätzlich können hier noch weitere Situationen aufgezählt werden. Im
Beispiel sind mit der eben beschriebenen Situation und der
ursprünglichen Situation jedoch die Alternativen erschöpft: Es kann
nicht sein, dass Nina $6$-mal Rotwein richtig voraussagt, wenn sie
insgesamt nur $5$-mal Rotwein sagt.

Nun werden die Wahrscheinlichkeiten aller Situation aufsummiert,
$p = p_0 + p_1 + \ldots = 0.159+0.008 =0.167$. Da mit diesem Vorgehen
genau der Definition des $p$-Wertes gefolgt wurde, stellt dieses $p$ nun
auch einen $p$-Wert dar. [Der dazugehörige Test wird **exakter Test nach
Fisher und Yates** oder einfach Fisher-Yates-Test
genannt.]{#customdef-fisher-yates .customdef}

> Ein einseitiger exakter Test nach Fisher und Yates ergibt, dass das
> Ansagen der Weinsorte von Nina nicht signifikant von der tatsächlichen
> Weinsorte abhängt, $p = .167$.

:::: {.caution data-latex=""}
::: remark
-   Der Test ist exakt, weil hier die Wahrscheinlichkeiten genau
    bestimmt wurden. Bei allen anderen bislang gesehenen Tests wird die
    Wahrscheinlichkeit über eine Verteilung angenähert. Diese Annäherung
    ist theoretisch nur richtig, wenn unendlich viele Beobachtungen
    gemacht werden, weshalb diese Art Test auch **asymptotisch** genannt
    wird. In der Praxis wird jedoch festgestellt, dass asymptotische
    Tests bereits für eine kleine Anzahl Beobachtungen (z. B. $50$ für
    den Einstichproben-$t$-Test) hinreichend genau sind.
-   Da für den exakten Test nach Fisher und Yates die
    Wahrscheinlichkeiten direkt berechnet werden, wird keine
    Teststatistik verwendet.
-   Um eine zweiseitige Alternative testen zu können, müsste der Test
    Wahrschinlichkeiten von gleichen oder extremeren Situationen in die
    andere Richtung dazusummieren. Solche Situationen können nicht immer
    eindeutig bestimmt werden. Im Beispiel wäre eine Möglichkeit, dass
    Nina $1$-mal Rotwein sagt, wenn es Rotwein ist. Eine andere
    Möglichkeit wäre, dass Nina 1-mal Weisswein sagt, wenn es Weisswein
    ist. Grundsätztlich wird hier nur der einseitige extakte Test nach
    Fisher verlangt.
:::
::::

## Übungen

::: {#autism-epilepsy .exercise}
```{=html}
<!-- 
Ziel: 
-
-->
```

```{r exr-autism-epilepsy}
gen_exr_autism_epilepsy <- function(){
  n <- 5185
  n1 <- 2500
  n2 <- n- n1
  p1 <- 0.12
  p2 <- 0.26
  n21 <- p1*n1
  n22 <- (1-p1)*n1
  n11 <- round(p2*n2)
  n12 <- round((1-p2)*n2)
  n <- n11+n12+n21+n22
  dd <- tibble(epilepsy = c(rep("ja",n11),
                        rep("nein",n12),
                        rep("ja",n21),
                        rep("nein",n22)),
         alter = c(rep("jugendlich",n11),
                      rep("jugendlich",n12),
                      rep("kind",n21),
                      rep("kind",n22))) %>% 
    slice_sample(prop = 1)
  n <- dd %>% nrow()
  jmv_output <- jmv::contTables(
    dd,
    "epilepsy",
    "alter",
    chiSq = TRUE,
    chiSqCorr = TRUE,
    odds = TRUE,
    relRisk = TRUE,
    diffProp = TRUE, 
    phiCra = TRUE,
    pcCol = TRUE,
    compare = 'columns'
  )
  jmv_output_freq <- jmv_output$freqs$asDF %>% 
    clean_jmv_colnames()
  jmv_output_odds <- jmv_output$odds$asDF %>% 
    clean_jmv_colnames()
  jmv_output_test <- jmv_output$chiSq$asDF %>% 
    clean_jmv_colnames()
  jmv_output_nom <- jmv_output$nom$asDF %>% 
    clean_jmv_colnames()
  file_name <- '09-exr-autism-epilepsy.sav'
  dd %>% write_sav(file_name)
  
  return(mget(ls()))
}
exr_autism_epilepsy <- gen_exr_autism_epilepsy()
```

@viscidi2013 wollten herausfinden wie sich das Alter (Kind bis $10$
Jahre / Jugendlich älter als $10$ Jahre) auf das Auftreten von Epilepsie
bei Menschen mit einer Autismus-Spektrum-Störung auswirkt. Dafür wurden
zufällig `r exr_autism_epilepsy$n` Menschen mit
Autismus-Spektrum-Störung zu ihrem Alter und dem Auftreten von Epilepsie
befragt. Simulierte Daten befinden sich im Datensatz
`r inline_code(exr_autism_epilepsy$file_name)`.

a)  Lässt das Studiendesign das Berechnen des relativen Risikos zu?
b)  Berechnen Sie das Risiko an Epilepsie zu leiden in den beiden Altersgruppen und anschliessend die Risikodifferenz, das relative Risiko und das Chancenverhältnis.
c)  Sichern Sie die Risikodifferenz zweiseitig gegen Null ab und
    berichten Sie das Ergebnis.
d)  Testen Sie den Zusammenhang mit einem $\chi^2$-Test und berichten
    Sie das Ergebnis. Schätzen und interpretieren Sie auch die Effektstärke.
:::

::: solution
Zuerst wird der Datensatz mit `Jamovi` eingelesen und die
Analyseparameter werden gesetzt, siehe Abbildung
\@ref(fig:sol-autism-epilepsy-input).

```{r sol-autism-epilepsy-input, fig.cap='Jamovi Eingabe.'}
knitr::include_graphics("figures/09-exr-autism-epilepsy-jmv-input.jpg")
```

Dies produziert das Analyseergebnis in Abbildung
\@ref(fig:sol-autism-epilepsy-output).

```{r sol-autism-epilepsy-output, fig.cap='Jamovi Ausgabe.'}
knitr::include_graphics("figures/09-exr-autism-epilepsy-jmv-output.jpg")
```

Damit kann die Frage nun beantwortet werden:

a) Ja die Leute wurden zufällig ausgewählt und nicht aufgrund der Präsenz oder Absenz eines Epilepsieanfalls.
b) Das Risiko an Epilepsie zu leiden liegt bei $12.0\%$ für Kinder und $26.0\%$ für Jugendliche. Die Risikodifferenz liegt bei $14.0\%$. Das Risiko ist für Jugendliche $14.0\%$ höher als für Kinder. Das relative Risiko liegt bei $2.17$. Das Risiko ist für Jugendliche also $2.17$-mal so hoch wie für Kinder. Das Chancenverhältnis liegt bei $2.58$. Die Chance an Epilepsie zu leiden ist für Jugendliche also $2.58$-mal so hoch wie für Kinder.
c) 
> Ein zweiseitiger $z$-Test für den Unterschied zwischen zwei Anteilen ergibt, dass sich der Anteil der autistischen Jugendlichen mit Epilepsieanfällen ($p_1 = 26.0\%$), signifikant vom Anteil der Kinder mit Epilepsieanfällen ($p_2 = 12.0\%$) unterschiedet, $z = 12.8, p < .001$.

d) 
> Ein $\chi^2$-Test ergibt, dass das Auftreten von Epilepsieanfällen (ja/nein) und die Alterskategorie (Jugendlich/Kind) ($p_1-p_2= `r round(exr_autism_epilepsy$jmv_output_odds$v_dp, 2)`$, $RR = `r round(exr_autism_epilepsy$jmv_output_odds$v_rr, 2)`$) signifikant voneinander abhängig sind, $\chi^2 (1) = `r round(exr_autism_epilepsy$jmv_output_test$value_chiSq,2)`$, $`r report_p(exr_autism_epilepsy$jmv_output_test$p_chiSq)`$, $\phi = `r round(exr_autism_epilepsy$jmv_output_nom$v_phi, 2)`.$ Der Effekt ist schwach.

:::

::: {#depression-training .exercise}
```{=html}
<!-- 
Ziel: 
- Vierfelder Testentscheidung
- Vierfeldertest
- Zusammenhangsmasse
-->
```

```{r exr-depression-training}
gen_exr_depression_training <- function(){
  n11 <- 22
  n12 <- 25
  n21 <- 23
  n22 <- 7
  dd <- tibble(depression = c(rep("depressiv",n11),
                        rep("depressiv",n12),
                        rep("nicht_depressiv",n21),
                        rep("nicht_depressiv",n22)),
         training = c(rep("oft",n11),
                      rep("selten",n12),
                      rep("oft",n21),
                      rep("selten",n22)))
  n <- dd %>% nrow()
  jmv_output <- jmv::contTables(
    dd,
    "depression",
    "training",
    chiSq = TRUE,
    chiSqCorr = TRUE,
    odds = TRUE,
    relRisk = TRUE,
    diffProp = TRUE, 
    phiCra = TRUE,
    pcCol = TRUE,
    compare = 'columns'
  )
  jmv_output_freq <- jmv_output$freqs$asDF %>% 
    clean_jmv_colnames()
  jmv_output_odds <- jmv_output$odds$asDF %>% 
    clean_jmv_colnames()
  jmv_output_test <- jmv_output$chiSq$asDF %>% 
    clean_jmv_colnames()
  jmv_output_nom <- jmv_output$nom$asDF %>% 
    clean_jmv_colnames()
  file_name <- '09-exr-depression-training.sav'
  dd %>% write_sav(file_name)
  
  return(mget(ls()))
}
exr_depression_training <- gen_exr_depression_training()
```

<!-- TODO: Ausschöpfen odds ratio, etc -->

Eine Psychologin hat versucht herauszufinden, wie sich das
Trainingsverhalten (oft/selten) auf depressive Stimmungen auswirkt. Dazu
hat sie in einem Experiment
$`r exr_depression_training$n`$ zufällige Leute befragt und die Resultate in Datensatz `r  inline_code(exr_depression_training$file_name)` erhalten.

a)  Welches ist die Risikovariable?
b)  Wie gross sind die Risiken in den beiden Gruppen? Wie gross ist die
    Risikodifferenz, das relative Risiko und das Chancenverhältnis?
    Welche Wirkung hat das Trainingsverhalten auf das Risiko eine
    Depression zu erleiden?
c)  Sind die Variablen Depression und Trainingsverhalten voneinander
    abhängig, wenn bei $\alpha = 5\%$ mit einem $\chi^2$-Test getestet wird?
d)  Ist die Kontinuitätskorrektur angebracht? Wie gross ist der Unterschied zwischen der Teststatistik mit und ohne
    Yates-Korrektur hier?
e)  Wie gross ist die Vierfelderkorrelation zwischen den beiden
    Variablen? Interpretieren Sie den Zusammenhang.
:::

::: solution

Zuerst wird der Datensatz mit `Jamovi` eingelesen und die
Analyseparameter werden gesetzt, siehe Abbildung
\@ref(fig:sol-depression-training-input).

```{r sol-depression-training-input, fig.cap='Jamovi Eingabe.'}
knitr::include_graphics("figures/09-exr-depression-training-jmv-input.jpg")
```

Dies produziert das Analyseergebnis in Abbildung
\@ref(fig:sol-depression-training-output).

```{r sol-depression-training-output, fig.cap='Jamovi Ausgabe.', fig.show='hold'}
knitr::include_graphics("figures/09-exr-depression-training-aggdata-view.jpg")
knitr::include_graphics("figures/09-exr-depression-training-jmv-output.jpg")
```

Damit kann die Frage nun beantwortet werden:

a)  Die Risikovariable ist hier eine Depression zu haben oder nicht.
b)  Das Risiko beträgt
    $p_1 = `r round(exr_depression_training$jmv_output_freq %>% filter(depression == "depressiv") %>% slice(1) %>% pull(all_of("1_pcCol"))*100,1)`\%$ in der oft trainierenden Gruppe. In der anderen Gruppe liegt das Risiko bei $p_2 =`r     round(exr_depression_training$jmv_output_freq %>% filter(depression == "depressiv") %>% slice(1) %>%  pull(all_of("2_pcCol"))*100,1)` \%$.
    Die Risikodifferenz liegt bei
    $`r round(100* exr_depression_training$jmv_output_odds$v_dp, 1)`\%$,
    das relative Risiko bei
    $`r round(exr_depression_training$jmv_output_odds$v_rr, 3)`$ und das
    Chancenverhältnis bei
    $`r round(exr_depression_training$jmv_output_odds$v_o, 3)`$. Oft zu
    trainineren hat einen protektive Wirkung auf das Risiko an einer
    Depression zu erkranken.
c)  
> Ein $\chi^2$-Test ergibt, dass das Auftreten von Depression (ja/nein) und die Trainingsfrequenz (oft/selten) ($p_1-p_2= `r round(exr_depression_training$jmv_output_odds$v_dp, 2)`$, $RR = `r round(exr_depression_training$jmv_output_odds$v_rr, 2)`$) signifikant voneinander abhängig sind, $\chi^2 (1) = `r round(exr_depression_training$jmv_output_test$value_chiSq,2)`$, $`r report_p(exr_depression_training$jmv_output_test$p_chiSq)`$, $\phi = `r round(exr_depression_training$jmv_output_nom$v_phi, 2)`.$ Der Effekt ist mittel.

d)  Die Kontinuitätskorrektur ist nicht nötig da mit $77$ Beobachtungen mehr als $40$ Beobachtungen vorliegen. Die Teststatistik ohne Kontinuitätskorrektur ist $\chi(1)^2 = `r round(exr_depression_training$jmv_output_test$value_chiSq,2)`$ und mit Kontinuitätskorrektur $\chi(1)^2 = `r round(exr_depression_training$jmv_output_test$value_chiSqCorr,2)`$. Beide Testverfahren deuten auf eine signifikante Abhängigkeit hin.
e)  Die Vierfelderkorrelation entspricht der Effektstärke $\phi = `r round(exr_depression_training$jmv_output_nom$v_phi, 2)`.$ Die Korrelation ist mittel. Die Richtung des Zusammenhangs muss aus den Anteilen abgelesen werden. Je eher jemand unter Depression leidet, desto eher trainiert jemand selten. 
:::

::: {#cancer-smoking .exercise}
```{=html}
<!-- 
https://pubmed.ncbi.nlm.nih.gov/9857993/
Ziel: 
- Vierfelder Testentscheidung
- Vierfeldertest
- Zusammenhangsmasse
-->
```

```{r exr-cancer-smoking}
gen_exr_cancer_smoking <- function(){
  dd <- tibble(lung = c("cancer", "cancer", "no_cancer", "no_cancer"),
               habit = c("smoking", "no_smoking", "smoking", "no_smoking"),
               counts = c(150,50,100,297))
  n <- dd %>% pull(counts) %>% sum()
    
  file_name <- '09-exr-cancer-smoking.sav'
  dd %>% write_sav(file_name)
  
  jmv_output <- jmv::contTables(
    dd,
    "habit",
    "lung",
    "counts",
    chiSq = TRUE,
    chiSqCorr = TRUE,
    odds = TRUE,
    relRisk = TRUE,
    diffProp = TRUE, 
    phiCra = TRUE,
    pcCol = TRUE,
    compare = 'rows'
  )
  jmv_output_freq <- jmv_output$freqs$asDF %>% 
    clean_jmv_colnames()
  jmv_output_odds <- jmv_output$odds$asDF %>% 
    clean_jmv_colnames()
  jmv_output_test <- jmv_output$chiSq$asDF %>% 
    clean_jmv_colnames()
  jmv_output_nom <- jmv_output$nom$asDF %>% 
    clean_jmv_colnames()
  return(mget(ls()))
}
exr_cancer_smoking <- gen_exr_cancer_smoking()
```

Um den Zusammenhang zwischen Rauchen und Lungenkrebs zu analysieren
haben Forschende in einer Studie $200$ an Lungenkrebs erkrankte und
$397$ nicht an Lungenkrebs erkrankte Menschen zu ihrem Rauchverhalten
(rauchen ja oder nein) befragt. Die Forschenden haben die Daten im
Datensatz `r inline_code(exr_cancer_smoking$file_name)` aggregiert zur
Verfügung gestellt. Lose nach @matos1998.

a)  Handelt es sich um eine Fall-Kontroll (case-control) Studie.
b)  Identifizieren Sie abhängige und unabhängige Variable. Wie gross ist
    das Risiko an Lungenkrebs zu erkranken für rauchende und nicht
    rauchende Menschen? Können hier die Risikodifferenz, das *RR* und
    der *OR* verwendet werden, um den Zusammenhang zu beschreiben?
c)  Wie gross ist das Chancenverhältnis und was heisst das für die
    rauchenden Menschen?
d)  Ist das Lungenkrebsrisiko vom Rauchverhalten abhängig? Führen Sie einen $\chi^2$-Test durch.
:::

::: solution
Zuerst wird der Datensatz mit `Jamovi` eingelesen und die
Analyseparameter werden gesetzt, siehe Abbildung
\@ref(fig:sol-cancer-smoking-input).

```{r sol-cancer-smoking-input, fig.cap='Jamovi Eingabe.'}
knitr::include_graphics("figures/09-exr-cancer-smoking-jmv-input.jpg")
```

Dies produziert das Analyseergebnis in Abbildung
\@ref(fig:sol-cancer-smoking-output).

```{r sol-cancer-smoking-output, fig.cap='Jamovi Ausgabe.'}
knitr::include_graphics("figures/09-exr-cancer-smoking-jmv-output.jpg")
```

Damit kann die Frage nun beantwortet werden:

a)  Ja. Die Forschenden haben bestimmt wie viele erkrankte und gesunde
    Personen sie für die Studie anschreiben.
b)  Die abhängige Variable oder Risikovariable ist hier die Erkrankung
    an Lungenkrebs. Die ursächliche oder unabhängige Variable ist das
    Rauchverhalten. Da in der Studie der Anteil gesunder und erkrankter
    Menschen im Vorherein festgelegt wurde, ist eine Berechnung des
    Risikos nicht sinnvoll. Daraus folgend ist auch die Risikodifferenz
    oder das relative Risiko nicht sinnvoll. Der OR kann immer verwendet
    werden, um den Zusammenhang zu beschreiben.
c)  Das Chancenverhältnis liegt bei $`r round(1/exr_cancer_smoking$jmv_output_odds$v_o, 2)`$. Das bedeutet für die
    rauchenden Leute ist die Chance an Lungenkrebs zu erkanken
    $8.91$-mal so hoch wie für nicht rauchende.
d)  
> Ein $\chi^2$-Test ergibt, dass das Auftreten von Lungenkrebs (ja/nein) und das Rauchverhalten (ja/nein) ($OR = `r round(1/exr_cancer_smoking$jmv_output_odds$v_o, 2)`$) signifikant voneinander abhängig sind, $\chi^2 (1) = `r round(exr_cancer_smoking$jmv_output_test$value_chiSq,2)`$, $`r report_p(exr_cancer_smoking$jmv_output_test$p_chiSq)`$, $\phi = `r round(exr_cancer_smoking$jmv_output_nom$v_phi, 2)`.$ Der Effekt ist stark.

:::

::: {#bio-milch .exercise}
```{=html}
<!-- 
Ziel: 
- Daten als einzelne Beobachtungen
- Vierfelder Testentscheidung
- Vierfeldertest
- Zusammenhangsmasse
-->
```

```{r exr-bio-milch}
gen_exr_bio_milch <- function(){
  n11 <- 7
  n12 <- 3
  n21 <- 2
  n22 <- 3
  dd <- tibble(behauptet = c(rep("bio",n11),
                        rep("bio",n12),
                        rep("nicht_bio",n21),
                        rep("nicht_bio",n22)),
         ist = c(rep("bio",n11),
                      rep("nicht_bio",n12),
                      rep("bio",n21),
                      rep("nicht_bio",n22)))
    
  file_name <- '09-exr-bio-milch.sav'
  dd %>% write_sav(file_name)
  jmv_output <- jmv::contTables(
    dd,
    "behauptet",
    "ist",
    fisher = TRUE,
    phiCra = TRUE,
    pcCol = TRUE,hypothesis = "oneGreater",
    compare = 'rows'
  )
  jmv_output_freq <- jmv_output$freqs$asDF %>%
    clean_jmv_colnames()
  jmv_output_test <- jmv_output$chiSq$asDF %>%
    clean_jmv_colnames()
  jmv_output_nom <- jmv_output$nom$asDF %>%
    clean_jmv_colnames()
  return(mget(ls()))
}
exr_bio_milch <- gen_exr_bio_milch()
```

<!-- TODO: Ausschöpfen odds ratio, etc -->

Eine Freundin von Ihnen behauptet, dass Sie Bio-Milch und nicht
Bio-Milch am Geschmack unterscheiden kann. Sie geben ihr $9$-mal
Bio-Milch zu trinken und $6$-mal nicht Bio-Milch zu trinken bei einem
doppel-blind Test. Es entstehen die Daten in
`r inline_code(exr_bio_milch$file_name)`.

a)  Wie hoch ist der Anteil der richtig erkannten Bio-Milch und nicht Bio-Milch Proben? 
b)  Welcher Test ist bei dieser Datenlage angebracht, um zu testen, ob
    die Freundin tatsächlich Bio und nicht Bio-Milch am Geschmack
    unterschieden kann?
c)  Konnte die Freundin ihre Behauptung im Experiment nachweisen? Führen
    Sie den angebrachten Test durch und berichten Sie das Resultat
    inklusive Effektstärke.
d)  Skizzieren Sie eines der im Test implizit verwendeten Alternativszenarien. 
:::

::: solution
Zuerst wird der Datensatz mit `Jamovi` eingelesen und die
Analyseparameter werden gesetzt, siehe Abbildung
\@ref(fig:sol-bio-milch-input).

```{r sol-bio-milch-input, fig.cap='Jamovi Eingabe.'}
knitr::include_graphics("figures/09-exr-bio-milch-jmv-input.jpg")
```

Dies produziert das Analyseergebnis in Abbildung
\@ref(fig:sol-cancer-smoking-output).

```{r sol-bio-milch-output, fig.cap='Jamovi Ausgabe.'}
knitr::include_graphics("figures/09-exr-bio-milch-jmv-output.jpg")
```

Damit kann die Frage nun beantwortet werden:

a) Der Anteil der richtig erkannten Bio-Milch Proben ist $p_1 = 78\%$. Der Anteil der richtig erkannten nicht Bio-Milch Proben ist $p_2 = 50\%$.
b) Insgesamt werden $n = `r exr_bio_milch$dd %>% nrow()`$ Proben beurteilt. Da dies kleiner ist als $40$ kommt der $\chi^2$-Test nicht in Frage. Die erwarteten Beobachtungen sind zum Teil unter $5$. Dies bedeutet, dass die Kontinuitätskorrektur auch nicht verwendet werden darf. Es bleibt der exakte Test nach Fisher und Yates als einzige mögliche Option.
c) Achtung der exakte Test nach Fisher und Yates wird einseitig durchgeführt, da es nicht interessiert, ob die Freundin die Bio-Milch unterdurchschnittlich gut erkennen kann.

> Ein einseitiger exakter Test nach Fisher und Yates ergibt, dass das Ansagen der Milchsorte der Freundin nicht signifikant von der tatsächlichen Milchsorte abhängt, $`r report_p(exr_bio_milch$jmv_output_test$p_fisher)`$, $\phi = `r round(exr_bio_milch$jmv_output_nom$v_phi, 2)`$. Der Effekt ist mittel.

d) Der Test belässt die Randsummen fixiert. Dies bedeutet, dass insgesamt immer gleich viele Proben jeder Milchsorte vorausgesagt werden und immer insgesamt gleich viele Porben von jeder Milchsorte gegeben werden. Der Test verwendet Alternativszenarien, welche extremer sind im Sinne der Alternativhypothese. Die Alternativhypothese ist, dass die Freundin Bio- von nicht Bio-Milch unterscheiden kann. Extremer bedeutet also hier, dass die Freundin mehr Proben richtig erkennt, zum Beispiel, $8$ statt der $7$ Bio-Milch Proben. Da die Randsummen gleichbleiben, bedeutet dies, dass die Freundin demnach $2$ statt $3$ nicht Bio-Milch Proben als Bio-Milch einstuft und $1$ statt $2$ Bio-Milch Porben als nicht Bio-Milch einstuft. Demnach ergibt sich, dass sie auch $4$ statt $3$ nicht Bio-Milch Proben als nicht Bio-Milch erkennt. Andere Szenarien, bei welchen $9$ respektive $10$ Bio-Milch Proben richtig erkannt werden.
:::

::: {#covid-sterblichkeit .exercise}
```{=html}
<!-- 
Ziel: 
- Starke Korrelation gegen Null absichern
-->
```

```{r exr-covid-atemnot}
gen_exr_covid_atemnot <- function(){
  covid <- 27698
  control <- 87337
  
  covid_rf <- 7845
  covid_nrf <- covid-covid_rf
  ncovid_rf <- 18456
  ncovid_nrf <- control-ncovid_rf
  dd <- tibble(atemprobleme = c(rep("ja",2), rep("nein",2)),
               covid = rep(c("ja", "nein"),2),
               anzahl = c(covid_rf, ncovid_rf, covid_nrf, ncovid_nrf))
  file_name <- '09-exr-covid-atemnot.sav'
  dd %>% write_sav(file_name)
  jmv_output <- jmv::contTables(
    dd,
    "atemprobleme",
    "covid",
    "anzahl",
    phiCra = TRUE,
    pcCol = TRUE,
    diffProp = TRUE, relRisk = TRUE, odds = TRUE,
    compare = 'columns'
  )
  jmv_output_freq <- jmv_output$freqs$asDF %>%
    clean_jmv_colnames()
  jmv_output_odds <- jmv_output$odds$asDF %>%
    clean_jmv_colnames()
  jmv_output_test <- jmv_output$chiSq$asDF %>%
    clean_jmv_colnames()
  jmv_output_nom <- jmv_output$nom$asDF %>%
    clean_jmv_colnames()
  return(mget(ls()))
}
exr_covid_atemnot <- gen_exr_covid_atemnot()
```

<!-- TODO: Ausschöpfen odds ratio, etc -->
@cohen2022 haben bei über $65$-jährigen den Zusammenhang zwischen Atemnot und einer SARS-CoV-2-Historie analysiert. Fiktive Daten dazu sind unter
`r inline_code(exr_covid_atemnot$file_name)` abgelegt. 

a) Wie gross ist das Risiko unter Atemnot zu leiden mit und ohne einer SARS-CoV-2 Historie? Identifizieren Sie zuerst ursächliche und Risikovariable.
b) Wie gross ist die Risikodifferenz, das relative Risiko und das Chancenverhältnis?
c) Welche Menschen stellen die Population dar?
d) Lässt sich der Zusammenhang auf die Population ausweiten? Führen Sie einen Test durch und interpretieren Sie die Effektstärke.
:::

::: solution
Zuerst wird der Datensatz mit `Jamovi` eingelesen und die
Analyseparameter werden gesetzt, siehe Abbildung
\@ref(fig:sol-bio-milch-input).

```{r sol-covid-atemnot-input, fig.cap='Jamovi Eingabe.'}
knitr::include_graphics("figures/09-exr-covid-atemnot-jmv-input.jpg")
```

Dies produziert das Analyseergebnis in Abbildung
\@ref(fig:sol-covid-atemnot-output).

```{r sol-covid-atemnot-output, fig.cap='Jamovi Ausgabe.'}
knitr::include_graphics("figures/09-exr-covid-atemnot-jmv-output.jpg")
```

Damit kann die Frage nun beantwortet werden:

a) Das untersuchte schädliche Ereignis ist hier die Atemnot. Als ursache wird die vorhergehende SARS-CoV-2-Infektion betrachtet. Das Risiko nach einer SARS-CoV-2-Infektion an Atemnot zu leiden, liegt bei $`r round(100*exr_covid_atemnot$jmv_output_freq %>% filter(atemprobleme == "ja") %>% pull(all_of("1_pcCol")),1)` \%$. Das Risiko ohne vorhergehende SARS-CoV-2-Infektion an Atemnot zu leiden, liegt bei $`r round(100*exr_covid_atemnot$jmv_output_freq %>% filter(atemprobleme == "ja") %>% pull(all_of("2_pcCol")),1)` \%.$
b) Die Risikodifferenz liegt demnach bei $`r round(100*exr_covid_atemnot$jmv_output_odds$v_dp,1)`\%$, das relative Risiko bei $`r round(exr_covid_atemnot$jmv_output_odds$v_rr,2)`$ und das Chancenverhältnis bei $`r round(exr_covid_atemnot$jmv_output_odds$v_o,2)`$. Eine vorhergehende SarsCov2 Infektion ist also mit einem erhöhten Risiko der Atemnot assoziiert.
c) Da für die Studie nur über $65$-jährige beobachtet wurden, sind alle über $65$-jährigen die Population. Im besten Fall sind die  Studienergebnisse aussagekräftig für diese Gruppe. Im schlimmsten Fall sind sie nur aussagekräftig für die gezogene Stichprobe an über $65$-jährigen.
d) 
> Ein $\chi^2$-Test ergibt, dass das Auftreten von Atemnot (ja/nein) und die SARS-CoV-2-Historie (vorhanden/nicht vorhanden) ($OR = `r round(exr_covid_atemnot$jmv_output_odds$v_o, 2)`$) signifikant voneinander abhängig sind, $\chi^2 (1) = `r round(exr_covid_atemnot$jmv_output_test$value_chiSq,2)`$, $`r report_p(exr_covid_atemnot$jmv_output_test$p_chiSq)`$, $\phi = `r round(exr_covid_atemnot$jmv_output_nom$v_phi, 2)`.$ Der Effekt ist schwach.

:::

## Test

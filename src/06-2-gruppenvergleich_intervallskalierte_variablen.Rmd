# (PART) Zwei Gruppen vergleichen {-}


# Mittelwertunterschied einer intervallskalierten Variable

Bislang wurde versucht mithilfe _einer_ Stichprobe eine Aussage über _eine_ Population zu treffen. Dies setzt voraus, dass der Erwartungswert bereits aus früheren Untersuchungen bekannt ist oder theoretisch hergeleitet werden kann (Beispiel zirkadianer Rhythmus). In der Realität ist dies oft nicht der Fall. Es muss also gleichzeitig etwas über eine potenziell veränderte Population und über die Referenzpopulation herausgefunden werden. Im experimentellen Kontext enspricht dies dem Vergleich der Experimental- mit der Kontrollgruppe. Im observationellen Kontext wird die Referenzgruppe willkürlich bestimmt.

:::{.example #breakup name="Trennungsschmerz"}

```{r exm-breakup}
gen_exm_breakup <- function(){
  mu0 <- 0
  
  mu1 <- 6.84
  s1 <- 2.52
  n1 <- 2695
  mu2 <- 6.58
  s2 <- 2.58
  n2 <- 1409
  var_name <- "ER"

  set.seed(61)
  x_min <- 0
  x_max <- 10
  x1 <- rnorm(n1, mu1, s1) %>% 
    crop(x_min, x_max)
  x2 <- rnorm(n2, mu2, s2) %>% 
    crop(x_min, x_max)
  x1_mean <- x1 %>% mean()
  x2_mean <- x2 %>% mean()
  x1_sd <- x1 %>% sd()
  x2_sd <- x2 %>% sd()
  s_p <- sqrt(weighted.mean(c(s1^2, s2^2), c(n1-1, n2-1)))
  s_means <- s_p * sqrt((1/n1+1/n2))
  x_mean <- x1_mean - x2_mean
  df <- n1 + n2 - 2
  
  
  # x <- scale_factor * rchisq(n, df)
  # scores_hover <- x / 1000 # hovering with K CHF in scale
  # x_mean <- x %>% mean()
  # x_sd <- x %>% sd()
  # t_emp <- (x_mean - mu0)/(x_sd/sqrt(n))
  # p_value_the <- 1-pt((x_mean - 100000)/ (x_sd / sqrt(n)), n-1)
  # effect_size <- (x_mean - mu0) / x_sd

  file_name <- '06-exm-breakup.sav'
  dd <- tibble(emotional_response = c(x1,x2),
         sex = c(rep('male',n1), rep('female', n2))) %>% 
    write_sav(file_name)
  
  jmv_res <- dd %>%
    jmv::ttestIS(vars = c("emotional_response"), 
                 group = "sex",
                 welchs = TRUE, 
                 mann = TRUE, 
                 effectSize = TRUE)
  
  scores_hover1 <- rnorm(20, 3, s1) %>% 
      crop(x_min, x_max)
  scores_hover2 <- rnorm(20, 7, s1) %>% 
      crop(x_min, x_max)
  plot_ball_bag_different <- plot_ball_bag_two_samples(
    scores_bag1 = rnorm(200, 3, s1) %>% 
      crop(x_min, x_max),
    scores_bag2 = rnorm(200, 7, s2) %>% 
      crop(x_min, x_max),
    scores_hover1 = scores_hover1,
    scores_hover2 = scores_hover2,
    score_name = var_name,
    no_legend = TRUE
  )
  
  plot_ball_bag_same <- plot_ball_bag_two_samples(
    scores_bag1 = rnorm(200, 5, s1) %>% 
      crop(x_min, x_max),
    scores_bag2 = rnorm(200, 5, s2) %>% 
      crop(x_min, x_max),
    scores_hover1 = scores_hover1,
    scores_hover2 = scores_hover2,
    score_name = var_name
  )
  

  # distribution if H_0 were true
  n_samples <- 3000L
  x1_means <- 1:n_samples %>%
    map_dbl(~ rnorm(n1,mean(mu1, mu2), s1) %>% 
            crop(x_min, x_max) %>% 
            mean())
  x2_means <- 1:n_samples %>%
    map_dbl(~ rnorm(n2, mean(mu1, mu2), s2) %>% 
              crop(x_min, x_max) %>% 
              mean()
    )
  means_diff <- x1_means - x2_means
  q975_x_means <- means_diff %>% quantile(c(0.975)) %>% unlist() %>% unname()
  q025_x_means <- means_diff %>% quantile(c(0.025)) %>% unlist() %>% unname()
  p_value_emp <- mean(means_diff > mean(x1) - mean(x2) | 
                        means_diff < 0 + (0 - mean(x1) - mean(x2)))
  plot_hist <- plot_hist_denstiy_expected_value(
    means = means_diff,
    mu = 0,
    sigma = s_p,
    1/(1/n1+1/n2),
    xlab = "ER-Mittelwertdifferenz",
    binwidth = 0.02)
  
  sigma_g <- s_means
  line_xlim <- xlim(3.5*sigma_g*c(-1, 1))
  x_range <- seq(0-3*sigma_g, 0+3*sigma_g, length.out = 1000)
  
  create_text_data <- function(labels, y_value, plot_type) {
    tibble(
      label = labels,
      x = c(98, 102),
      y = rep(y_value, 2),
      color = c("red", "green"),
      plot_type = plot_type
    )
  }
  
  
  add_colors <- function(x, type){
    if(type == "Histogram"){
      x <- x %>% 
      mutate(
      color = case_when(
        plot_type == type %>% str_c(" p-Wert") & 
          (abs(x_mean - mu0) > abs(x - mu0)) ~ "red",
        (plot_type == type %>% str_c(" Ablehnungsbereich")) & 
          (x <= q975_x_means & x >= q025_x_means) ~ "red",
        TRUE ~ "green",
      )
    )
    }else{
      x <- x %>% 
        mutate(
        color = case_when(
          plot_type == type %>% str_c(" p-Wert") & x > x_mean & x < mu0 + (mu0 - x_mean) ~ "red",
          plot_type == type %>% str_c(" p-Wert") & (x <= x_mean | x >= mu0 + (mu0 - x_mean)) ~ "green",
          (plot_type == type %>% str_c(" Ablehnungsbereich")) & 
            (x > mu0 + qt(0.975, n-1)*x_sd/sqrt(n) | x < mu0 - qt(0.975, n-1)*x_sd/sqrt(n))~ "green",
          (plot_type == type %>% str_c(" Ablehnungsbereich")) & 
            (x <= mu0 + qt(0.975, n-1)*x_sd/sqrt(n) & x >= mu0 - qt(0.975, n-1)*x_sd/sqrt(n)) ~ "red"
        )
      )
    } 
    x %>% 
      mutate(color  = color %>% 
      factor(levels = c("green", "red")))
  }
  # Create data for histograms
  histogram_data <- tibble(
    x = rep(means_diff, 2),
    plot_type = rep(c("Histogram p-Wert", 
                      "Histogram Ablehnungsbereich"), 
                    each = length(means_diff))
  ) %>%
    add_colors("Histogram")
  
  # Create text data for all plots
  text_pval <- str_c(round(100 * c(1 - p_value_emp, p_value_emp), 1), '%')
  text_sign <- c('95%', '5%')
  text_data_all <- bind_rows(
    create_text_data(
      text_pval,
      200,
      "Histogram p-Wert"
    ),
    create_text_data(
      text_sign, 
      200,
      "Histogram Ablehnungsbereich"
    )
  )
  
  custom_labeller <- as_labeller(c(
    "Histogram p-Wert" = "p-Wert",
    "Histogram Ablehnungsbereich" = "Ablehnungsbereich"
  ))
  
  plot_hist_pval_reja <- ggplot() +
    geom_histogram(data = histogram_data,
                   aes(x = x, fill = color),
                   binwidth = 0.02) +
    geom_vline(xintercept = x_mean) +
    geom_text(data = text_data_all,
              mapping = aes(x = x, y = y, label = label, colour = color)) +
    facet_wrap(~ plot_type, nrow = 1, scales = "free_y", 
               strip.position = "top",
               labeller = custom_labeller) +
    line_xlim +
    theme(
      axis.text.y = element_text(),
      axis.ticks.y = element_line(),
      axis.title.y = element_text(),
      strip.placement = "outside",
      legend.position = "none"
    ) +
    labs(x = "ER-Mittelwertdifferenz", y = "Häufigkeit")


  return(mget(ls()))
}
exm_breakup <- gen_exm_breakup()
```

@morris2015 haben untersucht, ob das Geschlecht einen Einfluss auf den Schmerz bei der Auflösung einer romantischen Beziehung hat. Die Autoren unterscheiden dabei zwischen emotionaler (Angst, Wut, Depression, Taubheit, usw.) und physischer Reaktion (Essgewohnheit, Schlaf, Gewicht, Panik, Immunsystem). Hier wird nur auf erstere Fokusiert, welche mit _ER_ abgekürzt wird. Dazu wurde mit erlösfreien Online-Umfragen unter anderem erfragt, ob die Person eine Trennung erlebt hat und wie sie ihren emotionalen Trennungsschmerz von $0$ (keine Schmerzen) bis $10$ (unerträglich) einstuft. An der Studie haben $N_\text{Frau} = `r exm_breakup$n1`$ Frauen und $N_\text{Mann} = `r exm_breakup$n2`$ Männer mitgemacht, welche eine ER von $M_\text{Frau} = `r round(exm_breakup$x1_mean,2)`, SD_\text{Frau} = `r round(exm_breakup$x1_sd,2)`$  und $M_\text{Mann} = `r round(exm_breakup$x2_mean,2)`, SD_\text{Mann} = `r round(exm_breakup$x2_sd,2)`$ respektive aufwiesen. 
:::

## Was ist das Problem der Stichprobenziehung?

In der Stichprobe kann also ein kleiner geschlechterspezifischer Mittelwertunterschied der ER beobachtet werden. Dieser Mittelwertunterschied könnte nun einerseits auf einen Mittelwertunterschied in der Population zurückzuführen sein, wie in Abbildung \@ref(fig:exm-breakup-bagplot) links dargestellt. Hier gibt es zwei Populationen: Frauen-Population  mit höheren und Männer-Population  mit tieferen ER-Werten. Dies führt dazu, dass der Erwartungswert der Frauen-Population höher ist als bei Männer-Population und eine zufällige gezogene stichprobe aus Frauen-Population auch ein höheres arithmetisches Mittel aufweist als Männer-Population.

Andererseits könnte der Mittelwertunterschied auch auf die zufällige Stichprobenziehung zurückzuführen sein Abbildung \@ref(fig:exm-breakup-bagplot) rechts. In dieser Situation haben die Frauen- und die Männer-Populationen ähnliche Werte und demnach auch einen ähnlichen Erwartungswert. Beim Ziehen der Stichproben spielt der Zufall hier so, dass aus der Frauen-Population einige Beobachtungen mehr mit hohen ER-Werten ausgewählt wurden als bei der Männer-Population. Dies führt dazu, dass in den zwei Stichproben ein Unterschied im arithmetischen Mittel der ER beobachtet werden kann. 

```{r exm-breakup-bagplot, fig.cap="Links: Zwei Stichprobenziehungen aus zwei Populationen mit unterschiedlichen Mittelwerten. Rechts: Zwei Stichprobenziehungen aus einer Populationen, bzw. aus zwei Populationen die sich bezüglich ihrer Werte nicht unterscheiden."}
grid.arrange(exm_breakup$plot_ball_bag_different,
             exm_breakup$plot_ball_bag_same, 
             ncol = 2)
```

<!-- Discuss: welchen zwei anderen Möglichkeiten sind hier nicht dargestellt? -->

Welche dieser Situationen zutrifft kann nicht genau herausgefunden werden, da die Population nie vollständig beobachtet werden kann.

Um trotzdem eine Aussage über die Population zu treffen, kann wie bereits mehrmals gemacht, die Stichprobenziehung oft - beispielsweise $`r exm_breakup$n_samples`$-mal - wiederholt werden. Dies wird unter der Annahme gemacht, dass es keinen ER-Erwartungswertunterschied zwischen der Frauen- und Männer-Population gibt. Die Verteilung der ER-Mittelwertdifferenzen dieser Stichproben ist in Abbildung \@ref(fig:exm-breakup-hist) dargestellt. 

```{r exm-breakup-hist, fig.cap="TODO."}
exm_breakup$plot_hist
```




Das Testprinzip funktioniert genau gleich wie beim $t$-Test für eine Stichprobe wie in Kapitel \@ref(zentrale-tendenz-testen). Zunächst werden die Hypothesen aufgestellt. A priori liegt keine Vermutung darüber vor, ob Männer oder Frauen eine stärkere ER zeigen. Die Null- und Alternativhypothese sind deshalb

> $H_0: \mu_\text{Frau} = \mu_\text{Mann}$
>
> $H_1: \mu_\text{Frau} \neq \mu_\text{Mann}.$

Dies entspricht, einfacher Arithmetik folgend, 

> $H_0: \mu_\text{Frau} - \mu_\text{Mann} = 0$
>
> $H_1: \mu_\text{Frau} - \mu_\text{Mann} \neq 0.$

Es kann beobachtet werden, dass, wenn es keine Erwartungswertdifferenz gibt, die Mittelwertdifferenzen der Stichproben am häufigsten bei $0$ liegen und mit zunehmender Entfernung von $0$ unwahrscheinlicher werden. Dies kann wieder formalisiert werden indem die $5\%$ unwahrscheinlichsten Werte ($2.5\%$ links und $2.5\%$ rechts) zum Ablehnungsbereich erklärt werden und entspricht der roten Fläche in Abbildung \@ref(fig:exm-breakup-hist-pval-reja) links. Die tatsächlich beobachtete Mittelwertdifferenz (schwarze Linie) liegt im Ablehnungsbereich. Dies bedeutet dass sich die Erwartungswertdifferenz bei Signifikanziniveau $5\%$ signifikant von $0$ unterscheidet. Dies ist äquivalent zu der Aussage, dass sich die ER-Erwartungswerte der Männer und Frauen signifikant unterscheidet.

```{r exm-breakup-hist-pval-reja, fig.cap="TODO"}
exm_breakup$plot_hist_pval_reja
```
<!-- Discuss: warum ist p-Wert nur rechts? Es hat keine Beobachtungen kleiner als -0.237. -->

Ebenfalls kann erneut der p-Wert berechnet werden. Dieser entspricht hier allen ER-Mittelwertdifferenzen, welche _extremer_ als die beobachtete Mittelwertdifferenz $`r round(exm_breakup$x_mean,2)`$ sind. Da die Hypothesenstellung hier zweiseitig ist, bedeutet extremer hier wieder grösser als $`r round(exm_breakup$x_mean,2)`$ oder kleiner als $`r round(-exm_breakup$x_mean,2)`$. Der $p$-Wert enspricht dem Anteil der roten Fläche in Abbildung \@ref(fig:exm-breakup-hist-pval-reja) rechts an der Gesamtfläche und beträgt $`r round(exm_breakup$p_value_emp,3)`$.

Die Verteilung der Mittelwertdifferenzen unter der Annahme, dass die Nullhypothese wahr ist, kann wieder mit einer Kurve angenähert werden. Diese Annäherung hat den Vorteil, dass der Ablehnungsbereich und der $p$-Wert abgeschätzt werden kann ohne dass dazu das Experiment wiederholt werden muss. Für die Annäherungskurve gibt es zwei Optionen, welche dann entsprechenden Tests ihre Namen geben: der Zweistichproben-$t$-Test nach Student und der Welch Test.

### Erwartungswertunterschied Zweistichproben-$t$-Test nach Student

Der Zweistichproben-$t$-Test setzt voraus, dass die beiden Populationen eine ähnliche Varianz haben. Dazu später mehr. Ist dies gegeben, so kann die Teststatistik mit

\begin{equation}
t = \frac{\bar{x_1}-\bar{x_2} - \omega_0}{\sqrt{\frac{(n_1 - 1) s_1^2)+(n_2-1)s_2^2}{n_1 + n_2 - 2}}\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}
(\#eq:t-emp-twosample-t)
\end{equation}

berechnet werden, wobei $\omega_0 = \mu_1 - \mu_2$ der Erwartungswertdifferenz entspricht und in unserem Fall $0$ beträgt. Wenn die Nullhypothese wahr ist, so ist diese Teststatistik bei wiederholter Stichprobenziehung $t$-verteilt bei $df = n_1 + n_2 -2$ Freiheitsgraden.

### Erwartungswertunterschied Welch Test

\begin{equation}
t = \frac{\bar{x_1}-\bar{x_2} - \omega_0}{\sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}}
(\#eq:t-emp-twosample-welch)
\end{equation}


## Übungen

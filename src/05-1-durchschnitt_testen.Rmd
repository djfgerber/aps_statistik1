# Zentrale Tendenz testen {#zentrale-tendenz-testen}

Eine andere Fragestellung, die mit Daten oft beantwortet wird ist, ob eine gewisse Aussage wahr ist oder falsch. [Eine solche Aussage wird **Hypothese** (Symbol: $H$) genannt.]{.customdef #customdef-hypothese} Eine Hypothese könnte zum Beispiel sein: 

> $H:$ Es regnet. 

Ist die Hypothese einmal gefunden, können Daten gesammelt werden, um diese Hypothese zu bestätigen oder zu falsifizieren. Man geht nach draussen und spürt Regen auf der Haut bedeutet $H$ ist wahr, spürt man keinen Regen, so ist $H$ falsch.

Wenn eine Hypothese wahr ist, dann ist das Gegenteil der Hypothese falsch. Weil oft über die Hypothese und ihr Gegenteil debattiert wird, ist es nützlich die beiden auch terminologisch auseinanderhalten zu können. [Die Hypothese, welche den bisherigen Informationsstand reflektiert wird **Nullhypothese** (Symbol $H_0$) genannt.]{.customdef #customdef-nullhypothese} War es draussen bei der letzten Messung vor einer Stunde schönes Wetter, dann ist die Nullhypothese

> $H_0:$ Es regnet nicht. 

[Das Gegenteil der Nullhypothese wird **Alternativhypothese** (Symbol $H_1$) genannt.]{.customdef #customdef-alternativhypothese} Im Beispiel ist die Alternativhypothese 

> $H_1:$ Es regnet.

## Entspricht der Erwartungswert einem gewissen Wert?

Um eine Hypothese mit Daten überprüfbar zu machen, muss diese in eine Form gebracht werden, welche Daten einbezieht. Eine einfache Form einer solchen überprüfbaren Hypothese ist 

> $H:$ Das durchschnittliche Vermögen einer in der Schweiz lebenden Person beträgt $100'000$ CHF. 

Wenn die Population alle in der Schweiz lebenden Personen sind, dann entspricht dies also der Nullhypothese

> $H_0:\mu = 100'000$. 

Abstrahiert, soll bei dieser Problemstellung herausgefunden werden, ob der Erwartungswert einer Population einem gewissen Wert entspricht. Das Gegenteil dieser Nullhypothese ist die Alternativhypothese 

> $H_1: \mu \neq 100'000$. 

Dies bedeutet, dass das Vermögen der Population nicht bei $100'000$ CHF liegt. [Weil die Alternativhypothese hier zwei Ausgänge zulässt, nämlich kleiner oder grösser als $100'000$ CHF wird diese Art **zweiseitige Hypothese** bezeichnet.]{.customdef #customdef-zweiseitige-hypothese}

Eine weitere Form der Hypothese wäre 

> $H:$ Das durchschnittliche Vermögen einer in der Schweiz lebenden Person beträgt weniger als oder genau $100'000$ CHF. 

In Formelsprache übersetzt entspricht dies 

> $H_0: \mu \leq 100'000$. 

Das Gegenteil davon ist, wenn das durchschnittliche Vermögen grösser und ungleich 100'000 CHF ist, also 

> $H_1: \mu > 100'000$. 

::::{.caution data-latex=""}
::: {.remark}
Die verwendeten Zeichen in den Formeln sind

- $=$: Gleichheit, sprich "gleich". Beispiele: 
    - $3 = 3$ ($3$ gleich $3$) ist eine wahre Aussage. 
    - $3 = 4$ ($3$ gleich $4$) ist eine falsche Aussage.
- $\neq$: Ungleichheit, sprich "ungleich" oder "nicht gleich". Beispiele: 
    - $3 \neq 3$ ($3$ ist nicht gleich $3$) ist eine falsche Aussage. 
    - $3 \neq 4$ ($3$ ist nicht gleich $4$) ist eine wahre Aussage.
- $<$: Kleiner, sprich "kleiner". Beispiele: 
    - $4 < 3$ ($4$ ist kleiner als $3$) ist eine falsche Aussage. 
    - $3 < 3$ ($3$ ist kleiner als $3$) ist eine falsche Aussage. 
    - $3 < 4$ ($3$ ist kleiner als $4$) ist eine wahre Aussage.
- $\leq$: Kleiner gleich, sprich "kleiner gleich". Beispiele: 
    - $4 \leq 3$ ($4$ ist kleiner oder gleich wie $3$) ist eine falsche Aussage.
    - $3 \leq 3$ ($3$ ist kleiner oder gleich wie $3$) ist eine wahre Aussage. 
    - $3 \leq 4$ ($3$ ist kleiner oder gleich wie $4$) ist eine wahre Aussage.
- $>$: Grösser, sprich "grösser". Beispiele: 
    - $4 > 3$ ($4$ ist grösser als $3$) ist eine wahre Aussage. 
    - $3 > 3$ ($3$ ist grösser als $3$) ist eine falsche Aussage. 
    - $3 > 4$ ($3$ ist grösser als $4$) ist eine falsche Aussage.
- $\geq$: Grösser gleich, sprich "grösser gleich". Beispiele: 
    - $4 \geq 3$ ($4$ ist grösser oder gleich wie $3$) ist eine wahre Aussage. 
    - $3 \geq 3$ ($3$ ist grösser oder gleich wie $3$) ist eine wahre Aussage. 
    - $3 \geq 4$ ($3$ ist grösser oder gleich wie $4$) ist eine falsche Aussage.
    
:::
::::


:::{.example #vermoegen name="Vermögen"}

```{r exm-vermoegen}
gen_exm_vermoegen <- function(){
  # x ~ chisq(df)
  # a * x ~ a chisq(df)
  # E(a*x) ~ a E(chisq(df)) = a df
  # Var(a*x) ~ a^2 Var(x) = a^2 2k / n
  df <- 3L
  mu0 <- 100000
  scale_factor <- mu0/df
  
  n <- 20L
  set.seed(61)
  x <- scale_factor * rchisq(n, df)
  scores_hover <- x / 1000 # hovering with K CHF in scale
  x_mean <- x %>% mean()
  x_sd <- x %>% sd()
  t_emp <- (x_mean - mu0)/(x_sd/sqrt(n))
  p_value_the <- 1-pt((x_mean - 100000)/ (x_sd / sqrt(n)), n-1)
  effect_size <- (x_mean - mu0) / x_sd

  
  file_name <- '05-exm-vermoegen.sav'
  tibble(vermoegen = x) %>% write_sav(file_name)
  
  # distribution if H_0 were true
  n_samples <- 3000L
  x_means <- 1:n_samples %>% 
    map_dbl(~ mean(scale_factor*rchisq(n, df)))
  q95_x_means <- x_means %>% quantile(c(0.95)) %>% unlist() %>% unname()
  p_value_emp <- mean(x_means > x_mean)
  
  # plot sampling bag
  n_bag <- 200L
  scores_bag <- list(40*rchisq(n_bag,df),
                   60*rchisq(n_bag,df))
  plots <- list()
  for (i in 1:length(scores_bag)) {
    plots[[i]] <- plot_ball_bag(
      scores_bag = scores_bag[[i]],
      scores_hover = scores_hover,
      score_name = "1000 CHF",
      seed = 123+i,
      no_legend = c(TRUE, FALSE)[i],
      limit_scores = c(0, 800)
    )
  }
  
  # plot histogram of sample means
  plot_hist_density <- plot_hist_denstiy_expected_value(
    x_means, 
    scale_factor*df, 
    sqrt((scale_factor)^2*2*df), 
    n,
    "Vermögen CHF",
    5000)
  
  line_xlim <- xlim(c(40000, 180000))
  sigma_g <- x_sd / sqrt(n)
  x_range <- seq(mu0-3*sigma_g, mu0+3*sigma_g, length.out = 1000)
  
  # Function to create text data
  create_text_data <- function(labels, y_value, plot_type) {
    tibble(
      label = labels,
      x = c(60000, 160000),
      y = rep(y_value, 2),
      color = c("red", "green"),
      plot_type = plot_type
    )
  }
  
  
  add_colors <- function(x, type){
    x %>% 
      mutate(
      color = case_when(
        plot_type == type %>% str_c(" p-Wert") & x > x_mean ~ "green",
        plot_type == type %>% str_c(" p-Wert") & x <= x_mean ~ "red",
        plot_type == type %>% str_c(" Ablehnungsbereich") & x > q95_x_means ~ "green",
        plot_type == type %>% str_c(" Ablehnungsbereich") & x <= q95_x_means ~ "red"
      )
    )
  }
  # Create data for histograms
  histogram_data <- tibble(
    x = rep(x_means, 2),
    plot_type = rep(c("Histogram p-Wert", 
                      "Histogram Ablehnungsbereich"), 
                    each = length(x_means))
  ) %>%
    add_colors("Histogram")
  
  # Create data for density plots
  density_data <- tibble(
    x = rep(x_range, 2),
    y = dt((x - mu0) / sigma_g, n - 1) / sigma_g,
    plot_type = rep(c("Verteilung p-Wert", 
                      "Verteilung Ablehnungsbereich"), 
                    each = length(x_range))
  ) %>%
    add_colors("Verteilung")
  
  # Create text data for all plots
  text_pval <- str_c(round(100 * c(1 - p_value_emp, p_value_emp), 1), '%')
  text_sign <- c('95%', '5%')
  text_data_all <- bind_rows(
    create_text_data(
      text_pval,
      200,
      "Histogram p-Wert"
    ),
    create_text_data(
      text_sign, 
      200,
      "Histogram Ablehnungsbereich"
    ),
    create_text_data(
      round(100 *c(1-p_value_the,p_value_the),1) %>% 
        str_c('%'),
      0.000015, 
      "Verteilung p-Wert"
    ),
    create_text_data(
      text_sign, 
      0.000015,
      "Verteilung Ablehnungsbereich"
    )
  )
  
  custom_labeller <- as_labeller(c(
    "Histogram p-Wert" = "p-Wert",
    "Histogram Ablehnungsbereich" = "Ablehnungsbereich",
    "Verteilung p-Wert" = "p-Wert",
    "Verteilung Ablehnungsbereich" = "Ablehnungsbereich"
  ))
  
  plot_hist_curve_pval_reja <- ggplot() +
    geom_histogram(data = histogram_data,
                   aes(x = x, fill = color),
                   binwidth = 4300) +
    geom_line(data = density_data,
              aes(x = x, y = y, colour = color)) +
    geom_area(data = density_data,
              aes(x = x, y = y, fill = color)) +
    geom_vline(xintercept = x_mean) +
    geom_text(data = text_data_all,
              mapping = aes(x = x, y = y, label = label, colour = color)) +
    facet_wrap(~ plot_type, nrow = 2, scales = "free_y", 
               strip.position = "top",
               labeller = custom_labeller) +
    line_xlim +
    theme(
      axis.text.y = element_text(),
      axis.ticks.y = element_line(),
      axis.title.y = element_text(),
      strip.placement = "outside",
      legend.position = "none"
    ) +
    labs(x = "Vermögen", y = "W.-dichte                              Häufigkeit")

  return(mget(ls()))
}
exm_vermoegen <- gen_exm_vermoegen()
```

<!-- ```{r} -->
<!-- 1-pnorm(mean(exm_vermoegen$x), 100000, sd(exm_vermoegen$x_means)) -->
<!-- 1-pnorm(mean(exm_vermoegen$x), 100000, sd(exm_vermoegen$x) / sqrt(exm_vermoegen$n)) -->

<!-- 1-pt((mean(exm_vermoegen$x) - 100000)/ sd(exm_vermoegen$x_means), exm_vermoegen$n-1) -->
<!-- 1-pt((mean(exm_vermoegen$x) - 100000)/ (sd(exm_vermoegen$x) / sqrt(exm_vermoegen$n)), exm_vermoegen$n-1) -->
<!-- ``` -->

Eine Sozialpolitikberatungsfirma will herausfinden, ob das durchschnittliche Vermögen der in der Schweiz lebenden Personen im letzten Jahr gestiegen ist. Sie stellen dazu basierend auf dem aktuellen Wissensstand die Nullhypothese auf, dass das durchschnittliche Vermögen nicht gestiegen ist, und die Alternativhypothese, dass das durchschnittliche Vermögen gestiegen ist:

> $H_0: \mu \leq 100'000$ CHF

> $H_1: \mu > 100'000$ CHF

Um die Hypothesen auf einer Datengrundlage zu evaluieren, erfragt es das Vermögen von $n=`r exm_vermoegen$n`$ zufällig ausgewählten Personen und findet ein durchschnittliches Vermögen von $M=`r round(mean(exm_vermoegen$x))`$ CHF.

:::

Es kann nun schnell gesagt werden, dass das durchschnittliche Vermögen in der Population gestiegen ist, weil $193'000$ CHF grösser ist als $100'000$ CHF. Dies so zu behaupten wäre jedoch falsch, weil nicht alle Personen in der Population befragt wurden, sondern lediglich eine Zufallsstichprobe. Wie in Kapitel \@ref(stichprobenziehung) muss hier für eine Generalisierung der Stichprobe auf die Population der Effekt der zufälligen Stichprobenziehung miteinbezogen werden. 

Aufgrund der Zufallsstichprobe ist es unmöglich zu sagen, ob unsere Stichprobe eine eher seltene Stichprobenziehung aus einer Population mit unverändertem durchschnittlichen Vermögen von $100'000$ CHF ist (Abbildung \@ref(fig:exm-vermoegen-sampling-plot) links) oder ob es eine eher häufig vorkommende Stichprobenziehung aus einer Population mit höherem durchschnittlichen Vermögen ist (Abbildung \@ref(fig:exm-vermoegen-sampling-plot) rechts). 

```{r exm-vermoegen-sampling-plot, fig.cap="Vorgestellte Zufallsstichprobenziehung. Links: Nullhypothese ist wahr. Rechts: Nullhypothese ist falsch.", echo = FALSE}
do.call(grid.arrange, c(exm_vermoegen$plots, ncol = 2))
```

Es kann jedoch ausgesagt werden, mit welcher Wahrscheinlichkeit der gefundene Stichprobenmittelwert realisiert wird, gegeben dass die Nullhypothese wahr ist. Hier wird also angenommen, dass eine Population mit Erwartungswert $\mu = 100'000$ CHF vorliegt und dass anschliessend zum Beispiel $`r exm_vermoegen$n_samples`$ Stichproben an je $`r exm_vermoegen$n`$ Beobachtungen pro Stichprobe gezogen werden. Von jeder dieser Stichproben wird das arithmetische Mittel berechnet. In der Verteilung dieser Mittelwerte, siehe Abbildung \@ref(fig:exm-vermoegen-histogram-plot), wird nun der tatsächliche Mittelwert der Stichprobe $\bar{x} = `r round(exm_vermoegen$x %>% mean())`$ verortet. 

```{r exm-vermoegen-histogram-plot, fig.cap="TODO.", echo = FALSE}
exm_vermoegen$plot_hist_density + 
  geom_vline(xintercept = exm_vermoegen$x %>% mean())+
  scale_x_continuous(n.breaks = 10)
```

Der beobachtete Mittelwert ist zwar nicht genau bei $100'000$ CHF, aber trotzdem noch einigermassen plausibel, wenn die Nullhypothese stimmt. Um diesen Gedanken zu formalisieren, gibt es zwei Denkweisen, welche nun vorgestellt werden.

Die eine von Ronald Fisher Denkweise ist die Frage nach der Wahrscheinlichkeit, dass der beobachtete Wert oder ein noch extremerer Wert in Richtung der Alternativhypothese resultiert. Im Beispiel entspricht dies der Wahrscheinlichkeit den Wert $`r round(exm_vermoegen$x %>% mean())`$ oder einen grösseren Wert zu beobachten, wenn der Erwartungswert tatsächlich bei $100'000$ CHF liegt. Um diese Wahrscheinlichkeit zu bestimmen, kann einfach gezählt werden, welcher Anteil der Stichprobenmittel werte grösser oder gleich $`r round(exm_vermoegen$x %>% mean())`$ CHF ist. Im Beispiel sind dies $`r round(exm_vermoegen$p_value_emp,3)` = `r round(exm_vermoegen$p_value_emp*100,1)`\%$. [Dieser Wert wird, abgeleitet vom englischen _probability_ auch __p-Wert__ (Symbol: $p$) genannt. Beim Berichten des p-Werts wird normalerweise die führende $0$ nicht geschrieben, also $p = `r round(exm_vermoegen$p_value_emp,3) %>% str_sub(2)`$.]{.customdef #customdef-pwert} 

[Bei der anderen Denkweise muss noch vor der Datenerhebung ein sogenanntes **Signifikanzniveau** (Symbol $\alpha$, sprich 'alpha')  bestimmt werden. Dieser Wert entspricht der Wahrscheinlichkeit, dass der statistische Test die Nullhypothese verwirft, obwohl diese wahr gewesen wäre. Normalerweise wird $\alpha = 5\%$ gesetzt.]{.customdef #customdef-signifikanzniveau} Es wird also akzeptiert, dass ein statistischer Test in $5\%$ der Fälle gegen die Nullhypothese entscheidet, obwohl diese wahr wäre. [In einem zweiten Schritt wird bestimmt, welches die $5\%$ unwahrscheinlichsten Werte sind, wenn die Nullhypothese wahr ist. Diese Werte werden **Ablehnungsbereich** genannt.]{.customdef #customdef-ablehnungsbereich} Im Beispiel sind dies die $5\%$ höchsten Werte, nämlich Vermögen von $`r round(exm_vermoegen$q95_x_means)`$ CHF und grössere Vermögen. Nun wird bestimmt, ob der tatsächliche beobachtete Wert im Ablehnungsbereich liegt oder nicht. [Im Beispiel liegt der Stichprobenmittelwert $`r round(exm_vermoegen$x_mean)`$ CHF nicht im Ablehnungsbereich. In diesem Fall wird die Nullhypothese nicht verworfen und das Testresultat erhält das Prädikat **nicht signifikant**. Läge der Stichprobenmittelwert im Ablehnungsbereich, so wäre das Testresultat als **signifikant** einzustufen.]{.customdef #customdef-signifikanz}

::::{.caution data-latex=""}
::: {.remark}
Ein signifikanter Unterschied bedeutet im allgemeinen Sprachgebrauch ein _bedeutsamer, substanzieller_ Unterschied. Im statistischen Kontext bedeutet ein _signifikanter Unterschied_, wie oben beschrieben, dass ein Unterschied bis auf eine gewisse Irrtumswahrscheinlichkeit (angegeben durch das Signifikanzniveau) _nicht zufällig_ zustande gekommen ist. Ein _nicht signifikanter Unterschied_ bedeutet dagegen, dass die Beobachtung _zufällig_ zustande gekommen sein könnte. Für letzteres gibt es zwei Erklärungen: (1) $H_0$ ist tatsächlich wahr. (2) $H_0$ ist zwar falsch, aber die Stichprobenziehung hat zufällig zu einem ähnlichen Resultat geführt, wie wenn $H_0$ wahr wäre. Ist ein Testresultat nicht signifikant, so kann also nicht genau gesagt werden, ob $H_0$ wahr ist oder nicht. Ist das Testresultat signifikant, so ist $H_0$ eher unwahrscheinlich.

In manchen Texten werden allgemeine und auch statistische Fragen bearbeitet. Hier empfiehlt sich für den allgemeinen Sprachgebrauch _substanziell_ und für die statischen Aussagen _statistisch signifikant_ zu verwenden.

Es wird ausserdem empfohlen, das Wort signifikant immer nur als Prädikat für eine Qualifizierung der Nullhypothese zu verwenden. Im Beispiel war $H_0: \mu \leq 100'000$CHF. Korrekte Aussage sind: 
- Das durchschnittliche Vermögen ist im letzten Jahr nicht signifikant gewachsen.
- Das durchschnittliche Vermögen ist in diesem Jahr nicht signifikant grösser als $100'000$ CHF.

:::
::::

Die beiden Denkarten entsprechen sich insofern, als ein $p$-Wert kleiner als $5\%$ ein signifikantes Resultat bei Signifikanzniveau $\alpha = 5\%$ bedeutet. In der Praxis werden beide Methoden verwendet. Im Beispiel liegt der $p$-Wert bei $p = `r round(exm_vermoegen$p_value_emp,3) %>% str_sub(2)`$. Dies bedeutet, dass die Wahrscheinlichkeit zufällig den realisierten Stichprobenmittelwert zu kommen, gegeben, dass die Nullhypothese stimmt, grösser als $5\%$ ist und demnach auch der Unterschied nicht signifikant ist.

Ein noch zu lösendes Problem ist, dass normalerweise Geld, Zeit und Nerven fehlen, um eine Stichprobenziehung $`r exm_vermoegen$n_samples`$ mal zu wiederholen. Hier hilft es wieder zu beobachten, dass die Verteilung der Werte des Histogramms in Abbildung \@ref(fig:exm-vermoegen-histogram-plot) wieder mit zunehmender Stichprobengrösse immer genauer einer Normalverteilung folgen. Tatsächlich trifft es aufgrund des [zentralen Grenzwertsatzes](#customdef-zentraler-grenzwertsatz) immer zu, dass wenn ein Merkmal mit $N$ Beobachtungen, Erwartungswert $\mu$ und Standardabweichung $\sigma$ hat, der Wert

$$z = \frac{\bar{x}-\mu}{\frac{\sigma}{\sqrt{n}}}$$
normalverteilt ist, wobei $\mu$ hier dem Wert der Nullhypothese entspricht, also $100'000$ CHF. Dies entspricht der roten Linie in Abbildung \@ref(fig:exm-vermoegen-histogram-plot). Ist die Standardabweichung des Merkmals unbekannt, so wird diese mit $s$ geschätzt. Diese zusätzliche Unsicherheit führt dazu, dass
\begin{equation}
t = \frac{\bar{x}-\mu}{\frac{s}{\sqrt{n}}}
(\#eq:t-emp-onesample)
\end{equation}
<!-- TODO: Discuss: I don't give the numerical values for t because they do not correspond to the distribution in the figure below because of the scaling and would therefore confuse the reader. -->
nicht mehr normal-, sondern $t$-verteilt ist bei $n-1$ Freiheitsgraden (grüne Linie, Abbildung \@ref(fig:exm-vermoegen-histogram-plot)). Die $t$-Verteilung mit allen Freiheitsgraden ist in `Jamovi` hinterlegt und es kann der Software überlassen werden den $p$-Wert und den Ablehnungsbereich genau zu bestimmen. In Abbildung \@ref(fig:exm-vermoegen-plots-sampling-theorie) wurde nochmal illustriert, dass es bei vielen Beobachtungen der theoretische $p$-Wert (Kurve) mit dem empirischen $p$-Wert der Simulationen (Histogramm) übereinstimmt respektive der Ablehnungsbereich der $t$-Verteilung (Kurve) gleich ist, wie der simulierte Ablehnungsbereich (Histogramm).

<!-- TODO: Discuss  -->
<!-- - why p-Wert does not correspond exactly to empirical p-Wert? -->
<!-- - what is that uncertainty w.r.t. the rejection area? -->

```{r exm-vermoegen-plots-sampling-theorie, fig.cap="Oben: Histogramm der simulierten Verteilung; unten: theoretische t-Verteilung; links: Illustration p-Wert; rechts: Illustration Ablehnungsbereich. Die Linie entspricht dem beobachteten Stichprobenmittelwert."}
exm_vermoegen$plot_hist_curve_pval_reja
```

[Die Berechnung des für den Test relevanten Wertes, hier des $t$-Wertes wird **Teststatistik** (oder auch _Prüfgrösse_ oder nur _Statistik_) genannt.]{.customdef #customdef-teststatistik} Eine Teststatistik hat normalerweise eine bekannte theoretische Verteilung, welcher die Teststatistik folgt, wenn die Nullhypothese wahr ist. [Aufgrund der theoretischen $t$-Verteilung der Statistik wird dieser Test **$t$-Test** genannt.]{.customdef #customdef-t-test}

Das oben gefundene Resultat wird in der folgenden Form berichtet:

> Das durchschnittliche Vermögen ($M = `r round(exm_vermoegen$x_mean)`$ CHF, $SD = `r round(exm_vermoegen$x_sd)`$, $N = `r round(exm_vermoegen$n)`$) ist in diesem Jahr nicht signifikant grösser als $100'000$ CHF, $t(`r round(exm_vermoegen$n-1)`) = `r round(exm_vermoegen$t_emp,3)`$, $p = `r round(exm_vermoegen$p_value_the,3) %>% str_sub(start = 2L)`$.

::::{.caution data-latex=""}
::: {.remark}
Folgende Begriffe und Zahlen werden dabei verwendet:

- Das _durchschnittliche_ Vermögen (fehlt durchschnittlich ist die Aussage falsch).
- $M$, $SD$, $N$ entsprechen dem arithmetischen Mittel, der geschätzten Standardabweichung und der Anzahl Beobachtungen in der Stichprobe. Die Einheit muss nicht wiederholt werden.
- Signifikanz (siehe letzter Hinweis)
- grösser als $100'000$ CHF ist die Referenz zur Alternativhypothese
- $t(`r round(exm_vermoegen$n-1)`)$ bedeutet, dass die Teststatistik $t$-verteilt ist mit $`r round(exm_vermoegen$n-1)`$ Freiheitsgraden.
- $`r round(exm_vermoegen$t_emp,3)`$ ist der Wert der Teststatistik berechnet mit Formel \@ref(eq:t-emp-onesample) aus der Stichprobe. Dieser Wert ist skaliert und muss im Kontext der standardisierten $t$-Verteilung wie in Abbildung \@ref(fig:t-distribution) interpretiert werden.
- $p = `r round(exm_vermoegen$p_value_the,3) %>% str_sub(start = 2L)`$ entspricht dem $p$-Wert. Es wird normalerweise die führende $0$ weggelassen (also nicht $`r round(exm_vermoegen$p_value_the,3)`)$, da es sich um eine Zahl handelt, welche nie kleiner als $0$ oder grösser als $1$ sein kann.
:::
::::


:::{.example #alexithymie name="Alexithymie"}

```{r exm-alexithymie}
gen_exm_alexithymie <- function(){
  set.seed(1982)
  mu0 <- 100
  x_min <- 37
  x_max <- 185
  n <- 391
  
  x <- rnorm(n, 96, 25) 
  x[which(x < x_min)] <- x_min
  x[which(x > x_max)] <- x_max
  # x %>% summary()
  # x %>% t.test(alternative = 'two.sided',
  #              mu = 100)
  x_mean <- x %>% mean()
  x_mean_sym <- mu0 + (mu0 - x_mean)
  x_sd <- x %>% sd()
  t_emp <- (x_mean - mu0)/(x_sd/sqrt(n))
  p_value_the <- 2*pt((x_mean - mu0)/ (x_sd / sqrt(n)), n-1)
  effect_size <- (x_mean - mu0) / x_sd
  
  file_name <- '05-exm-alexithymie.sav'
  tibble(alexithymie = x) %>% write_sav(file_name)
  
  # distribution if H_0 were true
  n_samples <- 4000L
  x_means <- 1:n_samples %>% 
    map_dbl(~ mean(rnorm(n, mu0, 25)))
  q975_x_means <- x_means %>% quantile(c(0.975)) %>% unlist() %>% unname()
  q025_x_means <- x_means %>% quantile(c(0.025)) %>% unlist() %>% unname()
  p_value_emp <- mean(x_means < x_mean | x_means > mu0 + (mu0 - x_mean))
  
  # plot histogram of sample means
  plot_hist_density <- plot_hist_denstiy_expected_value(
    x_means, 
    mu0, 
    x_sd, 
    n,
    "Alexithymie CHF",
    0.25)
  
  line_xlim <- xlim(c(95, 105))
  sigma_g <- x_sd / sqrt(n)
  x_range <- seq(mu0-3*sigma_g, mu0+3*sigma_g, length.out = 1000)
  
  # Function to create text data
  create_text_data <- function(labels, y_value, plot_type) {
    tibble(
      label = labels,
      x = c(98, 102),
      y = rep(y_value, 2),
      color = c("red", "green"),
      plot_type = plot_type
    )
  }
  
  
  add_colors <- function(x, type){
    if(type == "Histogram"){
      x %>% 
      mutate(
      color = case_when(
        plot_type == type %>% str_c(" p-Wert") & x > x_mean & x < mu0 + (mu0 - x_mean) ~ "red",
        plot_type == type %>% str_c(" p-Wert") & (x <= x_mean | x >= mu0 + (mu0 - x_mean)) ~ "green",
        (plot_type == type %>% str_c(" Ablehnungsbereich")) & 
          (x > q975_x_means | x < q025_x_means)~ "green",
        (plot_type == type %>% str_c(" Ablehnungsbereich")) & 
          (x <= q975_x_means & x >= q025_x_means) ~ "red"
      )
    )
    }else{
      x %>% 
        mutate(
        color = case_when(
          plot_type == type %>% str_c(" p-Wert") & x > x_mean & x < mu0 + (mu0 - x_mean) ~ "red",
          plot_type == type %>% str_c(" p-Wert") & (x <= x_mean | x >= mu0 + (mu0 - x_mean)) ~ "green",
          (plot_type == type %>% str_c(" Ablehnungsbereich")) & 
            (x > mu0 + qt(0.975, n-1)*x_sd/sqrt(n) | x < mu0 - qt(0.975, n-1)*x_sd/sqrt(n))~ "green",
          (plot_type == type %>% str_c(" Ablehnungsbereich")) & 
            (x <= mu0 + qt(0.975, n-1)*x_sd/sqrt(n) & x >= mu0 - qt(0.975, n-1)*x_sd/sqrt(n)) ~ "red"
        )
      )
    }
    
  }
  # Create data for histograms
  histogram_data <- tibble(
    x = rep(x_means, 2),
    plot_type = rep(c("Histogram p-Wert", 
                      "Histogram Ablehnungsbereich"), 
                    each = length(x_means))
  ) %>%
    add_colors("Histogram")
  
  # Create data for density plots
  density_data <- tibble(
    x = rep(x_range, 2),
    y = dt((x - mu0) / sigma_g, n - 1) / sigma_g,
    plot_type = rep(c("Verteilung p-Wert", 
                      "Verteilung Ablehnungsbereich"), 
                    each = length(x_range))
  ) %>%
    add_colors("Verteilung")
  
  density_data %>% 
    filter(plot_type ==  "Verteilung Ablehnungsbereich")
  
  # Create text data for all plots
  text_pval <- str_c(round(100 * c(1 - p_value_emp, p_value_emp), 1), '%')
  text_sign <- c('95%', '5%')
  text_data_all <- bind_rows(
    create_text_data(
      text_pval,
      200,
      "Histogram p-Wert"
    ),
    create_text_data(
      text_sign, 
      200,
      "Histogram Ablehnungsbereich"
    ),
    create_text_data(
      round(100 *c(1-p_value_the,p_value_the),1) %>% 
        str_c('%'),
      0.25, 
      "Verteilung p-Wert"
    ),
    create_text_data(
      text_sign, 
      0.25,
      "Verteilung Ablehnungsbereich"
    )
  )
  
  custom_labeller <- as_labeller(c(
    "Histogram p-Wert" = "p-Wert",
    "Histogram Ablehnungsbereich" = "Ablehnungsbereich",
    "Verteilung p-Wert" = "p-Wert",
    "Verteilung Ablehnungsbereich" = "Ablehnungsbereich"
  ))
  
  plot_hist_curve_pval_reja <- ggplot() +
    geom_histogram(data = histogram_data,
                   aes(x = x, fill = color),
                   binwidth = 0.25) +
    geom_line(data = density_data,
              aes(x = x, y = y)) +
    geom_ribbon(data = density_data,
                aes(x = x, ymin = 0, ymax = ifelse(color == "red", y, 0)), fill = "#00BFC4") +
    geom_ribbon(data = density_data,
                aes(x = x, ymin = 0, ymax = ifelse(color == "green", y, 0)), fill = "#F8766D") +
    geom_vline(xintercept = x_mean) +
    geom_text(data = text_data_all,
              mapping = aes(x = x, y = y, label = label, colour = color)) +
    facet_wrap(~ plot_type, nrow = 2, scales = "free_y", 
               strip.position = "top",
               labeller = custom_labeller) +
    line_xlim +
    theme(
      axis.text.y = element_text(),
      axis.ticks.y = element_line(),
      axis.title.y = element_text(),
      strip.placement = "outside",
      legend.position = "none"
    ) +
    labs(x = "Alexithymie", y = "W.-dichte                              Häufigkeit")

  return(mget(ls()))
}
exm_alexithymie <- gen_exm_alexithymie()
```

Mit Gefühlsblindheit oder _Alexithymie_ (griechisch: a = ohne, lexis= lesen, sprechen, thymie = Gefühle) werden Einschränkungen bei der Fähigkeit Emotionen wahrzunehmen, zu erkennen und zu beschreiben bezeichnet. Es gibt ein online [Messinstrument](https://www.alexithymie.com/de/), welches die Alexithymie auf einer Skala von $`r exm_alexithymie$x_min`$ Punkten (kleine Gefühlsblindheit) bis $`r exm_alexithymie$x_max`$ (grosse Gefühlsblindheit) misst. Die Skala wurde so gewählt, dass die durchschnittliche Alexithymie aller Menschen bei $`r exm_alexithymie$mu0`$ liegt. Eine Psychologin interessiert sich nun dafür, ob junge Menschen unter $25$ durchschnittlich andere Alexithymie-Werte aufweisen als die Gesamtbevölkerung. Um dies zu testen, befragt sie $N = `r exm_alexithymie$n`$ unter $25$-jährige mit besagtem Messinstrument. In dieser Gruppe wurde eine durchschnittliche Alexithymie von $M = `r round(exm_alexithymie$x_mean,1)`$ Punkten festgestellt.
:::

<!-- Discuss: Was könnten gründe sein für eine tiefere, höhrere Alexithymie? -->
<!-- Es kann festgestellt werden, dass das wahrnehmen, erkennen und beschreiben von Emotionen in den letzten Jahrzehnten vermehrt in den Fokus der Früherziehung gerückt ist. -->
<!-- Discuss: Wieso ist hier ein Test nötig? -->

Der erste Schritt ist auch hier die Null- und Alternativhypothesen aufzustellen. Die Psychologin stellt die Frage, ob sich die durchschnittliche Alexithymie in der Grundgesamtheit, in der Folge mit $\mu$ bezeichnet, von $100$ unterscheidet oder nicht. Es ist zu beobachten, dass sie keine Annahme über die Richtung der Abweichung trifft (eine höhere oder eine tiefere Alexithymie wären denkbar) und es sich deshalb um eine zweiseitige Hypothesenstellung handelt. 

Die Nullhypothese beschreibt den bisherigen Informationsstand, also dass die durchschnittliche Alexithymie der Population bei $100$ Punkten liegt, oder kurz

> $H_0:\mu = 100$ Punkte. 

Die Alternativhypothese besagt das Gegenteil davon, also hier, dass die durchschnittliche Alexithymie nicht mehr bei $100$ Punkten liegt, oder kurz

> $H_1: \mu \neq 100$ Punkte. 

Um die Wahrscheinlichkeit des beobachteten arithmetischen Mittels der Stichprobe von $M = `r round(exm_alexithymie$x_mean,1)`$ Punkten zu ermitteln, gegeben, dass die Nullhypothese wahr ist, kann erneut auf eine Simulation zurückgegriffen werden. Bei diesem Gedankenexperiment wird angenommen, dass Nullhypothese wahr ist und dass das die Untersuchung $`r exm_alexithymie$n_samples`$-mal wiederholt wurde mit jeweils $`r exm_alexithymie$n`$ Beobachtungen. Von jeder dieser Stichproben kann wiederum das arithmetische Mittel berechnet werden. Die Verteilung dieser arithmetischen Mittel ist in Abbildung \@ref(fig:exm-alexithymie-plot) oben dargestellt.

```{r exm-alexithymie-plot, fig.cap="TODO:"}
exm_alexithymie$plot_hist_curve_pval_reja
```

Der $p$-Wert, also die Wahrscheinlichkeit, dass der beobachtete Wert oder ein noch extremerer Wert in Richtung der Alternativhypothese resultiert, wird hier aufgrund der zweiseitigen Hypothesenstellung auch zweiseitig ausgelegt. Extremer in Richtung der Alternativhypothese meint hier alle Werte, die weiter weg als der beobachtete Durchschnittswert $`r round(exm_alexithymie$x_mean,1)`$ vom hypothetischen Erwartungswert $\mu = `r exm_alexithymie$mu0`$ sind. Konkret sind dies alle Werte, welche kleiner als $`r round(exm_alexithymie$x_mean,1)`$, und alle Werte, welche grösser als $`r round(exm_alexithymie$x_mean_sym,1)`$ sind (roter Bereich in Abbildung \@ref(fig:exm-alexithymie-plot) oben rechts). Der Anteil der Werte, welche diese Bedinung erfüllen liegt bei $p = `r round(100*exm_alexithymie$p_value_emp,1)`\%$. Es ist demnach recht unwahrscheinlich, dass die Nullhypothese stimmt und zufällig ein Stichprobendurchschnittswert von $`r round(exm_alexithymie$x_mean,1)`$ Alexithymie-Punkten herauskommt.

Aufgrund der zweiseitigen Hypothesenstellung beinhaltet auch der Ablehnungsbereich sowohl die tiefsten $2.5\%$ und höchsten $2.5\%$, also insgesamt die $5\%$ extremen Durchschnittswerte. Dies sind alle Werte tiefer als  $`r round(exm_alexithymie$q025_x_means,2)`$ und alle Werte höher als $`r round(exm_alexithymie$q975_x_means,2)`$ (roter Bereich in Abbildung \@ref(fig:exm-alexithymie-plot) oben links). Da das arithmetische Mittel der Stichprobe $`r round(exm_alexithymie$x_mean,1)`$ im Ablehnungsbereich liegt, liegt hier ein signifikantes Resultat vor bei Signifikanzniveau $5\%$.

Auch in diesem Fall kann die Verteilung der Stichprobenmittelwerte mit dem zentralen Grenzwertsatz angenähert werden. Es ergeben sich annähernd dieselben Resultate für den $p$-Wert (roter Bereich in Abbildung \@ref(fig:exm-alexithymie-plot) unten rechts) und für den Ablehnungsbereich (roter Bereich in Abbildung \@ref(fig:exm-alexithymie-plot) unten links).

Die Psychologin kann nun wie folgt berichten:

> Die durchschnittliche Alexithymie ($M = `r round(exm_alexithymie$x_mean,1)`$ Punkte, $SD = `r round(exm_alexithymie$x_sd,1)`$, $N = `r round(exm_alexithymie$n)`$) unterscheidet sich bei den unter 25-jährigen signifikant vom Populationsdurchschnitt von $100$ Punkte, $t(`r round(exm_alexithymie$n-1)`) = `r round(exm_alexithymie$t_emp,3)`$, $p = `r round(exm_alexithymie$p_value_the,3) %>% str_sub(start = 2L)`$.


## Weicht der gefundene Durchschnitt stark vom hypothetischen Wert ab?

<!-- Discuss: Probleme (grosses n -> immer signifikant, je nach Einheit ist Erwartungswertunterschied ganz anders). -->

In einem so berichteten Testresultat sind essenziell zwei Informationen enthalten: (1) was sind die getesteten Hypothesen und (2) wie wahrscheinlich es ist, dass das gefundene Resultat eine Folge der Zufallsstichprobenziehung ist. Was hier noch fehlt ist eine Angabe darüber wie gross die praktische Relevanz dieses Testresultates ist.

Um eine solche Relevanz zu messen wurde der Begriff der Effektstärke eingeführt. Eine Effektstärke ist eine Zahl ohne Einheit (Meter, Franken, ...), welche unabhängig von der Stichprobengrösse ist und nahe bei Null liegt, wenn die Nullhypothese nicht abgelehnt wurde.

Wird im Vermögensbeispiel \@ref(exm:vermoegen) die Differenz zwischen geschätzem Erwartungswert und hypothetischem Erwartungswert 
$$\bar{x} - \mu = `r round(exm_vermoegen$x_mean)` \text{CHF} - `r exm_vermoegen$mu0` \text{CHF}  = `r round(exm_vermoegen$x_mean)-exm_vermoegen$mu0`$$
betrachtet, so fällt auf, dass dieser Wert bereits zwei der oben genannten Eigenschaften aufweist. Tatsächlich ist dieser Wert unabhängig von der Stichprobengrösse und er liegt nahe bei $0$, wenn das Testresultat nicht signifikant war. Letzteres kann beobachtet werde indem in der Formel \@ref(eq:t-emp-onesample) verschiedene Differenzen eingesetzt werden und mit der Abbildung  \@ref(fig:t-distribution) verglichen werden. 

<!-- Discuss: how? -->

Wenn jetzt ein anderer Sozialpsychologe die Auswertung wiederholen würde, aber statt in CHF in Rappen Rp rechnet, dann erhält er den Wert
$$\bar{x} - \mu = `r 100*round(exm_vermoegen$x_mean)` \text{Rp} - `r exm_vermoegen$mu0*100` \text{Rp}  = `r (round(exm_vermoegen$x_mean)-exm_vermoegen$mu0)*100`.$$
Dass mit den gleichen Zahlen je nach Einheit eine andere Effektstärke gefunden wird ist unpraktisch für den Vergleich der Testresultate. Die Lösung in diesem Fall ist diese Differenz durch die geschätzte Standardabweichung zu rechnen. Dies ergibt

- in CHF: $d = \frac{\bar{x} - \mu}{s} = \frac{`r round(exm_vermoegen$x_mean)` \text{CHF} - `r exm_vermoegen$mu0` \text{CHF}}{`r round(exm_vermoegen$x_sd)`\text{CHF}}  = `r round((round(exm_vermoegen$x_mean)-exm_vermoegen$mu0)/round(exm_vermoegen$x_sd),2)`$
- in Rp: $d = \frac{\bar{x} - \mu}{s} = \frac{`r 100*round(exm_vermoegen$x_mean)` \text{Rp} - `r exm_vermoegen$mu0*100` \text{Rp}}{`r 100*round(exm_vermoegen$x_sd)`\text{Rp}}  = `r round((round(exm_vermoegen$x_mean)-exm_vermoegen$mu0)/round(exm_vermoegen$x_sd),2)` .$

Mit dieser Formel werden für beide Einheiten derselbe Wert berechnet. Effektiv dient jetzt als Einheit die Standardabweichung: Eine grosse Differenz bei einer grossen Standardabweichung des Merkmals führt zur selben Effektstärke wie eine kleine Differenz bei kleiner Standardabweichung eines Merkmals. Da Menschen sich nicht gewohnt sind Zahlen als Standardabweichungen zu interpretieren hat [@cohen1988] ein folgende Richtwerte entwickelt:

- $|d| \approx 0.3$: schwacher Effekt
- $|d| \approx 0.5$: mittlerer Effekt
- $|d| \approx 0.8$: starker Effekt

<!-- Discuss: 0.5 bedeutet die Differenz ist eine halbe standardabweichung gross. -->

Cohen selbst hat davor gewarnt diese Werte als absolut darzustellen. Vielmehr sollte die Interpretation der Effektstärke vom Forschungsgebiet und dem Messinstrument abhängen. Um im Unterricht eine beurteilbare Praxis zu etablieren sollen folgende Regeln gelten:

- $0 < |d| \leq 0.4$: schwacher Effekt
- $0.4 < |d| \leq 0.65$: mittlerer Effekt
- $0.65 < |d|$: starker Effekt

<!-- Discuss absoluter Wert -->

Das Berichten der Testresultate wird mit der Effektstärke ergänzt:

> Das durchschnittliche Vermögen ($M = `r round(exm_vermoegen$x_mean)`$ CHF, $SD = `r round(exm_vermoegen$x_sd)`$, $N = `r round(exm_vermoegen$n)`$) ist in diesem Jahr nicht signifikant grösser als $100'000$ CHF, $t(`r round(exm_vermoegen$n-1)`) = `r round(exm_vermoegen$t_emp,3)`$, $p = `r round(exm_vermoegen$p_value_the,3) %>% str_sub(start = 2L)`, d = `r round(exm_vermoegen$effect_size,2)`$.

> Die durchschnittliche Alexithymie ($M = `r round(exm_alexithymie$x_mean,1)`$ Punkte, $SD = `r round(exm_alexithymie$x_sd,1)`$, $N = `r round(exm_alexithymie$n)`$) unterscheidet sich bei den unter 25-jährigen signifikant vom Populationsdurchschnitt von $100$ Punkte, $t(`r round(exm_alexithymie$n-1)`) = `r round(exm_alexithymie$t_emp,3)`$, $p = `r round(exm_alexithymie$p_value_the,3) %>% str_sub(start = 2L)`, d = `r round(exm_alexithymie$effect_size,2)`$.

In beiden Fällen liegt ein schwacher Effekt vor. Der Effekt bei der Alexithymie ist schwächer als der Effekt bei der Vermögensstudie. Der $p$-Wert sagt aber aus, dass der Effekt beim Vermögen durch die Zufallsstichprobe zustande gekommen ist, während es bei der Alexithymie unwahrscheinlich ist, dass der Effekt durch die Zufallsstichprobe zustande gekommen ist.

## Übungen

::: {.exercise  #vermoegen}
<!-- 
Ziel: 
- Zahlen aus den Vermögen-Beispiel mit Jamovi verknüpfen.
-->
Reproduziere das Beispiel Vermögen \@ref(exm:vermoegen) mit `Jamovi` indem folgende Teilschritte durchgeführt werden:

- Datensatz `r inline_code(exm_vermoegen$file_name)` in `Jamovi` einladen.
- Wähle `Analysen > t-Tests > t-Test mit einer Stichprobe`.
- Definiere die Hypothese wie im Beispiel und wähle die Testoptionen so, dass du alle Zahlen des Testberichts wiederfindest.

:::

:::{.solution}
```{r sol-vermoegen-input, out.width='100%', fig.cap='Jamovi Eingabe.', fig.show='hold'}
knitr::include_graphics("figures/05-exr-vermoegen-jmv-input.jpg")
```

```{r sol-vermoegen-output, out.width='100%', fig.cap='Deskriptive Statistiken.', fig.show='hold'}
knitr::include_graphics("figures/05-exr-vermoegen-jmv-output.jpg")
```  
:::

::: {.exercise  #alexithymie}
<!-- 
Ziel: 
- Zahlen aus den Alexithymie-Beispiel mit Jamovi verknüpfen.
-->
Reproduziere das Beispiel Alexithymie \@ref(exm:alexithymie) mit `Jamovi` indem folgende Teilschritte durchgeführt werden:

- Datensatz `r inline_code(exm_alexithymie$file_name)` in `Jamovi` einladen.
- Wähle `Analysen > t-Tests > t-Test mit einer Stichprobe`.
- Definiere die Hypothese wie im Beispiel und wähle die Testoptionen so, dass du alle Zahlen des Testberichts wiederfindest.
:::

:::{.solution}
```{r sol-alexithymie-input, out.width='100%', fig.cap='Jamovi Eingabe.', fig.show='hold'}
knitr::include_graphics("figures/05-exr-alexithymie-jmv-input.jpg")
```

```{r sol-alexithymie-output, out.width='100%', fig.cap='Deskriptive Statistiken.', fig.show='hold'}
knitr::include_graphics("figures/05-exr-alexithymie-jmv-output.jpg")
```  
:::
